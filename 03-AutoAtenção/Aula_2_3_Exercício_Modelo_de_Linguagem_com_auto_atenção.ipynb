{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMI0JT_YuYF3"
      },
      "source": [
        "## Exercício: Modelo de Linguagem com auto-atenção\n",
        "\n",
        "Este exercício é similar ao da aula passada, mas iremos agora treinar uma rede neural *com auto-atenção* para prever a próxima palavra de um texto, data as palavras anteriores como entrada.\n",
        "\n",
        "Na camada de auto-atenção, deve-se implementar (vide slide 34):\n",
        "- Embeddings de posição\n",
        "- Projeções lineares (WQ, WK, WV, WO)\n",
        "- Camada de feed forward (2-layer MLP)\n",
        "\n",
        "Instrucões:\n",
        "- É necessário fazer duas implementações da camada de auto-atenção: uma usando laços (ineficiente, mas fácil de entender) e outra matricial (eficiente mas difícil de entender). Usar slide 36 como referência.\n",
        "\n",
        "- Fazer um assert para garantir que o resultado das duas implementações é exatamente igual.\n",
        "\n",
        "- No treinamento, usar apenas a implementação matricial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string\n",
        "from collections import Counter\n",
        "from typing import List, Dict, Union, Tuple\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "import abc\n",
        "\n",
        "import numpy as np\n",
        "from numpy.testing import assert_raises, assert_array_equal, assert_array_almost_equal\n",
        "from numpy.typing import ArrayLike\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def assert_array_not_equal(array1:ArrayLike, array2:ArrayLike) -> ArrayLike:\n",
        "    assert_raises(AssertionError, assert_array_equal, array1, array2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reset_seeds() -> None:\n",
        "    random.seed(18)\n",
        "    torch.manual_seed(18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYbkEzdD37sZ"
      },
      "source": [
        "## Faz download e carrega o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qAnqY_q0beK",
        "outputId": "f810fdb0-138d-4917-b7ef-69ab266acef6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100   304  100   304    0     0    454      0 --:--:-- --:--:-- --:--:--   456\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "\n",
            " 11  364k   11 42594    0     0  31528      0  0:00:11  0:00:01  0:00:10 31528\n",
            "100  364k  100  364k    0     0   177k      0  0:00:02  0:00:02 --:--:--  463k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100   304  100   304    0     0    549      0 --:--:-- --:--:-- --:--:--   551\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "\n",
            " 12  337k   12 42594    0     0  33796      0  0:00:10  0:00:01  0:00:09 33796\n",
            "100  337k  100  337k    0     0   184k      0  0:00:01  0:00:01 --:--:--  521k\n"
          ]
        }
      ],
      "source": [
        "if not os.path.isfile(\"67724.txt.utf-8\"):\n",
        "    !curl -LO https://www.gutenberg.org/ebooks/67724.txt.utf-8\n",
        "\n",
        "if not os.path.isfile(\"67725.txt.utf-8\"):\n",
        "    !curl -LO https://www.gutenberg.org/ebooks/67725.txt.utf-8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_UzC9pV091C",
        "outputId": "1553b04f-24c4-4027-8cab-0907f92f04df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4969"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = open(\"67724.txt.utf-8\",\"r\", encoding=\"utf8\").read()\n",
        "text += open(\"67725.txt.utf-8\",\"r\", encoding=\"utf8\").read()\n",
        "\n",
        "paragraphs = text.split(\"\\n\\n\")\n",
        "len(paragraphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text:str) -> str:\n",
        "    '''\n",
        "    Clean the text, changing upper case and setting numbers to 999\n",
        "    '''\n",
        "    \n",
        "    text = text.lower()\n",
        "    old_text = text.split()\n",
        "    new_text = []\n",
        "\n",
        "    for j in range(len(old_text)):\n",
        "        word = old_text[j] \n",
        "        if word.isdigit():\n",
        "            word = \"999\"\n",
        "        elif len(word) > 1 and word[0] in string.punctuation:\n",
        "            old_text.insert(j+1, word[1:])\n",
        "            word = word[0]\n",
        "        elif word[-1] in string.punctuation and len(word) > 1:\n",
        "            old_text.insert(j+1, word[:-1])\n",
        "            old_text.insert(j+2, word[-1])\n",
        "            \n",
        "            word = \"\"\n",
        "        \n",
        "        if len(word) > 0:\n",
        "            new_text.append(word)\n",
        "    \n",
        "    return \" \".join(new_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhUFjtNdDuG0",
        "outputId": "78798c0c-deca-4454-d3fb-7d3ba70f3e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAMPLE ----------------\n",
            "﻿the project gutenberg ebook of o guarany : romance brazileiro , vol . 999 ( of 999 ) this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with almost no restrictions whatsoever . you may copy it , give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org . if you are not located in the united states , you\n",
            "---------------------\n",
            "4892\n"
          ]
        }
      ],
      "source": [
        "cleaned_paragraphs = [paragraph.replace(\"\\n\", \" \") for paragraph in paragraphs if paragraph.strip()]\n",
        "\n",
        "#Paper:\n",
        "#ponctuation -> keep (separado das outras palavras, \"pontuação,\" -> \"pontuação\"+\",\")\n",
        "#numeric -> special symbol (colocando todos como 999 para convergir para o mesmo símbolo)\n",
        "#upper -> lower\n",
        "#proper nouns -> special symbol (difícil identificar, ignorado)\n",
        "#rare words -> special symbol (feito na parte de encoding)\n",
        "\n",
        "for i in range(len(cleaned_paragraphs)):\n",
        "    cleaned_paragraphs[i] = clean_text(cleaned_paragraphs[i])\n",
        "\n",
        "print(\"SAMPLE ----------------\")\n",
        "print(cleaned_paragraphs[0])\n",
        "print(\"---------------------\")\n",
        "\n",
        "print(len(cleaned_paragraphs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFVN2ihb33Rf"
      },
      "source": [
        "## Análise do dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSRHqe3H4ZFw",
        "outputId": "4a985c7a-ce1d-4b72-d253-c9fbbc5f9440"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11470"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def count_words(texts:List[str]) -> Counter:\n",
        "    word_counts = Counter()\n",
        "    for text in texts:\n",
        "        word_counts.update(text.split(\" \"))\n",
        "    return word_counts\n",
        "\n",
        "word_counts = count_words(cleaned_paragraphs)\n",
        "\n",
        "len(word_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyGVDL9KzJ_I"
      },
      "source": [
        "## Criando um vocabulário"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vocab(word_counts:Counter, vocab_size:int) -> Tuple[Dict[str, int], List[str]]:\n",
        "    most_frequent_words = [word for word, count in word_counts.most_common(vocab_size)]\n",
        "    vocab = {word: i for i, word in enumerate(most_frequent_words, 1)}\n",
        "\n",
        "    inverse_vocab = list(vocab.keys())\n",
        "\n",
        "    return vocab, inverse_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_vocab_size = 1000\n",
        "test_vocab, test_inverse_vocab = create_vocab(word_counts, test_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{',': 1,\n",
              " 'a': 2,\n",
              " 'que': 3,\n",
              " '-': 4,\n",
              " 'o': 5,\n",
              " 'de': 6,\n",
              " 'e': 7,\n",
              " ';': 8,\n",
              " '.': 9,\n",
              " 'um': 10,\n",
              " 'do': 11,\n",
              " 'não': 12,\n",
              " 'uma': 13,\n",
              " 'os': 14,\n",
              " 'se': 15,\n",
              " 'da': 16,\n",
              " 'com': 17,\n",
              " 'sua': 18,\n",
              " 'para': 19,\n",
              " 'seu': 20,\n",
              " 'em': 21,\n",
              " 'pery': 22,\n",
              " 'as': 23,\n",
              " 'no': 24,\n",
              " 'por': 25,\n",
              " 'como': 26,\n",
              " 'ao': 27,\n",
              " 'era': 28,\n",
              " 'tinha': 29,\n",
              " 'á': 30,\n",
              " 'cecilia': 31,\n",
              " 'na': 32,\n",
              " 'd': 33,\n",
              " 'sobre': 34,\n",
              " 'é': 35,\n",
              " 'mas': 36,\n",
              " 'the': 37,\n",
              " '!': 38,\n",
              " 'elle': 39,\n",
              " 'dos': 40,\n",
              " 'indio': 41,\n",
              " 'quando': 42,\n",
              " 'seus': 43,\n",
              " ':': 44,\n",
              " 'antonio': 45,\n",
              " 'mais': 46,\n",
              " 'alvaro': 47,\n",
              " 'of': 48,\n",
              " 'das': 49,\n",
              " 'lhe': 50,\n",
              " 'olhos': 51,\n",
              " 'depois': 52,\n",
              " 'menina': 53,\n",
              " '?': 54,\n",
              " 'ella': 55,\n",
              " 'pela': 56,\n",
              " 'disse': 57,\n",
              " 'havia': 58,\n",
              " 'fidalgo': 59,\n",
              " 'tu': 60,\n",
              " 'ainda': 61,\n",
              " 'isabel': 62,\n",
              " 'senhora': 63,\n",
              " 'momento': 64,\n",
              " 'estava': 65,\n",
              " 'aventureiros': 66,\n",
              " 'loredano': 67,\n",
              " 'project': 68,\n",
              " 'dous': 69,\n",
              " 'casa': 70,\n",
              " 'to': 71,\n",
              " 'me': 72,\n",
              " 'tempo': 73,\n",
              " 'só': 74,\n",
              " 'já': 75,\n",
              " 'nos': 76,\n",
              " 'mariz': 77,\n",
              " 'italiano': 78,\n",
              " 'todos': 79,\n",
              " '_': 80,\n",
              " 'mesmo': 81,\n",
              " 'you': 82,\n",
              " 'pelo': 83,\n",
              " 'foi': 84,\n",
              " 'porque': 85,\n",
              " 'então': 86,\n",
              " 'homem': 87,\n",
              " 'sem': 88,\n",
              " 'meio': 89,\n",
              " 'olhar': 90,\n",
              " 'ia': 91,\n",
              " 'and': 92,\n",
              " 'or': 93,\n",
              " 'esse': 94,\n",
              " 'vida': 95,\n",
              " 'essa': 96,\n",
              " 'suas': 97,\n",
              " 'mão': 98,\n",
              " 'aos': 99,\n",
              " 'entre': 100,\n",
              " 'isto': 101,\n",
              " 'quem': 102,\n",
              " 'tão': 103,\n",
              " 'tudo': 104,\n",
              " 'pouco': 105,\n",
              " 'in': 106,\n",
              " 'eu': 107,\n",
              " 'vez': 108,\n",
              " 'rio': 109,\n",
              " 'assim': 110,\n",
              " 'esta': 111,\n",
              " 'podia': 112,\n",
              " 'homens': 113,\n",
              " 'cabeça': 114,\n",
              " 'moça': 115,\n",
              " 'onde': 116,\n",
              " 'apenas': 117,\n",
              " 'moço': 118,\n",
              " 'gutenberg™': 119,\n",
              " 'ou': 120,\n",
              " 'te': 121,\n",
              " 'ser': 122,\n",
              " 'meu': 123,\n",
              " 'nem': 124,\n",
              " 'ha': 125,\n",
              " 'este': 126,\n",
              " 'vos': 127,\n",
              " 'cavalheiro': 128,\n",
              " 'palavra': 129,\n",
              " 'selvagem': 130,\n",
              " 'fez': 131,\n",
              " 'toda': 132,\n",
              " 'minha': 133,\n",
              " 'dia': 134,\n",
              " 'pai': 135,\n",
              " 'with': 136,\n",
              " 'bem': 137,\n",
              " 'sim': 138,\n",
              " 'palavras': 139,\n",
              " 'corpo': 140,\n",
              " 'duas': 141,\n",
              " 'work': 142,\n",
              " 'fazer': 143,\n",
              " 'rosto': 144,\n",
              " 'this': 145,\n",
              " 'pois': 146,\n",
              " 'até': 147,\n",
              " 'coração': 148,\n",
              " 'selvagens': 149,\n",
              " 'tinhão': 150,\n",
              " 'terra': 151,\n",
              " 'ayres': 152,\n",
              " '999': 153,\n",
              " 'ver': 154,\n",
              " 'ás': 155,\n",
              " 'nas': 156,\n",
              " 'ter': 157,\n",
              " 'noite': 158,\n",
              " 'porém': 159,\n",
              " 'labios': 160,\n",
              " 'porta': 161,\n",
              " 'voz': 162,\n",
              " 'grande': 163,\n",
              " 'cousa': 164,\n",
              " 'outro': 165,\n",
              " 'velho': 166,\n",
              " 'sr': 167,\n",
              " 'passava': 168,\n",
              " 'pag': 169,\n",
              " 'devia': 170,\n",
              " 'vezes': 171,\n",
              " 'qual': 172,\n",
              " 'amigo': 173,\n",
              " 'primeiro': 174,\n",
              " 'morte': 175,\n",
              " 'força': 176,\n",
              " 'alguma': 177,\n",
              " 'amor': 178,\n",
              " 'emquanto': 179,\n",
              " 'ruy': 180,\n",
              " 'muito': 181,\n",
              " 'longe': 182,\n",
              " 'nesse': 183,\n",
              " 'gomes': 184,\n",
              " 'esplanada': 185,\n",
              " 'parecia': 186,\n",
              " 'tua': 187,\n",
              " 'mãi': 188,\n",
              " 'any': 189,\n",
              " 'lugar': 190,\n",
              " 'todas': 191,\n",
              " 'algum': 192,\n",
              " 'outros': 193,\n",
              " 'mãos': 194,\n",
              " 'alma': 195,\n",
              " 'works': 196,\n",
              " 'primeira': 197,\n",
              " 'seio': 198,\n",
              " 'espirito': 199,\n",
              " 'hora': 200,\n",
              " 'arvore': 201,\n",
              " 'parte': 202,\n",
              " 'fundo': 203,\n",
              " 'dessa': 204,\n",
              " 'filha': 205,\n",
              " 'idéa': 206,\n",
              " 'sempre': 207,\n",
              " 'alguns': 208,\n",
              " 'companheiros': 209,\n",
              " 'antes': 210,\n",
              " 'respondeu': 211,\n",
              " 'escudeiro': 212,\n",
              " 'aymorés': 213,\n",
              " 'gutenberg': 214,\n",
              " 'not': 215,\n",
              " 'lado': 216,\n",
              " 'agora': 217,\n",
              " 'luz': 218,\n",
              " 'sol': 219,\n",
              " 'céo': 220,\n",
              " 'aquella': 221,\n",
              " 'tres': 222,\n",
              " 'pelos': 223,\n",
              " 'braço': 224,\n",
              " 'familia': 225,\n",
              " 'gesto': 226,\n",
              " 'aventureiro': 227,\n",
              " 'viu': 228,\n",
              " 'sabia': 229,\n",
              " 'ahi': 230,\n",
              " 'feito': 231,\n",
              " 'mulher': 232,\n",
              " 'movimento': 233,\n",
              " 'electronic': 234,\n",
              " 'novo': 235,\n",
              " 'desse': 236,\n",
              " 'todo': 237,\n",
              " 'tambem': 238,\n",
              " 'janella': 239,\n",
              " 'razão': 240,\n",
              " 'fosse': 241,\n",
              " 'by': 242,\n",
              " 'si': 243,\n",
              " 'contra': 244,\n",
              " 'pés': 245,\n",
              " 'repente': 246,\n",
              " 'fazia': 247,\n",
              " 'junto': 248,\n",
              " 'arvores': 249,\n",
              " 'sorriso': 250,\n",
              " 'sentia': 251,\n",
              " 'are': 252,\n",
              " 'nada': 253,\n",
              " 'diogo': 254,\n",
              " 'quanto': 255,\n",
              " 'inimigo': 256,\n",
              " 'nunca': 257,\n",
              " 'algumas': 258,\n",
              " 'lauriana': 259,\n",
              " 'deus': 260,\n",
              " 'vós': 261,\n",
              " 'for': 262,\n",
              " 'if': 263,\n",
              " 'quasi': 264,\n",
              " 'filho': 265,\n",
              " 'cada': 266,\n",
              " 'floresta': 267,\n",
              " 'pelas': 268,\n",
              " 'erão': 269,\n",
              " 'vendo': 270,\n",
              " 'elles': 271,\n",
              " 'scena': 272,\n",
              " 'aquelle': 273,\n",
              " 'face': 274,\n",
              " 'ouvido': 275,\n",
              " 'terms': 276,\n",
              " 'durante': 277,\n",
              " 'preciso': 278,\n",
              " 'mesma': 279,\n",
              " 'dias': 280,\n",
              " 'talvez': 281,\n",
              " 'vai': 282,\n",
              " 'braços': 283,\n",
              " 'quer': 284,\n",
              " 'senão': 285,\n",
              " 'apezar': 286,\n",
              " 'diante': 287,\n",
              " 'fogo': 288,\n",
              " \"n'um\": 289,\n",
              " 'desde': 290,\n",
              " 'és': 291,\n",
              " 'desta': 292,\n",
              " 'sala': 293,\n",
              " 'campo': 294,\n",
              " 'aqui': 295,\n",
              " 'essas': 296,\n",
              " 'ar': 297,\n",
              " 'folhas': 298,\n",
              " 'esses': 299,\n",
              " 'fim': 300,\n",
              " 'passado': 301,\n",
              " 'india': 302,\n",
              " 'morrer': 303,\n",
              " 'leito': 304,\n",
              " 'menos': 305,\n",
              " 'delle': 306,\n",
              " 'ficou': 307,\n",
              " 'esperança': 308,\n",
              " 'is': 309,\n",
              " 'neste': 310,\n",
              " 'pequena': 311,\n",
              " 'grandes': 312,\n",
              " 'pé': 313,\n",
              " 'causa': 314,\n",
              " 'continuou': 315,\n",
              " 'horas': 316,\n",
              " 'silencio': 317,\n",
              " 'sentio': 318,\n",
              " 'quarto': 319,\n",
              " 'menor': 320,\n",
              " 'tanto': 321,\n",
              " 'isso': 322,\n",
              " 'outra': 323,\n",
              " 'sombra': 324,\n",
              " 'passou': 325,\n",
              " 'pensamento': 326,\n",
              " 'tem': 327,\n",
              " 'fôra': 328,\n",
              " 'states': 329,\n",
              " 'entretanto': 330,\n",
              " 'havião': 331,\n",
              " 'tomou': 332,\n",
              " 'armas': 333,\n",
              " 'della': 334,\n",
              " 'forte': 335,\n",
              " 'desses': 336,\n",
              " 'doce': 337,\n",
              " 'terrivel': 338,\n",
              " 'seria': 339,\n",
              " 'bento': 340,\n",
              " 'copyright': 341,\n",
              " 'janeiro': 342,\n",
              " 'natureza': 343,\n",
              " 'perigo': 344,\n",
              " 'prazer': 345,\n",
              " 'sentimento': 346,\n",
              " 'flôr': 347,\n",
              " '(': 348,\n",
              " 'dar': 349,\n",
              " 'certo': 350,\n",
              " 'ultima': 351,\n",
              " 'estas': 352,\n",
              " 'dizer': 353,\n",
              " 'expressão': 354,\n",
              " 'triste': 355,\n",
              " 'simões': 356,\n",
              " 'foundation': 357,\n",
              " 'posição': 358,\n",
              " 'ordem': 359,\n",
              " 'instante': 360,\n",
              " 'luta': 361,\n",
              " 'sangue': 362,\n",
              " 'nobre': 363,\n",
              " 'visto': 364,\n",
              " 'nessa': 365,\n",
              " 'tirou': 366,\n",
              " 'teu': 367,\n",
              " 'prima': 368,\n",
              " 'grito': 369,\n",
              " 'prisioneiro': 370,\n",
              " 'all': 371,\n",
              " 'donations': 372,\n",
              " \"n'uma\": 373,\n",
              " 'beira': 374,\n",
              " 'passar': 375,\n",
              " 'canto': 376,\n",
              " 'indios': 377,\n",
              " 'espada': 378,\n",
              " 'animal': 379,\n",
              " 'tenho': 380,\n",
              " 'arco': 381,\n",
              " 'aposento': 382,\n",
              " ')': 383,\n",
              " 'it': 384,\n",
              " 'plano': 385,\n",
              " 'especie': 386,\n",
              " 'alto': 387,\n",
              " 'vontade': 388,\n",
              " 'sido': 389,\n",
              " 'senhor': 390,\n",
              " 'oh': 391,\n",
              " 'exclamou': 392,\n",
              " 'peito': 393,\n",
              " 'voltou': 394,\n",
              " 'segredo': 395,\n",
              " 'tribu': 396,\n",
              " 'from': 397,\n",
              " 'agreement': 398,\n",
              " 'pedra': 399,\n",
              " 'parede': 400,\n",
              " 'nome': 401,\n",
              " 'passos': 402,\n",
              " 'agua': 403,\n",
              " 'inimigos': 404,\n",
              " 'arma': 405,\n",
              " 'ardente': 406,\n",
              " 'ultimo': 407,\n",
              " 'tivesse': 408,\n",
              " 'soeiro': 409,\n",
              " 'manhã': 410,\n",
              " 'united': 411,\n",
              " 'other': 412,\n",
              " 'pequeno': 413,\n",
              " 'tronco': 414,\n",
              " 'effeito': 415,\n",
              " 'ponta': 416,\n",
              " 'distancia': 417,\n",
              " 'fronte': 418,\n",
              " 'sabeis': 419,\n",
              " 'vossa': 420,\n",
              " 'ergueu-se': 421,\n",
              " 'vento': 422,\n",
              " 'cuja': 423,\n",
              " 'via': 424,\n",
              " 'poder': 425,\n",
              " 'guerreiros': 426,\n",
              " 'salvar': 427,\n",
              " 'be': 428,\n",
              " 'that': 429,\n",
              " 'literary': 430,\n",
              " 'são': 431,\n",
              " 'impossivel': 432,\n",
              " 'seja': 433,\n",
              " 'coragem': 434,\n",
              " 'occasião': 435,\n",
              " 'conhecia': 436,\n",
              " 'tarde': 437,\n",
              " 'verdade': 438,\n",
              " 'veio': 439,\n",
              " 'voltou-se': 440,\n",
              " 'perto': 441,\n",
              " 'esperava': 442,\n",
              " 'dedicação': 443,\n",
              " 'logo': 444,\n",
              " 'mal': 445,\n",
              " 'may': 446,\n",
              " 'license': 447,\n",
              " 'annos': 448,\n",
              " 'ião': 449,\n",
              " 'dava': 450,\n",
              " 'vista': 451,\n",
              " 'chão': 452,\n",
              " 'embora': 453,\n",
              " 'estavão': 454,\n",
              " 'tendes': 455,\n",
              " 'signal': 456,\n",
              " 'passo': 457,\n",
              " 'sob': 458,\n",
              " 'raio': 459,\n",
              " 'acabava': 460,\n",
              " 'lagrimas': 461,\n",
              " 'deo': 462,\n",
              " 'susto': 463,\n",
              " 'dizia': 464,\n",
              " 'teve': 465,\n",
              " 'começou': 466,\n",
              " 'conheceu': 467,\n",
              " 'torno': 468,\n",
              " 'nossa': 469,\n",
              " 'quatro': 470,\n",
              " 'livre': 471,\n",
              " 'deserto': 472,\n",
              " 'cabana': 473,\n",
              " 'nesta': 474,\n",
              " 'fazendo': 475,\n",
              " 'chefe': 476,\n",
              " 'volta': 477,\n",
              " 'respeito': 478,\n",
              " 'quereis': 479,\n",
              " 'faces': 480,\n",
              " 'quiz': 481,\n",
              " 'sei': 482,\n",
              " 'perguntou': 483,\n",
              " 'physionomia': 484,\n",
              " 'cabellos': 485,\n",
              " 'cahir': 486,\n",
              " 'ergueu': 487,\n",
              " 'ouvio': 488,\n",
              " 'felicidade': 489,\n",
              " 'frade': 490,\n",
              " 'gabinete': 491,\n",
              " 'canôa': 492,\n",
              " 'ebook': 493,\n",
              " 'use': 494,\n",
              " 'copy': 495,\n",
              " 'dessas': 496,\n",
              " 'simples': 497,\n",
              " 'jardim': 498,\n",
              " 'frente': 499,\n",
              " 'quero': 500,\n",
              " 'melhor': 501,\n",
              " 'pôde': 502,\n",
              " 'ora': 503,\n",
              " 'mim': 504,\n",
              " 'está': 505,\n",
              " 'côr': 506,\n",
              " 'calma': 507,\n",
              " 'rapidamente': 508,\n",
              " 'vingança': 509,\n",
              " 'alegria': 510,\n",
              " 'soltou': 511,\n",
              " 'medo': 512,\n",
              " 'trademark': 513,\n",
              " 'on': 514,\n",
              " 'archive': 515,\n",
              " 'deve': 516,\n",
              " 'escada': 517,\n",
              " 'guerra': 518,\n",
              " 'naquella': 519,\n",
              " 'naquelle': 520,\n",
              " 'ponto': 521,\n",
              " 'companheiro': 522,\n",
              " 'nós': 523,\n",
              " 'deixou': 524,\n",
              " 'brilhante': 525,\n",
              " 'sorrindo': 526,\n",
              " 'rumor': 527,\n",
              " 'bella': 528,\n",
              " 'vosso': 529,\n",
              " 'vão': 530,\n",
              " 'alpendre': 531,\n",
              " 'comprehender': 532,\n",
              " 'vespera': 533,\n",
              " 'aguas': 534,\n",
              " 'esforço': 535,\n",
              " 'direito': 536,\n",
              " 'interior': 537,\n",
              " 'deste': 538,\n",
              " 'mundo': 539,\n",
              " 'tom': 540,\n",
              " 'qualquer': 541,\n",
              " 'caminho': 542,\n",
              " 'aproximou-se': 543,\n",
              " 'immediatamente': 544,\n",
              " 'momentos': 545,\n",
              " 'innocente': 546,\n",
              " 'feliz': 547,\n",
              " 'cahio': 548,\n",
              " 'objecto': 549,\n",
              " 'tendo': 550,\n",
              " 'imagem': 551,\n",
              " 'resolução': 552,\n",
              " 'cecy': 553,\n",
              " 'queria': 554,\n",
              " 'dôr': 555,\n",
              " 'can': 556,\n",
              " 'rochedo': 557,\n",
              " 'sublime': 558,\n",
              " 'tinha-se': 559,\n",
              " 'resto': 560,\n",
              " 'maior': 561,\n",
              " 'bom': 562,\n",
              " 'delles': 563,\n",
              " 'deixar': 564,\n",
              " 'possivel': 565,\n",
              " 'clavina': 566,\n",
              " 'galho': 567,\n",
              " 'joelhos': 568,\n",
              " 'estendeu': 569,\n",
              " 'segundo': 570,\n",
              " 'setta': 571,\n",
              " 'tal': 572,\n",
              " 'podesse': 573,\n",
              " 'deixava': 574,\n",
              " 'vinha': 575,\n",
              " 'queres': 576,\n",
              " 'sabes': 577,\n",
              " 'ti': 578,\n",
              " 'dirigio-se': 579,\n",
              " 'irmão': 580,\n",
              " 'entrou': 581,\n",
              " 'tanta': 582,\n",
              " 'thesouro': 583,\n",
              " 'affeição': 584,\n",
              " 'sorrio': 585,\n",
              " 'bastava': 586,\n",
              " 'receio': 587,\n",
              " 'horrivel': 588,\n",
              " 'corria': 589,\n",
              " 'margem': 590,\n",
              " 'servia': 591,\n",
              " 'uns': 592,\n",
              " 'dever': 593,\n",
              " 'daquelle': 594,\n",
              " 'replicou': 595,\n",
              " 'outras': 596,\n",
              " 'dentes': 597,\n",
              " 'longa': 598,\n",
              " 'ah': 599,\n",
              " 'algodão': 600,\n",
              " 'faca': 601,\n",
              " 'forão': 602,\n",
              " 'ouvio-se': 603,\n",
              " 'pobre': 604,\n",
              " 'lembrança': 605,\n",
              " 'chegado': 606,\n",
              " 'adormecida': 607,\n",
              " 'profundo': 608,\n",
              " 'estou': 609,\n",
              " 'nunes': 610,\n",
              " 'including': 611,\n",
              " 'full': 612,\n",
              " 'agree': 613,\n",
              " 'must': 614,\n",
              " 'we': 615,\n",
              " 'rei': 616,\n",
              " 'belleza': 617,\n",
              " 'edificio': 618,\n",
              " 'azul': 619,\n",
              " 'natural': 620,\n",
              " 'achava': 621,\n",
              " 'alta': 622,\n",
              " 'hombros': 623,\n",
              " 'estar': 624,\n",
              " 'sois': 625,\n",
              " 'lentamente': 626,\n",
              " 'onça': 627,\n",
              " 'redor': 628,\n",
              " 'comprehendeu': 629,\n",
              " 'principio': 630,\n",
              " 'correu': 631,\n",
              " 'maneira': 632,\n",
              " 'conhecer': 633,\n",
              " 'alegre': 634,\n",
              " 'acção': 635,\n",
              " 'tantos': 636,\n",
              " 'desejo': 637,\n",
              " 'raiva': 638,\n",
              " 'pensava': 639,\n",
              " 'nelle': 640,\n",
              " 'obrigado': 641,\n",
              " 'ouvindo': 642,\n",
              " 'levantou': 643,\n",
              " 'amigos': 644,\n",
              " 'at': 645,\n",
              " 'linda': 646,\n",
              " 'via-se': 647,\n",
              " 'larga': 648,\n",
              " 'profunda': 649,\n",
              " 'facto': 650,\n",
              " 'aspecto': 651,\n",
              " 'pennas': 652,\n",
              " 'banda': 653,\n",
              " 'fallar': 654,\n",
              " 'trazia': 655,\n",
              " 'cinta': 656,\n",
              " 'chegou': 657,\n",
              " 'chegar': 658,\n",
              " 'cousas': 659,\n",
              " 'hombro': 660,\n",
              " 'tigre': 661,\n",
              " 'abrio': 662,\n",
              " 'lindo': 663,\n",
              " 'desgraça': 664,\n",
              " 'ficar': 665,\n",
              " 'moças': 666,\n",
              " 'brancos': 667,\n",
              " 'aquelles': 668,\n",
              " 'desespero': 669,\n",
              " 'amava': 670,\n",
              " 'conseguio': 671,\n",
              " 'fitou': 672,\n",
              " 'partir': 673,\n",
              " 'lembrou-se': 674,\n",
              " 'cacique': 675,\n",
              " 'encontro': 676,\n",
              " 'nosso': 677,\n",
              " 'chegando': 678,\n",
              " 'partio': 679,\n",
              " 'mestre': 680,\n",
              " 'palmeira': 681,\n",
              " 'sacrificio': 682,\n",
              " 'access': 683,\n",
              " 'guarany': 684,\n",
              " 'precipicio': 685,\n",
              " 'ouro': 686,\n",
              " 'phrase': 687,\n",
              " 'procurava': 688,\n",
              " 'quaes': 689,\n",
              " 'baixa': 690,\n",
              " 'dentro': 691,\n",
              " 'ligeiro': 692,\n",
              " 'conversa': 693,\n",
              " 'folhagem': 694,\n",
              " 'seis': 695,\n",
              " 'sombras': 696,\n",
              " 'segunda': 697,\n",
              " 'trabalho': 698,\n",
              " 'flor': 699,\n",
              " 'elevava': 700,\n",
              " 'alli': 701,\n",
              " 'appareceu': 702,\n",
              " 'azues': 703,\n",
              " 'admiração': 704,\n",
              " 'paixão': 705,\n",
              " 'morto': 706,\n",
              " 'vinho': 707,\n",
              " 'lua': 708,\n",
              " 'orgulho': 709,\n",
              " 'fr': 710,\n",
              " 'guerreiro': 711,\n",
              " 'brazil': 712,\n",
              " 'extrema': 713,\n",
              " 'paquequer': 714,\n",
              " 'graça': 715,\n",
              " 'janellas': 716,\n",
              " 'acontecimentos': 717,\n",
              " 'cruz': 718,\n",
              " 'suave': 719,\n",
              " 'pode': 720,\n",
              " 'caso': 721,\n",
              " 'necessidade': 722,\n",
              " 'estais': 723,\n",
              " 'nossos': 724,\n",
              " 'ninguem': 725,\n",
              " 'cheio': 726,\n",
              " 'continuava': 727,\n",
              " 'tremula': 728,\n",
              " 'vulto': 729,\n",
              " 'direcção': 730,\n",
              " 'sentou-se': 731,\n",
              " 'sabe': 732,\n",
              " 'religião': 733,\n",
              " 'existencia': 734,\n",
              " 'tornou-se': 735,\n",
              " 'boa': 736,\n",
              " 'comprehendia': 737,\n",
              " 'ambos': 738,\n",
              " 'estremeceu': 739,\n",
              " 'pistolas': 740,\n",
              " 'afim': 741,\n",
              " 'crime': 742,\n",
              " 'comtudo': 743,\n",
              " 'levou': 744,\n",
              " 'emoção': 745,\n",
              " 'papel': 746,\n",
              " 'lhes': 747,\n",
              " 'fazião': 748,\n",
              " 'cima': 749,\n",
              " 'raça': 750,\n",
              " 'daquella': 751,\n",
              " 'distributing': 752,\n",
              " 'copies': 753,\n",
              " 'your': 754,\n",
              " 'fee': 755,\n",
              " 'paragraph': 756,\n",
              " 'which': 757,\n",
              " 'provide': 758,\n",
              " 'about': 759,\n",
              " 'refund': 760,\n",
              " 'somno': 761,\n",
              " 'obra': 762,\n",
              " 'fora': 763,\n",
              " 'deixando': 764,\n",
              " 'solidão': 765,\n",
              " 'espaço': 766,\n",
              " 'supremo': 767,\n",
              " \"outr'ora\": 768,\n",
              " 'longo': 769,\n",
              " 'habitação': 770,\n",
              " 'pertencia': 771,\n",
              " 'sou': 772,\n",
              " 'abysmo': 773,\n",
              " 'attenção': 774,\n",
              " 'estes': 775,\n",
              " 'modo': 776,\n",
              " 'chegava': 777,\n",
              " 'rapidez': 778,\n",
              " 'perdido': 779,\n",
              " 'fructos': 780,\n",
              " 'immovel': 781,\n",
              " 'corda': 782,\n",
              " 'digno': 783,\n",
              " 'alva': 784,\n",
              " 'nuvens': 785,\n",
              " 'vivo': 786,\n",
              " 'póde': 787,\n",
              " 'procurar': 788,\n",
              " 'vencer': 789,\n",
              " 'castigo': 790,\n",
              " 'differentes': 791,\n",
              " 'poderosa': 792,\n",
              " 'oleo': 793,\n",
              " 'virgem': 794,\n",
              " 'esperavão': 795,\n",
              " 'forças': 796,\n",
              " 'lingua': 797,\n",
              " 'realisar': 798,\n",
              " '«a': 799,\n",
              " 'combate': 800,\n",
              " 'ataque': 801,\n",
              " 'under': 802,\n",
              " 'located': 803,\n",
              " '*': 804,\n",
              " \"d'agua\": 805,\n",
              " 'rapido': 806,\n",
              " 'florestas': 807,\n",
              " 'anno': 808,\n",
              " 'direita': 809,\n",
              " 'formava': 810,\n",
              " 'teria': 811,\n",
              " 'graciosa': 812,\n",
              " 'inteiramente': 813,\n",
              " 'historia': 814,\n",
              " 'côres': 815,\n",
              " 'santo': 816,\n",
              " 'vinte': 817,\n",
              " 'pessoas': 818,\n",
              " 'voltava': 819,\n",
              " 'ouvir': 820,\n",
              " 'diz': 821,\n",
              " 'dormia': 822,\n",
              " 'devião': 823,\n",
              " 'nisto': 824,\n",
              " 'costas': 825,\n",
              " 'campos': 826,\n",
              " 'escravo': 827,\n",
              " 'ficava': 828,\n",
              " 'parou': 829,\n",
              " 'olha': 830,\n",
              " 'sahio': 831,\n",
              " 'mil': 832,\n",
              " 'terreiro': 833,\n",
              " 'saber': 834,\n",
              " 'apresentava': 835,\n",
              " 'tocou': 836,\n",
              " 'presença': 837,\n",
              " 'gritou': 838,\n",
              " 'ir': 839,\n",
              " 'hoje': 840,\n",
              " 'intelligencia': 841,\n",
              " 'relva': 842,\n",
              " 'olhava': 843,\n",
              " 'resolveu': 844,\n",
              " 'será': 845,\n",
              " 'espanto': 846,\n",
              " 'ferro': 847,\n",
              " 'resultado': 848,\n",
              " 'nação': 849,\n",
              " 'ararê': 850,\n",
              " 'desappareceu': 851,\n",
              " 'complices': 852,\n",
              " 'manda': 853,\n",
              " 'teus': 854,\n",
              " 'salvação': 855,\n",
              " 'começava': 856,\n",
              " 'tranquillo': 857,\n",
              " 'will': 858,\n",
              " 'law': 859,\n",
              " 'distribute': 860,\n",
              " 'without': 861,\n",
              " 'section': 862,\n",
              " 'have': 863,\n",
              " 'laws': 864,\n",
              " 'information': 865,\n",
              " 'romance': 866,\n",
              " 'brazileiro': 867,\n",
              " 'braças': 868,\n",
              " 'nossas': 869,\n",
              " 'cinco': 870,\n",
              " 'entrada': 871,\n",
              " 'largo': 872,\n",
              " 'prata': 873,\n",
              " 'palha': 874,\n",
              " 'objectos': 875,\n",
              " 'frio': 876,\n",
              " 'dado': 877,\n",
              " 'primeiros': 878,\n",
              " 'circulo': 879,\n",
              " 'dez': 880,\n",
              " 'defeza': 881,\n",
              " 'riqueza': 882,\n",
              " 'fructo': 883,\n",
              " 'cavalleiros': 884,\n",
              " 'vamos': 885,\n",
              " 'contrario': 886,\n",
              " 's': 887,\n",
              " 'faz': 888,\n",
              " 'chapéo': 889,\n",
              " 'cahia': 890,\n",
              " 'querer': 891,\n",
              " 'lançando': 892,\n",
              " 'pelle': 893,\n",
              " 'raios': 894,\n",
              " 'feroz': 895,\n",
              " 'linha': 896,\n",
              " 'ligeiramente': 897,\n",
              " 'eis': 898,\n",
              " 'tranquillamente': 899,\n",
              " 'vira': 900,\n",
              " 'folha': 901,\n",
              " 'saltou': 902,\n",
              " 'violenta': 903,\n",
              " 'dedos': 904,\n",
              " 'completamente': 905,\n",
              " 'lançou': 906,\n",
              " 'pescoço': 907,\n",
              " 'sonho': 908,\n",
              " 'irmã': 909,\n",
              " 'vio': 910,\n",
              " 'gibão': 911,\n",
              " 'bocca': 912,\n",
              " 'caracter': 913,\n",
              " 'sentado': 914,\n",
              " 'christão': 915,\n",
              " 'firmeza': 916,\n",
              " 'tristeza': 917,\n",
              " 'horizonte': 918,\n",
              " 'reflexo': 919,\n",
              " 'beijo': 920,\n",
              " 'unicamente': 921,\n",
              " 'fallava': 922,\n",
              " 'sentio-se': 923,\n",
              " 'meia': 924,\n",
              " 'socego': 925,\n",
              " 'ellas': 926,\n",
              " 'guarda': 927,\n",
              " 'estendia': 928,\n",
              " 'sobretudo': 929,\n",
              " 'sentimentos': 930,\n",
              " 'tocar': 931,\n",
              " 'fitos': 932,\n",
              " 'soffrer': 933,\n",
              " 'corrente': 934,\n",
              " 'perdão': 935,\n",
              " 'puro': 936,\n",
              " 'atravessou': 937,\n",
              " 'gritos': 938,\n",
              " 'apertou': 939,\n",
              " 'valente': 940,\n",
              " 'ama': 941,\n",
              " 'achavão': 942,\n",
              " 'semelhante': 943,\n",
              " 'levantou-se': 944,\n",
              " 'caminhou': 945,\n",
              " 'ouvia': 946,\n",
              " 'promessa': 947,\n",
              " 'roberio': 948,\n",
              " 'almas': 949,\n",
              " 'dera': 950,\n",
              " 'houve': 951,\n",
              " '«pery': 952,\n",
              " 'veneno': 953,\n",
              " 'bastante': 954,\n",
              " 'settas': 955,\n",
              " 'precisava': 956,\n",
              " 'anyone': 957,\n",
              " 'most': 958,\n",
              " 'tomo': 959,\n",
              " 'prova': 960,\n",
              " 'satisfação': 961,\n",
              " 'dir-se-hia': 962,\n",
              " 'ondas': 963,\n",
              " 'pontas': 964,\n",
              " 'cidade': 965,\n",
              " 'cerca': 966,\n",
              " 'oratorio': 967,\n",
              " 'mesa': 968,\n",
              " 'sofá': 969,\n",
              " 'prestes': 970,\n",
              " 'portuguez': 971,\n",
              " 'sá': 972,\n",
              " 'expedição': 973,\n",
              " 'combater': 974,\n",
              " 'juramento': 975,\n",
              " 'esperou': 976,\n",
              " 'fé': 977,\n",
              " 'além': 978,\n",
              " 'contar': 979,\n",
              " 'punhal': 980,\n",
              " 'animaes': 981,\n",
              " 'respondeo': 982,\n",
              " 'vêr': 983,\n",
              " 'acudio': 984,\n",
              " 'deixado': 985,\n",
              " 'ameaça': 986,\n",
              " 'nenhum': 987,\n",
              " 'energia': 988,\n",
              " 'superior': 989,\n",
              " 'cintura': 990,\n",
              " 'reflexos': 991,\n",
              " 'cujo': 992,\n",
              " 'ramo': 993,\n",
              " 'galhos': 994,\n",
              " 'consciencia': 995,\n",
              " 'matta': 996,\n",
              " 'sorria': 997,\n",
              " 'caça': 998,\n",
              " 'sereno': 999,\n",
              " 'pura': 1000}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Codificando e Decodificando sentenças"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode_sentence(sentence:Union[str,List[str]], vocab:Dict) -> List[int]:\n",
        "    if isinstance(sentence, list):\n",
        "        words = sentence\n",
        "    else:\n",
        "        words = sentence.split(\" \")\n",
        "    \n",
        "    return [vocab.get(word, 0) for word in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decode_sentence(encoding, inverse_vocab):\n",
        "    result = []\n",
        "\n",
        "    for encoding_i in encoding:\n",
        "        if encoding_i == 0:\n",
        "            result.append(\"???\")\n",
        "        else:\n",
        "            result.append(inverse_vocab[encoding_i-1])\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wia_ygbvzJ_J"
      },
      "source": [
        "## Classe do dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sequences(texts:List[str], context_size:int, \n",
        "                     vocab:Dict) -> Tuple[List[List[int]], List[int]]:\n",
        "\n",
        "\n",
        "    x_all = []\n",
        "    y_all = []\n",
        "\n",
        "    for paragraph in texts:\n",
        "        start = 0\n",
        "        end = context_size\n",
        "\n",
        "        paragraph = encode_sentence(paragraph, vocab)\n",
        "\n",
        "        while end < len(paragraph):\n",
        "            x = paragraph[start:end]\n",
        "            y = paragraph[end]\n",
        "\n",
        "            if not ( 0 in x or 0 == y):\n",
        "                x_all.append(x)\n",
        "                y_all.append(y)\n",
        "\n",
        "            start += 1\n",
        "            end += 1\n",
        "            \n",
        "    x_all = np.array(x_all)\n",
        "    y_all = np.array(y_all)\n",
        "\n",
        "    return x_all, y_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_context_size = 10\n",
        "\n",
        "test_x_all, test_y_all = create_sequences(cleaned_paragraphs, test_context_size, test_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert len(test_x_all) == len(test_y_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gC0C5qn2zJ_J"
      },
      "outputs": [],
      "source": [
        "#Embaralhando para evitar viés\n",
        "\n",
        "def shuffle_dataset(x:List, y:List) -> Tuple[List, List]:\n",
        "\n",
        "    indexes = list(range(len(x)))\n",
        "    random.shuffle(indexes)\n",
        "\n",
        "    x = x[indexes]\n",
        "    y = y[indexes]\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def separate_dataset(x_all:List, y_all:List) -> Tuple[Tuple[List, List], Tuple[List, List], Tuple[List, List]]:\n",
        "    size_all = len(x_all)\n",
        "\n",
        "    cut1 = int(0.6*size_all)\n",
        "    cut2 = int(0.8*size_all)\n",
        "\n",
        "    x_train = x_all[0:cut1]\n",
        "    y_train = y_all[0:cut1]\n",
        "\n",
        "    x_val = x_all[cut1:cut2]\n",
        "    y_val = y_all[cut1:cut2]\n",
        "\n",
        "    x_test = x_all[cut2:]\n",
        "    y_test = y_all[cut2:]\n",
        "\n",
        "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "(test_x_train, test_y_train), (test_x_val, test_y_val), (test_x_test, test_y_test) = separate_dataset(test_x_all, test_y_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert len(test_x_train)+len(test_x_val)+len(test_x_test) == len(test_x_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TextPredictDataset(Dataset):\n",
        "    def __init__(self, x_data:List[int], y_data:List[int]):\n",
        "        self._x_data = torch.tensor(x_data)-1\n",
        "        self._y_data = torch.tensor(y_data, dtype=torch.int64)-1\n",
        "        \n",
        "        if len(x_data) != len(y_data):\n",
        "            raise ValueError(f\"x_data and y_data must have same size. ({len(x_data)} ≠ {len(y_data)})\")\n",
        "        \n",
        "        self._size = len(x_data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self._x_data[idx], self._y_data[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_train_dataset = TextPredictDataset(test_x_train, test_y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert_array_equal(test_train_dataset[0][0].shape, [test_context_size])\n",
        "assert_array_equal(test_train_dataset[0][1].shape, [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_batch_size = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_train_loader = DataLoader(test_train_dataset, batch_size=test_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = next(iter(test_train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert_array_equal(test_data[0].shape, [test_batch_size, test_context_size])\n",
        "assert_array_equal(test_data[1].shape, [test_batch_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Juntando tudo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_data_loaders(texts:List[str], vocab_size:int, context_size:int, batch_size:int) -> Tuple[Dict, List, DataLoader, DataLoader, DataLoader]:\n",
        "    word_counts = count_words(texts)\n",
        "    vocab, inverse_vocab = create_vocab(word_counts, vocab_size)\n",
        "\n",
        "    x_all, y_all = create_sequences(texts, context_size, vocab)\n",
        "    \n",
        "    x_all, y_all = shuffle_dataset(x_all, y_all)\n",
        "\n",
        "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = separate_dataset(x_all, y_all)\n",
        "\n",
        "    train_dataset = TextPredictDataset(x_train, y_train)\n",
        "    val_dataset = TextPredictDataset(x_val, y_val)\n",
        "    test_dataset = TextPredictDataset(x_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return vocab, inverse_vocab, train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5_-Yud0zJ_K"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SingleHeadAttentionBase(torch.nn.Module, abc.ABC):\n",
        "    def __init__(self, embed_dim:int) -> None:\n",
        "        super().__init__()\n",
        "        \n",
        "        #d_model = dv = dk = embed_dim\n",
        "        #h = 1\n",
        "\n",
        "        wQ = torch.Tensor(embed_dim, embed_dim) #embed, embed\n",
        "        wK = torch.Tensor(embed_dim, embed_dim) #embed, dk\n",
        "        wV = torch.Tensor(embed_dim, embed_dim) #embed, dv\n",
        "        w0 = torch.Tensor(embed_dim, embed_dim) #embed, embed\n",
        "\n",
        "        self.wQ = torch.nn.Parameter(wQ)\n",
        "        self.wK = torch.nn.Parameter(wK)\n",
        "        self.wV = torch.nn.Parameter(wV)\n",
        "        self.w0 = torch.nn.Parameter(w0)\n",
        "\n",
        "        self.register_buffer(\"dk_root\", torch.sqrt(torch.tensor(embed_dim, dtype=torch.float32)))\n",
        "\n",
        "        for w in [self.wQ, self.wK, self.wV, self.w0]:\n",
        "            torch.nn.init.xavier_uniform_(w)\n",
        "    \n",
        "    @abc.abstractmethod\n",
        "    def forward(self, query:torch.Tensor, key:torch.Tensor, value:torch.Tensor) -> torch.Tensor:\n",
        "        ...\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SingleHeadAttention(SingleHeadAttentionBase):\n",
        "\n",
        "    def __init__(self, embed_dim: int) -> None:\n",
        "        super().__init__(embed_dim)\n",
        "\n",
        "    def forward(self, query:torch.Tensor, key:torch.Tensor, value:torch.Tensor) -> torch.Tensor:        \n",
        "        #Transpose weights because PyTorch does that\n",
        "        Q = query @ self.wQ.T\n",
        "        K = key @ self.wK.T\n",
        "        V = value @ self.wV.T\n",
        "\n",
        "        scores = Q @ K.permute(0,2,1)\n",
        "        scores /= self.dk_root\n",
        "        probs = torch.softmax(scores, dim=-1)\n",
        "        E = probs @ V\n",
        "\n",
        "        result = E @ self.w0.T \n",
        "\n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SingleHeadAttentionLoop(SingleHeadAttentionBase):\n",
        "    def __init__(self, embed_dim: int) -> None:\n",
        "        super().__init__(embed_dim)\n",
        "\n",
        "\n",
        "    def forward(self, query:torch.Tensor, key:torch.Tensor, value:torch.Tensor) -> torch.Tensor:\n",
        "        batch_size = query.shape[0]\n",
        "        sequence_size = query.shape[1]\n",
        "        \n",
        "        result = torch.empty_like(query)\n",
        "        scores = torch.empty(sequence_size, device=query.device)\n",
        "\n",
        "        for batch_index in range(batch_size):\n",
        "            for word_index in range(sequence_size):\n",
        "                xq = query[batch_index, word_index]\n",
        "                q = xq @ self.wQ.T\n",
        "                \n",
        "                for key_index in range(sequence_size):\n",
        "                    xk = key[batch_index][key_index]\n",
        "                    k = xk @ self.wK.T\n",
        "                    score = q @ k.T\n",
        "                    scores[key_index] = score\n",
        "                \n",
        "                scores /= self.dk_root\n",
        "                probs = torch.softmax(scores, dim=-1)\n",
        "\n",
        "                e = 0\n",
        "                for xv, p in zip(value[batch_index], probs):\n",
        "                    v = xv @ self.wV.T\n",
        "                    e += p*v\n",
        "                \n",
        "                e = e @ self.w0.T\n",
        "\n",
        "                result[batch_index, word_index] = e\n",
        "\n",
        "        return result\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_embed_dim = 5\n",
        "matrix_version = SingleHeadAttention(test_embed_dim).eval()\n",
        "loop_version = SingleHeadAttentionLoop(test_embed_dim).eval()\n",
        "torch_version = torch.nn.MultiheadAttention(test_embed_dim, num_heads=1, bias=False, batch_first=True).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "wQ = matrix_version.wQ\n",
        "wK = matrix_version.wK\n",
        "wV = matrix_version.wV\n",
        "w0 = matrix_version.w0\n",
        "\n",
        "loop_version.wQ = wQ\n",
        "loop_version.wK = wK\n",
        "loop_version.wV = wV\n",
        "loop_version.w0 = w0\n",
        "\n",
        "torch_version.in_proj_weight = torch.nn.Parameter(torch.concat((wQ, wK, wV)))\n",
        "torch_version.out_proj.weight = w0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = torch.rand(2, 3, test_embed_dim) #2 batchs, sequences of 3 words, embed_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-31-b756e465b0fe>:21: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3641.)\n",
            "  score = q @ k.T\n"
          ]
        }
      ],
      "source": [
        "result_matrix = matrix_version(test_data, test_data, test_data)\n",
        "result_loop = loop_version(test_data, test_data, test_data)\n",
        "result_torch, _ = torch_version(test_data, test_data, test_data, need_weights=False)\n",
        "\n",
        "result_matrix = result_matrix.detach()\n",
        "result_loop = result_loop.detach()\n",
        "result_torch = result_torch.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert result_matrix.shape == result_torch.shape\n",
        "assert result_loop.shape == result_torch.shape\n",
        "\n",
        "assert_array_almost_equal(result_matrix, result_torch, decimal=5)\n",
        "assert_array_almost_equal(result_matrix, result_loop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%timeit matrix_version(test_data, test_data, test_data)\n",
        "#%timeit loop_version(test_data, test_data, test_data)\n",
        "#%timeit torch_version(test_data, test_data, test_data, need_weights=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Matrix: 112 µs ± 1.77 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\\\n",
        "Loop: 1.79 ms ± 15.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\\\n",
        "Torch: 218 µs ± 4.81 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SinePositionalEncoding(torch.nn.Module):\n",
        "    def __init__(self, embed_dim:int, sequence_size:int) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        position = torch.arange(sequence_size, dtype=torch.float32)\n",
        "        expoent = 2.0*torch.arange(embed_dim, dtype=torch.float32)/embed_dim\n",
        "\n",
        "        pe = torch.empty((sequence_size, embed_dim))\n",
        "\n",
        "        pe.T[:] = position\n",
        "        pe /= torch.pow(1e4, expoent)\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(pe[:, 0::2])\n",
        "        pe[:, 1::2] = torch.cos(pe[:, 1::2])\n",
        "\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, input_tensor:torch.Tensor) -> torch.Tensor:\n",
        "        output = input_tensor + self.pe\n",
        "\n",
        "        return output\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_embed_dim = 5\n",
        "test_sequence_size = 3\n",
        "\n",
        "test_data = torch.zeros(2, test_sequence_size, test_embed_dim) #2 batchs, sequences of 3 words, embed_dim\n",
        "\n",
        "positional_encoding = SinePositionalEncoding(test_embed_dim, test_sequence_size)\n",
        "\n",
        "result = positional_encoding(test_data)\n",
        "\n",
        "assert_array_equal(result[0], result[1]) #Correct operation across batchs\n",
        "assert_array_not_equal(result[0, 0], result[0, 1]) #Different positions -> Different encodings\n",
        "assert_array_not_equal(result[0,:,0], result[0,:,1]) #Different dimensions -> Different encodings\n",
        "assert len(list(positional_encoding.parameters())) == 0 #No trainable parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Embedding(torch.nn.Module):\n",
        "    def __init__(self, embed_dim:int, vocab_size:int) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        C = torch.Tensor(vocab_size, embed_dim)\n",
        "        nn.init.xavier_uniform_(C)\n",
        "        self.C = torch.nn.Parameter(C)\n",
        "\n",
        "    def forward(self, input_tensor:torch.Tensor) -> torch.Tensor:\n",
        "        #OBS: I checked, \"index_select\" doesn't work with batchs, \"index\" (third parameter) must be 1-D\n",
        "        result = torch.stack([torch.index_select(self.C, 0, input_i) for input_i in input_tensor])\n",
        "        \n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_embed_dim = 2\n",
        "test_vocab_size = 3\n",
        "test_sequence_size = test_vocab_size\n",
        "\n",
        "test_data = torch.empty((2, test_sequence_size), dtype=int)\n",
        "test_data[:] = torch.arange(test_vocab_size)\n",
        "\n",
        "embedding = Embedding(test_embed_dim, test_vocab_size)\n",
        "\n",
        "result = embedding(test_data)\n",
        "result = result.detach()\n",
        "\n",
        "C = embedding.C.detach()\n",
        "\n",
        "assert_array_equal(C.shape, [test_vocab_size, test_embed_dim]) #C matrix have correct shape\n",
        "assert_array_equal(result.shape, [2, test_sequence_size, test_embed_dim])\n",
        "assert_array_equal(result[0], result[1]) #Correct operation across batchs\n",
        "assert_array_equal(result[0, 0], C[0]) #First result = embedding of first word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "I2qKG9YczJ_K"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "    def __init__(self, embed_dim:int, vocab_size:int, sequence_size:int, droput_rate:float=0.0) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = Embedding(embed_dim, vocab_size)\n",
        "\n",
        "        self.positional_encoding = SinePositionalEncoding(embed_dim, sequence_size)\n",
        "        self.dropout_encoding = torch.nn.Dropout(droput_rate)\n",
        "\n",
        "        self.attention = SingleHeadAttention(embed_dim)\n",
        "        self.dropout_attention = torch.nn.Dropout(droput_rate)\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(embed_dim, 4*embed_dim)\n",
        "        self.dropout_linear1 = torch.nn.Dropout(droput_rate)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(4*embed_dim, embed_dim)\n",
        "        self.dropout_linear2 = torch.nn.Dropout(droput_rate)\n",
        "\n",
        "        self.linear_out = torch.nn.Linear(sequence_size*embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
        "        y = self.embedding(x)\n",
        "        y = self.dropout_encoding(self.positional_encoding(y))\n",
        "        y = self.dropout_attention(self.attention(y, y, y))\n",
        "\n",
        "        y = self.dropout_linear1(self.linear1(y))\n",
        "        y = self.dropout_linear2(self.linear2(y))\n",
        "\n",
        "        #Linears inside encoders(above): equal for every position (Attention is all you need)\n",
        "        #Linear for output: use the entery sequence -> Flatten\n",
        "        y = y.flatten(start_dim=1)\n",
        "        \n",
        "        y = self.linear_out(y)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "7yjQ1KXOzJ_K"
      },
      "outputs": [],
      "source": [
        "test_batch_size = 5\n",
        "test_embed_dim = 2\n",
        "test_vocab_size = 3\n",
        "test_sequence_size = test_vocab_size\n",
        "\n",
        "test_model = LanguageModel(test_embed_dim, test_vocab_size, test_sequence_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xmsD59TfzJ_K"
      },
      "outputs": [],
      "source": [
        "test_data = torch.empty((test_batch_size, test_sequence_size), dtype=int)\n",
        "test_data[:] = torch.arange(test_sequence_size)\n",
        "\n",
        "inputs = test_data\n",
        "targets = test_vocab_size*torch.rand(test_batch_size).long()\n",
        "\n",
        "output = test_model(inputs)\n",
        "result = output.argmax(dim=1)\n",
        "\n",
        "assert_array_equal(output.shape, [test_batch_size, test_vocab_size])\n",
        "assert_array_equal(result.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "old_C = test_model.embedding.C.detach().numpy().copy()\n",
        "old_wQ = test_model.attention.wQ.detach().numpy().copy()\n",
        "old_wK = test_model.attention.wK.detach().numpy().copy()\n",
        "old_wV = test_model.attention.wV.detach().numpy().copy()\n",
        "old_w0 = test_model.attention.w0.detach().numpy().copy()\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(test_model.parameters(), lr=100)\n",
        "\n",
        "test_model.train()\n",
        "\n",
        "logits = test_model(inputs)\n",
        "loss = criterion(logits.squeeze(), targets)\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "new_C = test_model.embedding.C.detach().numpy()\n",
        "new_wQ = test_model.attention.wQ.detach().numpy()\n",
        "new_wK = test_model.attention.wK.detach().numpy()\n",
        "new_wV = test_model.attention.wV.detach().numpy()\n",
        "new_w0 = test_model.attention.w0.detach().numpy()\n",
        "\n",
        "assert_array_not_equal(old_C, new_C)\n",
        "assert_array_not_equal(old_wQ, new_wQ) \n",
        "assert_array_not_equal(old_wK, new_wK)\n",
        "assert_array_not_equal(old_wV, new_wV)\n",
        "assert_array_not_equal(old_w0, new_w0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UngUhyu7zJ_L"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wntaV50nzJ_L",
        "outputId": "a054092b-d801-4c60-eb75-85abfe57151d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ppl(loss:torch.Tensor) -> torch.Tensor:\n",
        "    return torch.exp(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_loss(model:torch.nn.Module, loader:DataLoader, criterion:torch.nn.Module) -> torch.Tensor:\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        n = 0\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            logits = model(inputs)\n",
        "            loss = criterion(logits.squeeze(), targets)\n",
        "            total_loss += loss*targets.size(0)\n",
        "\n",
        "            n += targets.size(0)\n",
        "\n",
        "        total_loss /= n \n",
        "    \n",
        "    return total_loss.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_info(loss_value:torch.Tensor, epoch:int, total_epochs:int, time:float=0.0):\n",
        "    ppl_value = ppl(loss_value)\n",
        "\n",
        "    \n",
        "    print(f'Epoch [{epoch+1}/{total_epochs}], \\\n",
        "            Loss: {loss_value.item():.4f}, \\\n",
        "            Perplexity: {ppl_value.item():.4f}', end=\"\")\n",
        "    \n",
        "    if time != 0:\n",
        "        print(f\", Elapsed Time: {time:.2f} sec\")    \n",
        "    else:\n",
        "        print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-50-e4c8e09828d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "raise ValueError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32 # Tamanho do batch\n",
        "context_size = 7 # n palavras de entrada. O target é a próxima palavra\n",
        "dropout_rate = 0.15 #Dropout entre as camadas\n",
        "embed_dim = 64 # Tamanho do feature vector de cada palavra\n",
        "epochs = 10 # Quantidade de epochs que serão treinadas\n",
        "lr = 2.5e-3 # Taxa de treinamento\n",
        "optimizer_class = torch.optim.Adam #torch.optim.SGD\n",
        "vocab_size = 3000 # Quantidade de palavras no vocabulário\n",
        "weight_decay = 3e-4 # Regularização L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_wandb = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [],
      "source": [
        "reset_seeds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab, inverse_vocab, train_loader, val_loader, test_loader = create_data_loaders(cleaned_paragraphs, vocab_size, context_size, batch_size)\n",
        "\n",
        "model = LanguageModel(embed_dim, vocab_size, context_size, dropout_rate)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optimizer_class(model.parameters(), lr=lr, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x169d02153d0>"
            ]
          },
          "execution_count": 260,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.autograd.set_detect_anomaly(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"vocab_size\": vocab_size,\n",
        "    \"context_size\": context_size,\n",
        "    \"embed_dim\": embed_dim,\n",
        "    \"epochs\": epochs,\n",
        "    \"lr\": lr,\n",
        "    \"weight_decay\": weight_decay,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"optimizer_class\": optimizer_class.__name__,\n",
        "    \"dropout_rate\": dropout_rate\n",
        "}\n",
        "\n",
        "if use_wandb:\n",
        "    wandb.init(project=\"IA024-03-Attention\", config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/10],             Loss: 8.0143,             Perplexity: 3023.8267\n",
            "Epoch [1/10],             Loss: 6.2031,             Perplexity: 494.2632, Elapsed Time: 2.82 sec\n",
            "VAL Epoch [1/10],             Loss: 5.8949,             Perplexity: 363.1829\n",
            "Epoch [2/10],             Loss: 5.7422,             Perplexity: 311.7361, Elapsed Time: 2.75 sec\n",
            "VAL Epoch [2/10],             Loss: 5.5307,             Perplexity: 252.3127\n",
            "Epoch [3/10],             Loss: 5.4305,             Perplexity: 228.2554, Elapsed Time: 2.78 sec\n",
            "VAL Epoch [3/10],             Loss: 5.3822,             Perplexity: 217.5072\n",
            "Epoch [4/10],             Loss: 5.2086,             Perplexity: 182.8447, Elapsed Time: 2.77 sec\n",
            "VAL Epoch [4/10],             Loss: 5.3663,             Perplexity: 214.0685\n",
            "Epoch [5/10],             Loss: 5.0461,             Perplexity: 155.4149, Elapsed Time: 2.76 sec\n",
            "VAL Epoch [5/10],             Loss: 5.1948,             Perplexity: 180.3368\n",
            "Epoch [6/10],             Loss: 4.9175,             Perplexity: 136.6538, Elapsed Time: 2.79 sec\n",
            "VAL Epoch [6/10],             Loss: 5.1275,             Perplexity: 168.5968\n",
            "Epoch [7/10],             Loss: 4.8005,             Perplexity: 121.5723, Elapsed Time: 2.76 sec\n",
            "VAL Epoch [7/10],             Loss: 5.1438,             Perplexity: 171.3740\n",
            "Epoch [8/10],             Loss: 4.6898,             Perplexity: 108.8362, Elapsed Time: 2.86 sec\n",
            "VAL Epoch [8/10],             Loss: 5.1364,             Perplexity: 170.1068\n",
            "Epoch [9/10],             Loss: 4.6118,             Perplexity: 100.6604, Elapsed Time: 2.75 sec\n",
            "VAL Epoch [9/10],             Loss: 5.1562,             Perplexity: 173.5083\n",
            "Epoch [10/10],             Loss: 4.5280,             Perplexity: 92.5730, Elapsed Time: 2.78 sec\n",
            "VAL Epoch [10/10],             Loss: 5.1332,             Perplexity: 169.5616\n"
          ]
        }
      ],
      "source": [
        "hist = {}\n",
        "hist[\"loss_train\"] = []\n",
        "hist[\"loss_val\"] = []\n",
        "hist[\"ppl_train\"] = []\n",
        "hist[\"ppl_val\"] = []\n",
        "\n",
        "prev_loss = compute_loss(model, train_loader, criterion)\n",
        "print_info(prev_loss, -1, epochs, 0)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time() \n",
        "\n",
        "    model.train()\n",
        "\n",
        "    loss_train = torch.tensor(0, dtype=torch.float32, device=device)\n",
        "    n_train = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        logits = model(inputs)\n",
        "        loss : torch.Tensor = criterion(logits.squeeze(), targets)\n",
        "\n",
        "        loss_train += loss*targets.size(0)\n",
        "        n_train += targets.size(0)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    end_time = time.time() \n",
        "    epoch_duration = end_time - start_time \n",
        "\n",
        "    loss_train /= n_train\n",
        "    ppl_train = ppl(loss_train)\n",
        "\n",
        "    print_info(loss_train, epoch, epochs, epoch_duration)\n",
        "    \n",
        "    print(\"VAL \", end=\"\")\n",
        "    loss_val = compute_loss(model, val_loader, criterion)\n",
        "    ppl_val = ppl(loss_val)\n",
        "    print_info(loss_val, epoch, epochs)\n",
        "\n",
        "    hist[\"loss_train\"].append(loss_train.item())\n",
        "    hist[\"loss_val\"].append(loss_val.item())\n",
        "    hist[\"ppl_train\"].append(ppl_train.item())\n",
        "    hist[\"ppl_val\"].append(ppl_val.item())\n",
        "\n",
        "    log = {\n",
        "        \"loss_train\": loss_train.item(),\n",
        "        \"loss_val\": loss_val.item(),\n",
        "        \"ppl_train\": ppl_train.item(),\n",
        "        \"ppl_val\": ppl_val.item()\n",
        "    }\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.log(log)\n",
        "\n",
        "for key in hist:\n",
        "    hist[key] = np.array(hist[key])\n",
        "\n",
        "if use_wandb:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(hist[\"loss_train\"], \"o-\")\n",
        "plt.plot(hist[\"loss_val\"], \"o-\")\n",
        "\n",
        "plt.legend([\"Train\", \"Val\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss history\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(hist[\"ppl_train\"]/vocab_size, \"o-\")\n",
        "plt.plot(hist[\"ppl_val\"]/vocab_size, \"o-\")\n",
        "\n",
        "plt.legend([\"Train\", \"Val\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Normalized PPL\")\n",
        "plt.title(\"Perplexity history\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-265-e4c8e09828d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "raise ValueError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSXfwYISDoPN"
      },
      "source": [
        "## Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXXO78GSDqPg"
      },
      "outputs": [],
      "source": [
        "test_loss = compute_loss(model, test_loader, criterion)\n",
        "test_ppl = ppl(test_loss)\n",
        "\n",
        "test_ppl.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1zhxVqfzJ_M"
      },
      "source": [
        "## Exemplo de uso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PExkoWOzJ_M"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, vocab:Dict, inverse_vocab:List, text:str, max_length:int):\n",
        "    text = clean_text(text)\n",
        "\n",
        "    total_length = len(text.split(\" \"))\n",
        "\n",
        "    last_sequence = create_sequences([text], context_size, vocab)[0][-1]\n",
        "    last_sequence = torch.tensor(last_sequence)-1\n",
        "    last_sequence = last_sequence.to(device)\n",
        "\n",
        "    new_characters = []\n",
        "\n",
        "    while total_length < max_length:\n",
        "        \n",
        "        output = model(torch.unsqueeze(last_sequence, 0))\n",
        "        \n",
        "        next_encoded = output.argmax(dim=1).item()\n",
        "\n",
        "        last_sequence = torch.cat((last_sequence[1:], torch.tensor([next_encoded]).to(device)))\n",
        "        \n",
        "        new_characters.append(next_encoded)\n",
        "\n",
        "        total_length += 1\n",
        "\n",
        "    new_characters = np.array(new_characters)+1\n",
        "\n",
        "    new_text = \" \".join(decode_sentence(new_characters, inverse_vocab))\n",
        "\n",
        "    return new_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OLD\n",
            "- - tu não abandonarás tua senhora , não é ? disse ella passando a\n",
            "\n",
            "GENERATED CONTINUATION\n",
            "a sua senhora , e a sua mãi , e a sua mãi , e a sua mãi , e a sua mãi , e\n"
          ]
        }
      ],
      "source": [
        "text = cleaned_paragraphs[300]\n",
        "max_length = 40\n",
        "\n",
        "new_text = generate_text(model, vocab, inverse_vocab, text, max_length)\n",
        "\n",
        "print(\"OLD\")\n",
        "print(text)\n",
        "print(\"\")\n",
        "print(\"GENERATED CONTINUATION\")\n",
        "print(new_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
