{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMI0JT_YuYF3"
      },
      "source": [
        "## Exercício: Modelo de Linguagem com auto-atenção e máscaras causais\n",
        "\n",
        "> Seguimos na mesma linha de treinar um modelo de linguagem a partir dos textos do livro \"O Guarani\", de José de Alencar.\n",
        "> \n",
        "> Neste exercício, vamos treinar um modelo de linguagem com auto-atenção e com máscara causal. A máscara causal é necessária para que o modelo não tenha acesso a palavras futuras, que é a abordagem usada por grandes modelos de linguagem, como o GPT.\n",
        "> \n",
        "> Use a implementação matricial de auto-atenção da aula passada.\n",
        "> \n",
        "> ### Modificações necessárias\n",
        "> \n",
        "> - [x] Adicione a máscara causal na função `forward` da cabeça de auto-atenção.\n",
        "> - [x] Modifique o nosso dataloader para retornar inputs (uma lista de tokens de tamanho $n$), targets (uma lista de tokens de tamanho $n$ deslocada para a esquerda em 1 token). Exemplo `input = [1, 2, 3, 4]`, `target = [2, 3, 4, 5]` para a sequência `[1, 2, 3, 4, 5]` com `seq_len=4`, por exemplo (Ver slide 50).\n",
        "> \n",
        "> ### Extra\n",
        "> - [x] MultiHeadAttention: modifique a cabeça de auto-atenção para ter múltiplas cabeças. Isso não é obrigatório, mas pode ser interessante para ver como o modelo se comporta.\n",
        "> - [ ] Diagrama da geração: fazer diagrama que mostre os passos da geração de tokens (conforme slide 47).\n",
        "> \n",
        "> ### Dicas\n",
        "> \n",
        "> * Use como base o vídeo do Karpathy: https://www.youtube.com/watch?v=kCc8FmEb1nY. Observe que, no vídeo, ele primeiro implementa um modelo bi-grama, depois um modelo de linguagem com auto-atenção. O modelo de auto-atenção é implementado por volta do minuto 40, mas vale a pena assistir o vídeo todo.\n",
        "> * Use esta implementação como base: https://colab.research.google.com/drive/1vFTg4MSXVJwNSzPjaCcvmqhxTP7gK7HA?usp=sharing. Observe como o modelo é organizado e como a máscara é implementada na classe MultiHeadAttention.\n",
        "> * Use `context_size=9`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este notebook irá mostrar o processo de criação de um modelo de linguagem utilizando um transformer decoder-only, com processo de atenção multi-cabeça e máscara causal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Iremos começar importando os módulos que serão utilizados na atividade:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string # Manipular strings\n",
        "from collections import Counter # Fazer contagem de elementos\n",
        "import random # Operações randômicas\n",
        "import os # Manipular arquivos\n",
        "import time # Medição de tempo\n",
        "import abc # Classes abstratas\n",
        "import itertools # Iterators\n",
        "from typing import List, Dict, Union, Tuple # Type hints\n",
        "\n",
        "import numpy as np # Operações vetoriais\n",
        "from numpy.testing import assert_raises, assert_array_equal, assert_array_almost_equal # Testes\n",
        "from numpy.typing import ArrayLike # Type hints\n",
        "import torch # ML\n",
        "from torch.utils.data import Dataset, DataLoader # Preparação de dados\n",
        "import matplotlib.pyplot as plt # Plots\n",
        "import wandb # Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E algumas funções auxiliares que serão utilizadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def assert_array_not_equal(array1:ArrayLike, array2:ArrayLike) -> None:\n",
        "    \"\"\"\n",
        "    Raises an AssertionError if two array_like objects are equal.\n",
        "\n",
        "    Args:\n",
        "        array1 (ArrayLike): First array to check.\n",
        "        array2 (ArrayLike): Second array to check.\n",
        "    \"\"\"\n",
        "    assert_raises(AssertionError, assert_array_equal, array1, array2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reset_seeds() -> None:\n",
        "    \"\"\"\n",
        "    Resets the random generators from random and torch to a fixed seed.\n",
        "    \"\"\"\n",
        "    random.seed(18)\n",
        "    torch.manual_seed(18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparação dos dados.\n",
        "\n",
        "Nesta seção serão definidas funções para preparar os dados para treino do modelo. Devido a necessidade de alterar os parâmetros constantemente durante os experimentos de treino, são definidas em funções as operações que são necessárias. Exemplos são executados para mostrar o funcionamento correto das operações."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYbkEzdD37sZ"
      },
      "source": [
        "### Faz download e carrega o dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nesta seção os dados serão transferidos, lidos e limpos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O primeiro passo é realizar o download dos dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qAnqY_q0beK",
        "outputId": "f810fdb0-138d-4917-b7ef-69ab266acef6"
      },
      "outputs": [],
      "source": [
        "if not os.path.isfile(\"67724.txt.utf-8\"):\n",
        "    !curl -LO https://www.gutenberg.org/ebooks/67724.txt.utf-8\n",
        "\n",
        "if not os.path.isfile(\"67725.txt.utf-8\"):\n",
        "    !curl -LO https://www.gutenberg.org/ebooks/67725.txt.utf-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seguido pela leitura:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_UzC9pV091C",
        "outputId": "1553b04f-24c4-4027-8cab-0907f92f04df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4971"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = open(\"67724.txt.utf-8\",\"r\", encoding=\"utf8\").read()\n",
        "text += open(\"67725.txt.utf-8\",\"r\", encoding=\"utf8\").read()\n",
        "\n",
        "paragraphs = text.split(\"\\n\\n\")\n",
        "len(paragraphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E limpeza dos dados.\n",
        "\n",
        "São realizadas as seguintes operações seguindo o paper \"A Neural Probabilistic Language Model\"\n",
        "\n",
        "\n",
        "- Pontuação: é mantida, porém separada do texto para permitir criação de símbolos próprios no vocabulário, e evitar a criação de várias símbolos representando as palavras com pontuação (\"pontuação\" -> \"pontuação\" + \",\" )\n",
        "- Número: convertidos para símbolo especial. No caso todos os números são convertidos para \"999\", para que convirjam para o mesmo símbolo no vocabulário\n",
        "- Letras maiúsculas: convertidas para minúsculas.\n",
        "- Nomes próprios: não são alterados devido a necessidade de serem identificados, diferente do paper.\n",
        "- Palavras raras: são removidas ao criar o vocabulário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text:str) -> str:\n",
        "    '''\n",
        "    Clean the text, changing upper case and setting numbers to 999.\n",
        "    '''\n",
        "    \n",
        "    text = text.lower() # Upper Case -> lower case\n",
        "    \n",
        "    old_text = text.split()\n",
        "    new_text = []\n",
        "\n",
        "    for j in range(len(old_text)):\n",
        "        word = old_text[j] \n",
        "\n",
        "        if word.isdigit(): #Number -> 999\n",
        "            word = \"999\"\n",
        "        elif len(word) > 1 and word[0] in string.punctuation: # Ponctuation -> separate\n",
        "            old_text.insert(j+1, word[1:])\n",
        "            word = word[0]\n",
        "        elif word[-1] in string.punctuation and len(word) > 1: # Ponctuation -> separate\n",
        "            old_text.insert(j+1, word[:-1])\n",
        "            old_text.insert(j+2, word[-1])\n",
        "            \n",
        "            word = \"\"\n",
        "        \n",
        "        if len(word) > 0: # No empty words\n",
        "            new_text.append(word)\n",
        "    \n",
        "    return \" \".join(new_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhUFjtNdDuG0",
        "outputId": "78798c0c-deca-4454-d3fb-7d3ba70f3e91"
      },
      "outputs": [],
      "source": [
        "cleaned_paragraphs = [paragraph.replace(\"\\n\", \" \") for paragraph in paragraphs if paragraph.strip()] # Removes \\n\n",
        "\n",
        "for i in range(len(cleaned_paragraphs)):\n",
        "    cleaned_paragraphs[i] = clean_text(cleaned_paragraphs[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos ver um exemplo de parágrafo limpo do dataset, junto com a quantidade total de parágrafos obtidos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAMPLE ----------------\n",
            "﻿the project gutenberg ebook of o guarany : romance brazileiro , vol . 999 ( of 999 ) this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with almost no restrictions whatsoever . you may copy it , give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org . if you are not located in the united states , you\n",
            "---------------------\n",
            "4892\n"
          ]
        }
      ],
      "source": [
        "print(\"SAMPLE ----------------\")\n",
        "print(cleaned_paragraphs[0])\n",
        "print(\"---------------------\")\n",
        "\n",
        "print(len(cleaned_paragraphs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFVN2ihb33Rf"
      },
      "source": [
        "### Análise do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aqui iremos realizar a contagem de palavras no dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSRHqe3H4ZFw",
        "outputId": "4a985c7a-ce1d-4b72-d253-c9fbbc5f9440"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11470"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def count_words(texts:List[str]) -> Counter:\n",
        "    \"\"\"\n",
        "    Counts the words in the texts.\n",
        "\n",
        "    Args:\n",
        "        texts (List[str]): List of strings with the texts.\n",
        "\n",
        "    Returns:\n",
        "        Counter: counter with the word count across all texts.\n",
        "    \"\"\"\n",
        "    \n",
        "    word_counts = Counter()\n",
        "    for text in texts:\n",
        "        word_counts.update(text.split(\" \"))\n",
        "    return word_counts\n",
        "\n",
        "word_counts = count_words(cleaned_paragraphs)\n",
        "\n",
        "len(word_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyGVDL9KzJ_I"
      },
      "source": [
        "### Criando um vocabulário"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Com a contagem de palavras podemos definir uma função para criar um novo vocabulário:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vocab(word_counts:Counter, vocab_size:int) -> Tuple[Dict[str, int], List[str]]:\n",
        "    \"\"\"\n",
        "    Generates the vocabulary with the most frequent words.\n",
        "\n",
        "    Args:\n",
        "        word_counts (Counter): word count to generate vocabulary.\n",
        "        vocab_size (int): maximum size for the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, int]: vocabulary mapping words to codes.\n",
        "        List[str]: inverse vocabulary mapping codes to words.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    most_frequent_words = [word for word, count in word_counts.most_common(vocab_size)]\n",
        "    vocab = {word: i for i, word in enumerate(most_frequent_words, 1)}\n",
        "\n",
        "    inverse_vocab = list(vocab.keys())\n",
        "\n",
        "    return vocab, inverse_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E podemos executar um teste mostrando a geração de um vocabulário e suas primeiras 0 entradas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_vocab_size = 1000\n",
        "test_vocab, test_inverse_vocab = create_vocab(word_counts, test_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(',', 1),\n",
              " ('a', 2),\n",
              " ('que', 3),\n",
              " ('-', 4),\n",
              " ('o', 5),\n",
              " ('de', 6),\n",
              " ('e', 7),\n",
              " (';', 8),\n",
              " ('.', 9),\n",
              " ('um', 10)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(itertools.islice(test_vocab.items(), 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "É interessante observar que as palavras mais frequentes são acentuações, o que pode dificultar o aprendizado de sentenças significativas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Codificando e Decodificando sentenças"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos utilizar as seguintes funções para codificar um texto e decodificá-lo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode_sentence(sentence:Union[str,List[str]], vocab:Dict) -> List[int]:\n",
        "    \"\"\"\n",
        "    Encodes a sentence using a vocabulary.\n",
        "\n",
        "    Args:\n",
        "        sentence (Union[str,List[str]]): sentence to encode. Or a string,\n",
        "            or the string already separated into words\n",
        "        vocab (Dict): vocabulary to encode. Maps words to codes.\n",
        "\n",
        "    Returns:\n",
        "        List[int]: the encoded sentence\n",
        "    \"\"\"\n",
        "    if isinstance(sentence, list):\n",
        "        words = sentence\n",
        "    else:\n",
        "        words = sentence.split(\" \")\n",
        "    \n",
        "    return [vocab.get(word, 0) for word in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decode_sentence(encoding:List[int], inverse_vocab:List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Decodes a sentence back to words.\n",
        "\n",
        "    Args:\n",
        "        encoding (List[int]): encoded sentence to decode.\n",
        "        inverse_vocab (List[str]): inverse vocabulary. Maps codes to words\n",
        "\n",
        "    Returns:\n",
        "        List[str]: decoded sentence. Unknown codes are decoded to '???' \n",
        "    \"\"\"\n",
        "    result = []\n",
        "\n",
        "    for encoding_i in encoding:\n",
        "        if encoding_i == 0:\n",
        "            result.append(\"???\")\n",
        "        else:\n",
        "            result.append(inverse_vocab[encoding_i-1])\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wia_ygbvzJ_J"
      },
      "source": [
        "### Separação e Classe do dataset\n",
        "\n",
        "Aqui iremos definir as sentenças a partir dos textos; divídi-las em treino, teste e valiadação; e criar a classe para carregar os dados durante os experimentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Criamos as sequências com tamanhos `context_size+1`, visto que elas precisaram ser deslocadas para gerar os targets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sequences(texts:List[str], context_size:int, \n",
        "                     vocab:Dict) -> Tuple[List[List[int]], List[int]]:\n",
        "    \"\"\"\n",
        "    Creates sequences from the texts, with the target (word to predict), \n",
        "    using a fixed size and vocabulary.\n",
        "\n",
        "    Args:\n",
        "        texts (List[str]): texts to create sequences.\n",
        "        context_size (int): size of the sequences.\n",
        "        vocab (Dict): maps words to codes.\n",
        "\n",
        "    Returns:\n",
        "        List[List[int]]: created sequences.\n",
        "    \"\"\"\n",
        "\n",
        "    x_all = []\n",
        "\n",
        "    for paragraph in texts:\n",
        "        start = 0\n",
        "        end = context_size+1\n",
        "\n",
        "        paragraph = encode_sentence(paragraph, vocab)\n",
        "\n",
        "        while end < len(paragraph):\n",
        "            x = paragraph[start:end]\n",
        "            y = paragraph[end]\n",
        "\n",
        "            if not ( 0 in x or 0 == y):\n",
        "                x_all.append(x)\n",
        "\n",
        "            start += 1\n",
        "            end += 1\n",
        "            \n",
        "    x_all = np.array(x_all)\n",
        "\n",
        "    return x_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Criamos um dataset de teste e validamos que as entradas e targets possuem o mesmo tamanho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_context_size = 10\n",
        "\n",
        "test_x_all = create_sequences(cleaned_paragraphs, test_context_size, test_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert len(test_x_all[0]) == test_context_size+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para evitar viéses, definimos uma função para embaralhar o dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gC0C5qn2zJ_J"
      },
      "outputs": [],
      "source": [
        "def shuffle_dataset(x:List) -> List[int]:\n",
        "    \"\"\"\n",
        "    Shuffle the dataset.\n",
        "\n",
        "    Args:\n",
        "        x (List): dataset elements.\n",
        "\n",
        "    Returns:\n",
        "        List: shuffled elements. \n",
        "    \"\"\"\n",
        "\n",
        "    indexes = list(range(len(x)))\n",
        "    random.shuffle(indexes)\n",
        "\n",
        "    x = x[indexes]\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_x_all = shuffle_dataset(test_x_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E separamos os dados em treino (60%), validação (20%) e teste (20%):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def separate_dataset(x_all:List[int]) -> Tuple[List[int], List[int], List[int]]:\n",
        "    \"\"\"\n",
        "    Separate the data in train, validation and test.\n",
        "\n",
        "    Args:\n",
        "        x_all (List[int]): all dataset elements.\n",
        "\n",
        "    Returns:\n",
        "        List[int]: train elements. \n",
        "        List[int]: validation elements.\n",
        "        List[int]: test elements.\n",
        "    \"\"\"\n",
        "    size_all = len(x_all)\n",
        "\n",
        "    cut1 = int(0.6*size_all)\n",
        "    cut2 = int(0.8*size_all)\n",
        "\n",
        "    x_train = x_all[0:cut1]\n",
        "\n",
        "    x_val = x_all[cut1:cut2]\n",
        "\n",
        "    x_test = x_all[cut2:]\n",
        "\n",
        "    return x_train, x_val, x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Separamos os conjuntos e demonstramos que a separação separa corretamente os dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_x_train, test_x_val, test_x_test = separate_dataset(test_x_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert len(test_x_train)+len(test_x_val)+len(test_x_test) == len(test_x_all)\n",
        "\n",
        "assert len(test_x_train) == int(0.6*len(test_x_all))\n",
        "assert (len(test_x_val) == np.floor(0.2*len(test_x_all)) or len(test_x_val) == np.ceil(0.2*len(test_x_all)))\n",
        "assert (len(test_x_test) == np.floor(0.2*len(test_x_all)) or len(test_x_test) == np.ceil(0.2*len(test_x_all)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Criamos a classe para manipular o dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TextPredictDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Text prediction dataset.\n",
        "\n",
        "    Input: sequence of encoded words.\n",
        "    Target: next word for the sequence.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, x_data:List[List[int]]) -> None:\n",
        "        \"\"\"\n",
        "        Creates a new dataset.\n",
        "\n",
        "        Args:\n",
        "            x_data (List[List[int]]): dataset elements.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self._x_data = torch.tensor(x_data).type(torch.LongTensor)-1\n",
        "        \n",
        "        self._size = len(x_data)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Gets the size of the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: dataset size.\n",
        "        \"\"\"\n",
        "\n",
        "        return self._size\n",
        "\n",
        "    def __getitem__(self, idx:int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Gets a item of the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): data index.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: dataset input. \n",
        "            torch.Tensor: dataset target.\n",
        "        \"\"\"\n",
        "        return self._x_data[idx][:-1], self._x_data[idx][1:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Geramos um dataset de exemplo e mostramos que os elementos e tamanhos das entradas e saídas estão correto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_train_dataset = TextPredictDataset(test_x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert_array_equal(test_train_dataset[0][0].shape, [test_context_size])\n",
        "assert_array_equal(test_train_dataset[0][1].shape, [test_context_size])\n",
        "\n",
        "assert_array_equal(test_train_dataset[0][1][1:-1], test_train_dataset[0][1][1:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por fim, mostramos o uso de um DataLoader e mostramos que os dados possuem tamanhos corretos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_batch_size = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_train_loader = DataLoader(test_train_dataset, batch_size=test_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = next(iter(test_train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert_array_equal(test_data[0].shape, [test_batch_size, test_context_size])\n",
        "assert_array_equal(test_data[1].shape, [test_batch_size, test_context_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Juntando tudo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para o uso posterior, podemos juntar todas as funções criadas realizando o processo completo de geração do dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_data_loaders(texts:List[str], vocab_size:int, context_size:int, batch_size:int) -> Tuple[Dict, List, DataLoader, DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    Generates a text prediction dataset.\n",
        "\n",
        "    Args:\n",
        "        texts (List[str]): texts to generate the dataset.\n",
        "        vocab_size (int): size of the vocabulary (know words).\n",
        "        context_size (int): size of the sequences.\n",
        "        batch_size (int): size of the batchs.\n",
        "\n",
        "    Returns:\n",
        "        Dict: vocabulary. Maps words to codes.\n",
        "        List: inverse vocabulary. Maps codes to words.\n",
        "        DataLoader: train DataLoader.\n",
        "        DataLoader: validation DataLoader.\n",
        "        DataLoader: test DataLoader.\n",
        "    \"\"\"\n",
        "\n",
        "    word_counts = count_words(texts)\n",
        "    vocab, inverse_vocab = create_vocab(word_counts, vocab_size)\n",
        "\n",
        "    x_all = create_sequences(texts, context_size, vocab)\n",
        "    \n",
        "    x_all = shuffle_dataset(x_all)\n",
        "\n",
        "    x_train, x_val, x_test = separate_dataset(x_all)\n",
        "\n",
        "    train_dataset = TextPredictDataset(x_train)\n",
        "    val_dataset = TextPredictDataset(x_val)\n",
        "    test_dataset = TextPredictDataset(x_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return vocab, inverse_vocab, train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5_-Yud0zJ_K"
      },
      "source": [
        "## Model\n",
        "\n",
        "Esta seção irá implementar o modelo que será treinado, começando pelas camadas de atenção, encoding posicional e embedding; seguindo pelo modelo em si e seu teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Attention\n",
        "\n",
        "A camada de atenção é implementada segundo descrito em \"Attention Is All You Need\". É implementada a versão com múltiplas cabeças de atenção e máscara causal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, embed_dim:int, num_heads:int) -> None:\n",
        "        \"\"\"\n",
        "        Creates the layer.\n",
        "\n",
        "        Args:\n",
        "            embed_dim (int): size of the embedding in the layer input and output.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embed_dim = embed_dim\n",
        "        \n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim//num_heads\n",
        "\n",
        "        if self.head_dim * num_heads != embed_dim:\n",
        "            raise ValueError(f\"embed_dim must be divisible by num_heads ({embed_dim}/{num_heads} is not integer).\")\n",
        "\n",
        "\n",
        "        #Initialize weights\n",
        "\n",
        "        #d_model = dv = dk = embed_dim\n",
        "        #h = 1\n",
        "\n",
        "        wQ = torch.Tensor(embed_dim, embed_dim) #embed, embed\n",
        "        wK = torch.Tensor(embed_dim, embed_dim) #embed, dk\n",
        "        wV = torch.Tensor(embed_dim, embed_dim) #embed, dv\n",
        "        w0 = torch.Tensor(embed_dim, embed_dim) #embed, embed\n",
        "\n",
        "        self.wQ = torch.nn.Parameter(wQ)\n",
        "        self.wK = torch.nn.Parameter(wK)\n",
        "        self.wV = torch.nn.Parameter(wV)\n",
        "        self.w0 = torch.nn.Parameter(w0)\n",
        "\n",
        "        self.register_buffer(\"dk_root\", torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32)))\n",
        "\n",
        "        for w in [self.wQ, self.wK, self.wV, self.w0]:\n",
        "            torch.nn.init.kaiming_normal_(w)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, query:torch.Tensor, key:torch.Tensor, value:torch.Tensor, is_causal:bool=False) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Process the inputs using the attention process.\n",
        "\n",
        "        Input tensors must be in [batch, sentence, embed] order.\n",
        "\n",
        "        Args:\n",
        "            query (torch.Tensor): queries tensor, are compared against the keys.\n",
        "            key (torch.Tensor): keys tensor, represents the keys.\n",
        "            value (torch.Tensor): values tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: the layer output, the values pondered by the compability between the keys and queries.\n",
        "        \"\"\"\n",
        "\n",
        "        #Check input\n",
        "        if query.shape[2] != self.embed_dim:\n",
        "            raise ValueError(f\"Inputs must have embed dimension of {self.embed_dim} ({query.shape[2]} != {self.embed_dim})\")\n",
        "\n",
        "        #Get dimensions\n",
        "        batch_size = query.shape[0]\n",
        "        context_size = query.shape[1]\n",
        "\n",
        "        #Linear input transformation\n",
        "        #Transpose weights because PyTorch does that\n",
        "        Q = query @ self.wQ.T\n",
        "        K = key @ self.wK.T\n",
        "        V = value @ self.wV.T\n",
        "\n",
        "        #batch_size, sentence, embed\n",
        "        # to\n",
        "        #batch_size,  n_head, sentence, head_dim\n",
        "        Q = Q.transpose(0,1).reshape(context_size, batch_size*self.num_heads, self.head_dim).transpose(0,1)\n",
        "        K = K.transpose(0,1).reshape(context_size, batch_size*self.num_heads, self.head_dim).transpose(0,1)\n",
        "        V = V.transpose(0,1).reshape(context_size, batch_size*self.num_heads, self.head_dim).transpose(0,1)\n",
        "        #Now we have [\n",
        "        # [batch0word0part0, batch0word1part0], \n",
        "        # [batch0word0part1, batch0word1part1],\n",
        "        # [batch1word0part0, batch1word1part0], \n",
        "        # [batch1word0part1, batch1word1part1],\n",
        "        #]\n",
        "        \n",
        "        scores = Q @ K.transpose(-2, -1) #K.permute(0,1,3,2)\n",
        "        scores /= self.dk_root\n",
        "\n",
        "        #Apply causal bias\n",
        "        if is_causal:\n",
        "            mask = torch.ones((context_size, context_size), dtype=torch.bool)\n",
        "            mask = mask.tril() #Lower triangular is one\n",
        "            mask = torch.bitwise_not(mask) #Upper triangular without diagonal is ones\n",
        "\n",
        "            attention_bias = torch.zeros((context_size, context_size), device=query.device)\n",
        "            attention_bias[mask] = -torch.inf\n",
        "        \n",
        "            scores += attention_bias\n",
        "\n",
        "\n",
        "        probs = torch.softmax(scores, dim=-1)\n",
        "        E = probs @ V\n",
        "\n",
        "        #Return elements to correct place \n",
        "        E = E.reshape(batch_size, self.num_heads, context_size, self.head_dim)\n",
        "        E = E.transpose(-3,-2)\n",
        "        E = E.reshape(batch_size, context_size, self.embed_dim)\n",
        "        #Now we have [\n",
        "        #[batch0word0, batch0word1], \n",
        "        #[batch1word0, batch1word1]\n",
        "        #]\n",
        "\n",
        "        result = E @ self.w0.T \n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para testar a camadas implementada, podemos instanciar ela junto da implementação de referência do PyTorch, e certificar que as saídas das 2 camadas são as mesmas, dado os mesmos pesos e entradas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instaciamos as camadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_embed_dim = 4\n",
        "test_num_heads = 2\n",
        "test_context_size = 3\n",
        "\n",
        "our_version = MultiHeadAttention(test_embed_dim, num_heads=test_num_heads).eval()\n",
        "torch_version = torch.nn.MultiheadAttention(test_embed_dim, num_heads=test_num_heads, bias=False, batch_first=True ).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Igualamos todos os pesos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "wQ = our_version.wQ\n",
        "wK = our_version.wK\n",
        "wV = our_version.wV\n",
        "w0 = our_version.w0\n",
        "\n",
        "torch_version.in_proj_weight = torch.nn.Parameter(torch.concat((wQ, wK, wV)))\n",
        "torch_version.out_proj.weight = w0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Geramos os dados de teste randomicamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = torch.rand(2, test_context_size, test_embed_dim) #2 batchs, sequences of test_context_size words, embed_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realizamos as operações com as camadas e verificamos se os resultados são os mesmos, com e sem causalidade:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_mask = torch.nn.Transformer.generate_square_subsequent_mask(test_context_size)\n",
        "\n",
        "for is_causal in [False, True]:\n",
        "\n",
        "    result_our = our_version(test_data, test_data, test_data, is_causal)\n",
        "\n",
        "    if is_causal:\n",
        "        result_torch, _ = torch_version(test_data, test_data, test_data, need_weights=False, is_causal=True, attn_mask=attention_mask)\n",
        "    else:\n",
        "        result_torch, _ = torch_version(test_data, test_data, test_data, need_weights=False)\n",
        "\n",
        "    result_our = result_our.detach()\n",
        "    result_torch = result_torch.detach()\n",
        "\n",
        "    assert result_our.shape == result_torch.shape\n",
        "    assert_array_almost_equal(result_our, result_torch, decimal=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por fim, podemos comparar a performance entre as camadas utilizando a CPU.\n",
        "\n",
        "A célula está comentada devido ao custo de executá-lo, porém os resultados estão disponíveis a seguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%timeit our_version(test_data, test_data, test_data)\n",
        "#%timeit torch_version(test_data, test_data, test_data, need_weights=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Our: 208 µs ± 13.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
        "Torch: 260 µs ± 21.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Curiosamente a implementação do PyTorch é mais lenta, porém pode ser devido as maiores capacidades que possue e checagens que executa. É importante que ressaltar que esses resultados são apenas para a execução utilizando a CPU.\n",
        "\n",
        "Comparado com o exercício anterior (sem multi-head) o custo de execução praticamente dobrou, possivelmente pelo custo de manipular a configuração dos dados na memória para realizar as operações."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Positional Encoding\n",
        "\n",
        "A camada de encoding posicional é implementada com funções periódicas, assim como o paper \"Attention is All You Need\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SinePositionalEncoding(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Positional enconding using sine/cossine function.\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim:int, sequence_size:int) -> None:\n",
        "        \"\"\"\n",
        "        Creates the layer.\n",
        "\n",
        "        Args:\n",
        "            embed_dim (int): embedding size in the input and output.\n",
        "            sequence_size (int): size of the sequence in the input and output.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        #Caches the positions encodings:\n",
        "        position = torch.arange(sequence_size, dtype=torch.float32)\n",
        "        expoent = 2.0*torch.arange(embed_dim, dtype=torch.float32)/embed_dim\n",
        "\n",
        "        pe = torch.empty((sequence_size, embed_dim))\n",
        "\n",
        "        pe.T[:] = position\n",
        "        pe /= torch.pow(1e4, expoent)\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(pe[:, 0::2])\n",
        "        pe[:, 1::2] = torch.cos(pe[:, 1::2])\n",
        "\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, input_tensor:torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Adds the positions encodings to the input.\n",
        "\n",
        "        Args:\n",
        "            input_tensor (torch.Tensor): input tensor to receive the positions encodings\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: input + positional encoding.\n",
        "        \"\"\"\n",
        "        output = input_tensor + self.pe\n",
        "\n",
        "        return output\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testamos a camada utilizando uma entrada nula para verificar se as codificações estão corretas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_embed_dim = 5\n",
        "test_sequence_size = 3\n",
        "\n",
        "test_data = torch.zeros(2, test_sequence_size, test_embed_dim) #2 batchs, sequences of 3 words, embed_dim\n",
        "\n",
        "positional_encoding = SinePositionalEncoding(test_embed_dim, test_sequence_size)\n",
        "\n",
        "result = positional_encoding(test_data)\n",
        "\n",
        "assert_array_equal(result[0], result[1]) #Correct operation across batchs\n",
        "assert_array_not_equal(result[0, 0], result[0, 1]) #Different positions -> Different encodings\n",
        "assert_array_not_equal(result[0,:,0], result[0,:,1]) #Different dimensions -> Different encodings\n",
        "assert len(list(positional_encoding.parameters())) == 0 #No trainable parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para o embedding utilizamos uma matriz de look-up aprendível, assim como \"A Neural Probabilistic Language Model\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Embedding(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Converts codes to embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim:int, vocab_size:int) -> None:\n",
        "        \"\"\"\n",
        "        Creates a new Embedding layer.\n",
        "\n",
        "        Args:\n",
        "            embed_dim (int): size of the embedding in the output.\n",
        "            vocab_size (int): size of the vocabulary the words were coded.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        C = torch.Tensor(vocab_size, embed_dim)\n",
        "        torch.nn.init.xavier_uniform_(C)\n",
        "        self.C = torch.nn.Parameter(C)\n",
        "\n",
        "    def forward(self, input_tensor:torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Embeds the input sequences.\n",
        "\n",
        "        Args:\n",
        "            input_tensor (torch.Tensor): sequences to be embeded.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: result embeddings.\n",
        "        \"\"\"\n",
        "        \n",
        "        #OBS: I checked, \"index_select\" doesn't work with batchs, \"index\" (third parameter) must be 1-D\n",
        "        result = torch.stack([torch.index_select(self.C, 0, input_i) for input_i in input_tensor])\n",
        "        \n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E testamos se a camada gera o embedding corretamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_embed_dim = 2\n",
        "test_vocab_size = 3\n",
        "test_sequence_size = test_vocab_size\n",
        "\n",
        "test_data = torch.empty((2, test_sequence_size), dtype=int)\n",
        "test_data[:] = torch.arange(test_vocab_size)\n",
        "\n",
        "embedding = Embedding(test_embed_dim, test_vocab_size)\n",
        "\n",
        "result = embedding(test_data)\n",
        "result = result.detach()\n",
        "\n",
        "C = embedding.C.detach()\n",
        "\n",
        "assert_array_equal(C.shape, [test_vocab_size, test_embed_dim]) #C matrix have correct shape\n",
        "assert_array_equal(result.shape, [2, test_sequence_size, test_embed_dim])\n",
        "assert_array_equal(result[0], result[1]) #Correct operation across batchs\n",
        "assert_array_equal(result[0, 0], C[0]) #First result = embedding of first word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformDecoderBlock(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Block of a Transform Decoder.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim:int, n_head:int, dropout_rate:float=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attention = MultiHeadAttention(embed_dim, n_head)\n",
        "        self.dropout_attention = torch.nn.Dropout(dropout_rate)\n",
        "        self.layer_norm1 = torch.nn.LayerNorm(embed_dim)\n",
        "        self.linear1 = torch.nn.Linear(embed_dim, 4*embed_dim)\n",
        "        self.dropout_linear1 = torch.nn.Dropout(dropout_rate)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(4*embed_dim, embed_dim)\n",
        "        self.dropout_linear2 = torch.nn.Dropout(dropout_rate)\n",
        "        self.layer_norm2 = torch.nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        #Masked Multi-Head Attention\n",
        "        y1 = self.dropout_attention(self.attention(x, x, x, is_causal=True))\n",
        "        \n",
        "        #Add & Norm\n",
        "        y1 = x+y1\n",
        "        y1 = self.layer_norm1(y1)\n",
        "        \n",
        "        #Feed Forward\n",
        "        y2 = self.dropout_linear1(self.linear1(y1))\n",
        "        y2 = self.relu(y2)\n",
        "        y2 = self.dropout_linear2(self.linear2(y2))\n",
        "        \n",
        "        #Add & Norm\n",
        "        result = y1+y2\n",
        "        result = self.layer_norm2(result)\n",
        "\n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por fim, defimos o modelo de linguagem utilizando as camadas criadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "I2qKG9YczJ_K"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Language model using Decorder-only Transform.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim:int, vocab_size:int, sequence_size:int, n_head:int, n_block:int, dropout_rate:float=0.0) -> None:\n",
        "        \"\"\"\n",
        "        Creates a new model\n",
        "\n",
        "        Args:\n",
        "            embed_dim (int): size of the embeddings between layers.\n",
        "            vocab_size (int): size of the vocabulary the inputs were coded.\n",
        "            sequence_size (int): size of the input sequences.\n",
        "            n_head (int): number of attention heads in each attention layer.\n",
        "            n_block (int): number of decoder blocks in the model.\n",
        "            dropout_rate (float, optional): dropout between layers rate. Defaults to 0.0.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = Embedding(embed_dim, vocab_size)\n",
        "\n",
        "        self.positional_encoding = SinePositionalEncoding(embed_dim, sequence_size)\n",
        "        self.dropout_encoding = torch.nn.Dropout(dropout_rate)\n",
        "\n",
        "        blocks = [TransformDecoderBlock(embed_dim, n_head, dropout_rate) for _ in range(n_block)]\n",
        "        self.decoder_blocks = torch.nn.Sequential(*blocks)\n",
        "\n",
        "\n",
        "        self.linear_out = torch.nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Predicts the next word of the sequence.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): sequence.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: next word predicted.\n",
        "        \"\"\"\n",
        "        y = self.embedding(x)\n",
        "        y = self.dropout_encoding(self.positional_encoding(y))\n",
        "\n",
        "        y = self.decoder_blocks(y)\n",
        "        \n",
        "        y = self.linear_out(y)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testamos o modelo com uma entrada aleatória para verificar se as saídas possuem tamanhos corretos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "7yjQ1KXOzJ_K"
      },
      "outputs": [],
      "source": [
        "test_embed_dim = 8\n",
        "test_vocab_size = 1000\n",
        "test_sequence_size = 10\n",
        "test_n_head = 2\n",
        "test_n_block = 2\n",
        "\n",
        "test_model = LanguageModel(test_embed_dim, test_vocab_size, test_sequence_size, test_n_head, test_n_block)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xmsD59TfzJ_K"
      },
      "outputs": [],
      "source": [
        "test_input, test_target = next(iter(test_train_loader))\n",
        "\n",
        "output = test_model(test_input)\n",
        "\n",
        "assert_array_equal(output.shape, [test_batch_size, test_sequence_size, test_vocab_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_target.reshape(-1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50, 1000])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.view(-1, test_vocab_size).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50, 1000])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.view(-1, output.shape[-1]).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UngUhyu7zJ_L"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Com o modelo e dados definidos, podemos iniciar o treinamento.\n",
        "\n",
        "Começamos definindo qual será o dispositivo utilizado para o treino:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wntaV50nzJ_L",
        "outputId": "a054092b-d801-4c60-eb75-85abfe57151d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Criamos algumas funções que serão utilizadas durante o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ppl(loss:torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the perplexity from the loss.\n",
        "\n",
        "    Args:\n",
        "        loss (torch.Tensor): loss to compute the perplexity.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: corresponding perplexity.\n",
        "    \"\"\"\n",
        "    return torch.exp(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_loss(model:torch.nn.Module, loader:DataLoader, criterion:torch.nn.Module) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the loss from a model across a dataset, without gradient and in eval mode.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): model to evaluate.\n",
        "        loader (DataLoader): dataset.\n",
        "        criterion (torch.nn.Module): loss function to compute.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: resulting loss.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        n = 0\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            targets = targets.reshape(-1)\n",
        "            targets = targets.to(device)\n",
        "            \n",
        "            logits = model(inputs)\n",
        "            logits = logits.view(-1, logits.shape[-1])\n",
        "\n",
        "            loss = criterion(logits.squeeze(), targets)\n",
        "            total_loss += loss*targets.size(0)\n",
        "\n",
        "            n += targets.size(0)\n",
        "\n",
        "        total_loss /= n \n",
        "    \n",
        "    return total_loss.detach()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_info(loss_value:torch.Tensor, epoch:int, total_epochs:int, time:float=0.0):\n",
        "    \"\"\"\n",
        "    Prints the information of a epoch.\n",
        "\n",
        "    Args:\n",
        "        loss_value (torch.Tensor): epoch loss.\n",
        "        epoch (int): epoch number.\n",
        "        total_epochs (int): total number of epochs. \n",
        "        time (float, optional): time to run the epoch. Don't print if is 0.0. Defaults to 0.0.\n",
        "    \"\"\"\n",
        "    ppl_value = ppl(loss_value)\n",
        "\n",
        "    \n",
        "    print(f'Epoch [{epoch+1}/{total_epochs}], \\\n",
        "            Loss: {loss_value.item():.4f}, \\\n",
        "            Perplexity: {ppl_value.item():.4f}', end=\"\")\n",
        "    \n",
        "    if time != 0:\n",
        "        print(f\", Elapsed Time: {time:.2f} sec\")    \n",
        "    else:\n",
        "        print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E realizamos o processo de treino, iniciando pela definição dos parâmetros que serão utilizados. Neste caso estão aqui os parâmetros que geraram o melhor treinamento, com todos os resultados de todas as variações testadas disponíveis em [https://api.wandb.ai/links/eltoncn/io0lpve3](https://api.wandb.ai/links/eltoncn/io0lpve3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 64 # Tamanho do batch\n",
        "context_size = 9 # n palavras de entrada. O target é a próxima palavra\n",
        "dropout_rate = 0.15 #Dropout entre as camadas\n",
        "embed_dim = 64 # Tamanho do feature vector de cada palavra\n",
        "epochs = 10 # Quantidade de epochs que serão treinadas\n",
        "lr = 2.5e-3 # Taxa de treinamento\n",
        "\n",
        "n_block = 4 # Quantidade de blocos de decoder\n",
        "n_head = 8 # Quantidade de cabeças de atenção\n",
        "\n",
        "optimizer_class = torch.optim.Adam #torch.optim.SGD\n",
        "vocab_size = 3000 # Quantidade de palavras no vocabulário\n",
        "weight_decay = 3e-4 # Regularização L2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E se será realizado o logging utilizando o wandb:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_wandb = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para garantir reprodutibilidade, a geração de todos os datasets e todos os treinos são realizados as mesmas sementes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "reset_seeds()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instanciamos todos os objetos necessários:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab, inverse_vocab, train_loader, val_loader, test_loader = create_data_loaders(cleaned_paragraphs, vocab_size, context_size, batch_size)\n",
        "\n",
        "model = LanguageModel(embed_dim, vocab_size, context_size, n_head, n_block, dropout_rate)\n",
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optimizer_class(model.parameters(), lr=lr, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Iniciamos o logging:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"vocab_size\": vocab_size,\n",
        "    \"context_size\": context_size,\n",
        "    \"embed_dim\": embed_dim,\n",
        "    \"epochs\": epochs,\n",
        "    \"lr\": lr,\n",
        "    \"weight_decay\": weight_decay,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"optimizer_class\": optimizer_class.__name__,\n",
        "    \"dropout_rate\": dropout_rate,\n",
        "    \"n_block\": n_block,\n",
        "    \"n_head\": n_head\n",
        "}\n",
        "\n",
        "if use_wandb:\n",
        "    wandb.init(project=\"IA024-04-TransformDecoder\", config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E realizamos o treino:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/10],             Loss: 8.0926,             Perplexity: 3270.1411\n",
            "Epoch [1/10],             Loss: 6.2406,             Perplexity: 513.1849, Elapsed Time: 2.92 sec\n",
            "VAL Epoch [1/10],             Loss: 6.1053,             Perplexity: 448.2085\n",
            "Epoch [2/10],             Loss: 6.1058,             Perplexity: 448.4725, Elapsed Time: 2.88 sec\n",
            "VAL Epoch [2/10],             Loss: 6.1010,             Perplexity: 446.3076\n",
            "Epoch [3/10],             Loss: 6.0983,             Perplexity: 445.0850, Elapsed Time: 2.69 sec\n",
            "VAL Epoch [3/10],             Loss: 6.0964,             Perplexity: 444.2652\n",
            "Epoch [4/10],             Loss: 5.3885,             Perplexity: 218.8787, Elapsed Time: 2.54 sec\n",
            "VAL Epoch [4/10],             Loss: 4.6622,             Perplexity: 105.8692\n",
            "Epoch [5/10],             Loss: 4.4310,             Perplexity: 84.0179, Elapsed Time: 2.38 sec\n",
            "VAL Epoch [5/10],             Loss: 4.1568,             Perplexity: 63.8661\n",
            "Epoch [6/10],             Loss: 4.0348,             Perplexity: 56.5295, Elapsed Time: 3.07 sec\n",
            "VAL Epoch [6/10],             Loss: 3.8845,             Perplexity: 48.6419\n",
            "Epoch [7/10],             Loss: 3.7749,             Perplexity: 43.5927, Elapsed Time: 3.02 sec\n",
            "VAL Epoch [7/10],             Loss: 3.6918,             Perplexity: 40.1156\n",
            "Epoch [8/10],             Loss: 3.5822,             Perplexity: 35.9509, Elapsed Time: 2.53 sec\n",
            "VAL Epoch [8/10],             Loss: 3.5441,             Perplexity: 34.6091\n",
            "Epoch [9/10],             Loss: 3.4264,             Perplexity: 30.7646, Elapsed Time: 2.66 sec\n",
            "VAL Epoch [9/10],             Loss: 3.4174,             Perplexity: 30.4907\n",
            "Epoch [10/10],             Loss: 3.2969,             Perplexity: 27.0289, Elapsed Time: 2.70 sec\n",
            "VAL Epoch [10/10],             Loss: 3.2946,             Perplexity: 26.9671\n"
          ]
        }
      ],
      "source": [
        "hist = {}\n",
        "hist[\"loss_train\"] = []\n",
        "hist[\"loss_val\"] = []\n",
        "hist[\"ppl_train\"] = []\n",
        "hist[\"ppl_val\"] = []\n",
        "\n",
        "prev_loss = compute_loss(model, train_loader, criterion)\n",
        "print_info(prev_loss, -1, epochs, 0)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time() \n",
        "\n",
        "    model.train()\n",
        "\n",
        "    loss_train = torch.tensor(0, dtype=torch.float32, device=device)\n",
        "    n_train = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        \n",
        "        targets = targets.reshape(-1)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        logits = model(inputs)\n",
        "        logits = logits.view(-1, vocab_size)\n",
        "\n",
        "        loss : torch.Tensor = criterion(logits.squeeze(), targets)\n",
        "\n",
        "        loss_train += loss*targets.size(0)\n",
        "        n_train += targets.size(0)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    end_time = time.time() \n",
        "    epoch_duration = end_time - start_time \n",
        "\n",
        "    loss_train /= n_train\n",
        "    ppl_train = ppl(loss_train)\n",
        "\n",
        "    print_info(loss_train, epoch, epochs, epoch_duration)\n",
        "    \n",
        "    print(\"VAL \", end=\"\")\n",
        "    loss_val = compute_loss(model, val_loader, criterion)\n",
        "    ppl_val = ppl(loss_val)\n",
        "    print_info(loss_val, epoch, epochs)\n",
        "\n",
        "    hist[\"loss_train\"].append(loss_train.item())\n",
        "    hist[\"loss_val\"].append(loss_val.item())\n",
        "    hist[\"ppl_train\"].append(ppl_train.item())\n",
        "    hist[\"ppl_val\"].append(ppl_val.item())\n",
        "\n",
        "    log = {\n",
        "        \"loss_train\": loss_train.item(),\n",
        "        \"loss_val\": loss_val.item(),\n",
        "        \"ppl_train\": ppl_train.item(),\n",
        "        \"ppl_val\": ppl_val.item()\n",
        "    }\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.log(log)\n",
        "\n",
        "for key in hist:\n",
        "    hist[key] = np.array(hist[key])\n",
        "\n",
        "if use_wandb:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos checar a perda e perplexidade obtidas durante o treino. Um ponto relevante é o rápido overfitting que ocorre, possivelmente pelo tamanho limitado pelo conjunto de treino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(hist[\"loss_train\"], \"o-\")\n",
        "plt.plot(hist[\"loss_val\"], \"o-\")\n",
        "\n",
        "plt.legend([\"Train\", \"Val\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss history\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(hist[\"ppl_train\"]/vocab_size, \"o-\")\n",
        "plt.plot(hist[\"ppl_val\"]/vocab_size, \"o-\")\n",
        "\n",
        "plt.legend([\"Train\", \"Val\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Normalized PPL\")\n",
        "plt.title(\"Perplexity history\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSXfwYISDoPN"
      },
      "source": [
        "## Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A avaliação é realizada calculando a perplexidade do modelo no conjunto de teste. É calculada apenas a perplexidade do melhor modelo nos dados de validação, para reportar a capacidade de generalização do modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "nXXO78GSDqPg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "27.32070541381836"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_loss = compute_loss(model, test_loader, criterion)\n",
        "test_ppl = ppl(test_loss)\n",
        "\n",
        "test_ppl.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculamos também a quantidade total de parâmetros utilizados pelo modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "585912"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_param = sum([p.numel() for p in model.parameters()])\n",
        "n_param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1zhxVqfzJ_M"
      },
      "source": [
        "## Exemplo de uso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para uso do modelo, definimos uma função para gerar mais texto até obter o tamanho máximo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "3PExkoWOzJ_M"
      },
      "outputs": [],
      "source": [
        "def generate_text(model:torch.nn.Module, vocab:Dict, inverse_vocab:List, text:str, max_length:int) -> str:\n",
        "    \"\"\"\n",
        "    Generates a text to complete the previous.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): language model to use.\n",
        "        vocab (Dict): vocabulary. Maps words to codes.\n",
        "        inverse_vocab (List): inverse vocabulary. Maps codes to words.\n",
        "        text (str): text to complete.\n",
        "        max_length (int): maximum length to obtain.\n",
        "\n",
        "    Returns:\n",
        "        str: generated text.\n",
        "    \"\"\"\n",
        "\n",
        "    text = clean_text(text)\n",
        "\n",
        "    total_length = len(text.split(\" \"))\n",
        "\n",
        "    last_sequence = create_sequences([text], context_size, vocab)[-1][1:]\n",
        "    last_sequence = torch.tensor(last_sequence)-1\n",
        "    last_sequence = last_sequence.to(device)\n",
        "\n",
        "    new_characters = []\n",
        "\n",
        "    while total_length < max_length:\n",
        "                \n",
        "        output = model(torch.unsqueeze(last_sequence, 0))\n",
        "\n",
        "        next_encoded = output[0][-1].argmax()\n",
        "\n",
        "        last_sequence = torch.cat((last_sequence[1:], torch.tensor([next_encoded]).to(device)))\n",
        "        \n",
        "        new_characters.append(next_encoded.item())\n",
        "\n",
        "        total_length += 1\n",
        "\n",
        "    new_characters = np.array(new_characters)+1\n",
        "\n",
        "    new_text = \" \".join(decode_sentence(new_characters, inverse_vocab))\n",
        "\n",
        "    return new_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E geramos um texto de exemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OLD\n",
            "nesse instante erguia a cabeça e fitava os olhos n'uma sebe de folhas que se elevava a vinte passos de distancia , e se\n",
            "\n",
            "GENERATED CONTINUATION\n",
            "a india , e o indio , que tinha visto ; e o seu instincto adivinhava , e que a expressão intelligente de sua familia , que a sua senhora , e o indio tinha a expressão de sua senhora , e que o indio tinha a expressão de sua senhora , e que o indio\n"
          ]
        }
      ],
      "source": [
        "text = cleaned_paragraphs[200]#300]\n",
        "max_length = 80\n",
        "\n",
        "new_text = generate_text(model, vocab, inverse_vocab, text, max_length)\n",
        "\n",
        "print(\"OLD\")\n",
        "print(text)\n",
        "print(\"\")\n",
        "print(\"GENERATED CONTINUATION\")\n",
        "print(new_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "É perceptível como que o modelo rapidamente colapsa para uma sequência fixa, porém não tão rápido quanto os modelos dos exercícios anteriores."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
