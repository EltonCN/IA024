{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMI0JT_YuYF3"
      },
      "source": [
        "## Exercício: Modelo de Linguagem com auto-atenção e máscaras causais\n",
        "\n",
        "> Seguimos na mesma linha de treinar um modelo de linguagem a partir dos textos do livro \"O Guarani\", de José de Alencar.\n",
        "> \n",
        "> Neste exercício, vamos treinar um modelo de linguagem com auto-atenção e com máscara causal. A máscara causal é necessária para que o modelo não tenha acesso a palavras futuras, que é a abordagem usada por grandes modelos de linguagem, como o GPT.\n",
        "> \n",
        "> Use a implementação matricial de auto-atenção da aula passada.\n",
        "> \n",
        "> ### Modificações necessárias\n",
        "> \n",
        "> - [x] Adicione a máscara causal na função `forward` da cabeça de auto-atenção.\n",
        "> - [x] Modifique o nosso dataloader para retornar inputs (uma lista de tokens de tamanho $n$), targets (uma lista de tokens de tamanho $n$ deslocada para a esquerda em 1 token). Exemplo `input = [1, 2, 3, 4]`, `target = [2, 3, 4, 5]` para a sequência `[1, 2, 3, 4, 5]` com `seq_len=4`, por exemplo (Ver slide 50).\n",
        "> \n",
        "> ### Extra\n",
        "> - [x] MultiHeadAttention: modifique a cabeça de auto-atenção para ter múltiplas cabeças. Isso não é obrigatório, mas pode ser interessante para ver como o modelo se comporta.\n",
        "> - [ ] Diagrama da geração: fazer diagrama que mostre os passos da geração de tokens (conforme slide 47).\n",
        "> \n",
        "> ### Dicas\n",
        "> \n",
        "> * Use como base o vídeo do Karpathy: https://www.youtube.com/watch?v=kCc8FmEb1nY. Observe que, no vídeo, ele primeiro implementa um modelo bi-grama, depois um modelo de linguagem com auto-atenção. O modelo de auto-atenção é implementado por volta do minuto 40, mas vale a pena assistir o vídeo todo.\n",
        "> * Use esta implementação como base: https://colab.research.google.com/drive/1vFTg4MSXVJwNSzPjaCcvmqhxTP7gK7HA?usp=sharing. Observe como o modelo é organizado e como a máscara é implementada na classe MultiHeadAttention.\n",
        "> * Use `context_size=9`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este notebook irá mostrar o processo de criação de um modelo de linguagem utilizando um transformer decoder-only, com processo de atenção multi-cabeça e máscara causal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Iremos começar importando os módulos que serão utilizados na atividade:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string # Manipular strings\n",
        "from collections import Counter # Fazer contagem de elementos\n",
        "import random # Operações randômicas\n",
        "import os # Manipular arquivos\n",
        "import time # Medição de tempo\n",
        "import abc # Classes abstratas\n",
        "import itertools # Iterators\n",
        "from typing import List, Dict, Union, Tuple # Type hints\n",
        "\n",
        "import numpy as np # Operações vetoriais\n",
        "from numpy.testing import assert_raises, assert_array_equal, assert_array_almost_equal # Testes\n",
        "from numpy.typing import ArrayLike # Type hints\n",
        "import torch # ML\n",
        "from torch.utils.data import Dataset, DataLoader # Preparação de dados\n",
        "import matplotlib.pyplot as plt # Plots\n",
        "import wandb # Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E algumas funções auxiliares que serão utilizadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {},
      "outputs": [],
      "source": [
        "def assert_array_not_equal(array1:ArrayLike, array2:ArrayLike) -> None:\n",
        "    \"\"\"\n",
        "    Raises an AssertionError if two array_like objects are equal.\n",
        "\n",
        "    Args:\n",
        "        array1 (ArrayLike): First array to check.\n",
        "        array2 (ArrayLike): Second array to check.\n",
        "    \"\"\"\n",
        "    assert_raises(AssertionError, assert_array_equal, array1, array2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reset_seeds() -> None:\n",
        "    \"\"\"\n",
        "    Resets the random generators from random and torch to a fixed seed.\n",
        "    \"\"\"\n",
        "    random.seed(18)\n",
        "    torch.manual_seed(18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparação dos dados.\n",
        "\n",
        "Nesta seção serão definidas funções para preparar os dados para treino do modelo. Devido a necessidade de alterar os parâmetros constantemente durante os experimentos de treino, são definidas em funções as operações que são necessárias. Exemplos são executados para mostrar o funcionamento correto das operações."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYbkEzdD37sZ"
      },
      "source": [
        "### Faz download e carrega o dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nesta seção os dados serão transferidos, lidos e limpos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O primeiro passo é realizar o download dos dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qAnqY_q0beK",
        "outputId": "f810fdb0-138d-4917-b7ef-69ab266acef6"
      },
      "outputs": [],
      "source": [
        "if not os.path.isfile(\"67724.txt.utf-8\"):\n",
        "    !curl -LO https://www.gutenberg.org/ebooks/67724.txt.utf-8\n",
        "\n",
        "if not os.path.isfile(\"67725.txt.utf-8\"):\n",
        "    !curl -LO https://www.gutenberg.org/ebooks/67725.txt.utf-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seguido pela leitura:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_UzC9pV091C",
        "outputId": "1553b04f-24c4-4027-8cab-0907f92f04df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4971"
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = open(\"67724.txt.utf-8\",\"r\", encoding=\"utf8\").read()\n",
        "text += open(\"67725.txt.utf-8\",\"r\", encoding=\"utf8\").read()\n",
        "\n",
        "paragraphs = text.split(\"\\n\\n\")\n",
        "len(paragraphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E limpeza dos dados.\n",
        "\n",
        "São realizadas as seguintes operações seguindo o paper \"A Neural Probabilistic Language Model\"\n",
        "\n",
        "\n",
        "- Pontuação: é mantida, porém separada do texto para permitir criação de símbolos próprios no vocabulário, e evitar a criação de várias símbolos representando as palavras com pontuação (\"pontuação\" -> \"pontuação\" + \",\" )\n",
        "- Número: convertidos para símbolo especial. No caso todos os números são convertidos para \"999\", para que convirjam para o mesmo símbolo no vocabulário\n",
        "- Letras maiúsculas: convertidas para minúsculas.\n",
        "- Nomes próprios: não são alterados devido a necessidade de serem identificados, diferente do paper.\n",
        "- Palavras raras: são removidas ao criar o vocabulário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text:str) -> str:\n",
        "    '''\n",
        "    Clean the text, changing upper case and setting numbers to 999.\n",
        "    '''\n",
        "    \n",
        "    text = text.lower() # Upper Case -> lower case\n",
        "    \n",
        "    old_text = text.split()\n",
        "    new_text = []\n",
        "\n",
        "    for j in range(len(old_text)):\n",
        "        word = old_text[j] \n",
        "\n",
        "        if word.isdigit(): #Number -> 999\n",
        "            word = \"999\"\n",
        "        elif len(word) > 1 and word[0] in string.punctuation: # Ponctuation -> separate\n",
        "            old_text.insert(j+1, word[1:])\n",
        "            word = word[0]\n",
        "        elif word[-1] in string.punctuation and len(word) > 1: # Ponctuation -> separate\n",
        "            old_text.insert(j+1, word[:-1])\n",
        "            old_text.insert(j+2, word[-1])\n",
        "            \n",
        "            word = \"\"\n",
        "        \n",
        "        if len(word) > 0: # No empty words\n",
        "            new_text.append(word)\n",
        "    \n",
        "    return \" \".join(new_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhUFjtNdDuG0",
        "outputId": "78798c0c-deca-4454-d3fb-7d3ba70f3e91"
      },
      "outputs": [],
      "source": [
        "cleaned_paragraphs = [paragraph.replace(\"\\n\", \" \") for paragraph in paragraphs if paragraph.strip()] # Removes \\n\n",
        "\n",
        "for i in range(len(cleaned_paragraphs)):\n",
        "    cleaned_paragraphs[i] = clean_text(cleaned_paragraphs[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos ver um exemplo de parágrafo limpo do dataset, junto com a quantidade total de parágrafos obtidos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAMPLE ----------------\n",
            "﻿the project gutenberg ebook of o guarany : romance brazileiro , vol . 999 ( of 999 ) this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with almost no restrictions whatsoever . you may copy it , give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org . if you are not located in the united states , you\n",
            "---------------------\n",
            "4892\n"
          ]
        }
      ],
      "source": [
        "print(\"SAMPLE ----------------\")\n",
        "print(cleaned_paragraphs[0])\n",
        "print(\"---------------------\")\n",
        "\n",
        "print(len(cleaned_paragraphs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFVN2ihb33Rf"
      },
      "source": [
        "### Análise do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aqui iremos realizar a contagem de palavras no dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSRHqe3H4ZFw",
        "outputId": "4a985c7a-ce1d-4b72-d253-c9fbbc5f9440"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11470"
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def count_words(texts:List[str]) -> Counter:\n",
        "    \"\"\"\n",
        "    Counts the words in the texts.\n",
        "\n",
        "    Args:\n",
        "        texts (List[str]): List of strings with the texts.\n",
        "\n",
        "    Returns:\n",
        "        Counter: counter with the word count across all texts.\n",
        "    \"\"\"\n",
        "    \n",
        "    word_counts = Counter()\n",
        "    for text in texts:\n",
        "        word_counts.update(text.split(\" \"))\n",
        "    return word_counts\n",
        "\n",
        "word_counts = count_words(cleaned_paragraphs)\n",
        "\n",
        "len(word_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyGVDL9KzJ_I"
      },
      "source": [
        "### Criando um vocabulário"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Com a contagem de palavras podemos definir uma função para criar um novo vocabulário:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vocab(word_counts:Counter, vocab_size:int) -> Tuple[Dict[str, int], List[str]]:\n",
        "    \"\"\"\n",
        "    Generates the vocabulary with the most frequent words.\n",
        "\n",
        "    Args:\n",
        "        word_counts (Counter): word count to generate vocabulary.\n",
        "        vocab_size (int): maximum size for the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, int]: vocabulary mapping words to codes.\n",
        "        List[str]: inverse vocabulary mapping codes to words.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    most_frequent_words = [word for word, count in word_counts.most_common(vocab_size)]\n",
        "    vocab = {word: i for i, word in enumerate(most_frequent_words, 1)}\n",
        "\n",
        "    inverse_vocab = list(vocab.keys())\n",
        "\n",
        "    return vocab, inverse_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E podemos executar um teste mostrando a geração de um vocabulário e suas primeiras 0 entradas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_vocab_size = 1000\n",
        "test_vocab, test_inverse_vocab = create_vocab(word_counts, test_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(',', 1),\n",
              " ('a', 2),\n",
              " ('que', 3),\n",
              " ('-', 4),\n",
              " ('o', 5),\n",
              " ('de', 6),\n",
              " ('e', 7),\n",
              " (';', 8),\n",
              " ('.', 9),\n",
              " ('um', 10)]"
            ]
          },
          "execution_count": 259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(itertools.islice(test_vocab.items(), 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "É interessante observar que as palavras mais frequentes são acentuações, o que pode dificultar o aprendizado de sentenças significativas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Codificando e Decodificando sentenças"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos utilizar as seguintes funções para codificar um texto e decodificá-lo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode_sentence(sentence:Union[str,List[str]], vocab:Dict) -> List[int]:\n",
        "    \"\"\"\n",
        "    Encodes a sentence using a vocabulary.\n",
        "\n",
        "    Args:\n",
        "        sentence (Union[str,List[str]]): sentence to encode. Or a string,\n",
        "            or the string already separated into words\n",
        "        vocab (Dict): vocabulary to encode. Maps words to codes.\n",
        "\n",
        "    Returns:\n",
        "        List[int]: the encoded sentence\n",
        "    \"\"\"\n",
        "    if isinstance(sentence, list):\n",
        "        words = sentence\n",
        "    else:\n",
        "        words = sentence.split(\" \")\n",
        "    \n",
        "    return [vocab.get(word, 0) for word in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decode_sentence(encoding:List[int], inverse_vocab:List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Decodes a sentence back to words.\n",
        "\n",
        "    Args:\n",
        "        encoding (List[int]): encoded sentence to decode.\n",
        "        inverse_vocab (List[str]): inverse vocabulary. Maps codes to words\n",
        "\n",
        "    Returns:\n",
        "        List[str]: decoded sentence. Unknown codes are decoded to '???' \n",
        "    \"\"\"\n",
        "    result = []\n",
        "\n",
        "    for encoding_i in encoding:\n",
        "        if encoding_i == 0:\n",
        "            result.append(\"???\")\n",
        "        else:\n",
        "            result.append(inverse_vocab[encoding_i-1])\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wia_ygbvzJ_J"
      },
      "source": [
        "### Separação e Classe do dataset\n",
        "\n",
        "Aqui iremos definir as sentenças a partir dos textos; divídi-las em treino, teste e valiadação; e criar a classe para carregar os dados durante os experimentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Criamos as sequências com tamanhos `context_size+1`, visto que elas precisaram ser deslocadas para gerar os targets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sequences(texts:List[str], context_size:int, \n",
        "                     vocab:Dict) -> Tuple[List[List[int]], List[int]]:\n",
        "    \"\"\"\n",
        "    Creates sequences from the texts, with the target (word to predict), \n",
        "    using a fixed size and vocabulary.\n",
        "\n",
        "    Args:\n",
        "        texts (List[str]): texts to create sequences.\n",
        "        context_size (int): size of the sequences.\n",
        "        vocab (Dict): maps words to codes.\n",
        "\n",
        "    Returns:\n",
        "        List[List[int]]: created sequences.\n",
        "    \"\"\"\n",
        "\n",
        "    x_all = []\n",
        "\n",
        "    for paragraph in texts:\n",
        "        start = 0\n",
        "        end = context_size+1\n",
        "\n",
        "        paragraph = encode_sentence(paragraph, vocab)\n",
        "\n",
        "        while end < len(paragraph):\n",
        "            x = paragraph[start:end]\n",
        "            y = paragraph[end]\n",
        "\n",
        "            if not ( 0 in x or 0 == y):\n",
        "                x_all.append(x)\n",
        "\n",
        "            start += 1\n",
        "            end += 1\n",
        "            \n",
        "    x_all = np.array(x_all)\n",
        "\n",
        "    return x_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Criamos um dataset de teste e validamos que as entradas e targets possuem o mesmo tamanho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_context_size = 10\n",
        "\n",
        "test_x_all = create_sequences(cleaned_paragraphs, test_context_size, test_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert len(test_x_all[0]) == test_context_size+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para evitar viéses, definimos uma função para embaralhar o dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "gC0C5qn2zJ_J"
      },
      "outputs": [],
      "source": [
        "def shuffle_dataset(x:List) -> List[int]:\n",
        "    \"\"\"\n",
        "    Shuffle the dataset.\n",
        "\n",
        "    Args:\n",
        "        x (List): dataset elements.\n",
        "\n",
        "    Returns:\n",
        "        List: shuffled elements. \n",
        "    \"\"\"\n",
        "\n",
        "    indexes = list(range(len(x)))\n",
        "    random.shuffle(indexes)\n",
        "\n",
        "    x = x[indexes]\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_x_all = shuffle_dataset(test_x_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E separamos os dados em treino (60%), validação (20%) e teste (20%):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {},
      "outputs": [],
      "source": [
        "def separate_dataset(x_all:List[int]) -> Tuple[List[int], List[int], List[int]]:\n",
        "    \"\"\"\n",
        "    Separate the data in train, validation and test.\n",
        "\n",
        "    Args:\n",
        "        x_all (List[int]): all dataset elements.\n",
        "\n",
        "    Returns:\n",
        "        List[int]: train elements. \n",
        "        List[int]: validation elements.\n",
        "        List[int]: test elements.\n",
        "    \"\"\"\n",
        "    size_all = len(x_all)\n",
        "\n",
        "    cut1 = int(0.6*size_all)\n",
        "    cut2 = int(0.8*size_all)\n",
        "\n",
        "    x_train = x_all[0:cut1]\n",
        "\n",
        "    x_val = x_all[cut1:cut2]\n",
        "\n",
        "    x_test = x_all[cut2:]\n",
        "\n",
        "    return x_train, x_val, x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Separamos os conjuntos e demonstramos que a separação separa corretamente os dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_x_train, test_x_val, test_x_test = separate_dataset(test_x_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert len(test_x_train)+len(test_x_val)+len(test_x_test) == len(test_x_all)\n",
        "\n",
        "assert len(test_x_train) == int(0.6*len(test_x_all))\n",
        "assert (len(test_x_val) == np.floor(0.2*len(test_x_all)) or len(test_x_val) == np.ceil(0.2*len(test_x_all)))\n",
        "assert (len(test_x_test) == np.floor(0.2*len(test_x_all)) or len(test_x_test) == np.ceil(0.2*len(test_x_all)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Criamos a classe para manipular o dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TextPredictDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Text prediction dataset.\n",
        "\n",
        "    Input: sequence of encoded words.\n",
        "    Target: next word for the sequence.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, x_data:List[List[int]]) -> None:\n",
        "        \"\"\"\n",
        "        Creates a new dataset.\n",
        "\n",
        "        Args:\n",
        "            x_data (List[List[int]]): dataset elements.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self._x_data = torch.tensor(x_data).type(torch.LongTensor)-1\n",
        "        \n",
        "        self._size = len(x_data)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Gets the size of the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: dataset size.\n",
        "        \"\"\"\n",
        "\n",
        "        return self._size\n",
        "\n",
        "    def __getitem__(self, idx:int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Gets a item of the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): data index.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: dataset input. \n",
        "            torch.Tensor: dataset target.\n",
        "        \"\"\"\n",
        "        return self._x_data[idx][:-1], self._x_data[idx][1:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Geramos um dataset de exemplo e mostramos que os elementos e tamanhos das entradas e saídas estão correto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_train_dataset = TextPredictDataset(test_x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert_array_equal(test_train_dataset[0][0].shape, [test_context_size])\n",
        "assert_array_equal(test_train_dataset[0][1].shape, [test_context_size])\n",
        "\n",
        "assert_array_equal(test_train_dataset[0][1][1:-1], test_train_dataset[0][1][1:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por fim, mostramos o uso de um DataLoader e mostramos que os dados possuem tamanhos corretos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_batch_size = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_train_loader = DataLoader(test_train_dataset, batch_size=test_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = next(iter(test_train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert_array_equal(test_data[0].shape, [test_batch_size, test_context_size])\n",
        "assert_array_equal(test_data[1].shape, [test_batch_size, test_context_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Juntando tudo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para o uso posterior, podemos juntar todas as funções criadas realizando o processo completo de geração do dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_data_loaders(texts:List[str], vocab_size:int, context_size:int, batch_size:int) -> Tuple[Dict, List, DataLoader, DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    Generates a text prediction dataset.\n",
        "\n",
        "    Args:\n",
        "        texts (List[str]): texts to generate the dataset.\n",
        "        vocab_size (int): size of the vocabulary (know words).\n",
        "        context_size (int): size of the sequences.\n",
        "        batch_size (int): size of the batchs.\n",
        "\n",
        "    Returns:\n",
        "        Dict: vocabulary. Maps words to codes.\n",
        "        List: inverse vocabulary. Maps codes to words.\n",
        "        DataLoader: train DataLoader.\n",
        "        DataLoader: validation DataLoader.\n",
        "        DataLoader: test DataLoader.\n",
        "    \"\"\"\n",
        "\n",
        "    word_counts = count_words(texts)\n",
        "    vocab, inverse_vocab = create_vocab(word_counts, vocab_size)\n",
        "\n",
        "    x_all = create_sequences(texts, context_size, vocab)\n",
        "    \n",
        "    x_all = shuffle_dataset(x_all)\n",
        "\n",
        "    x_train, x_val, x_test = separate_dataset(x_all)\n",
        "\n",
        "    train_dataset = TextPredictDataset(x_train)\n",
        "    val_dataset = TextPredictDataset(x_val)\n",
        "    test_dataset = TextPredictDataset(x_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return vocab, inverse_vocab, train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5_-Yud0zJ_K"
      },
      "source": [
        "## Model\n",
        "\n",
        "Esta seção irá implementar o modelo que será treinado, começando pelas camadas de atenção, encoding posicional e embedding; seguindo pelo modelo em si e seu teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Attention\n",
        "\n",
        "A camada de atenção é implementada segundo descrito em \"Attention Is All You Need\". É implementada a versão com múltiplas cabeças de atenção e máscara causal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, embed_dim:int, num_heads:int) -> None:\n",
        "        \"\"\"\n",
        "        Creates the layer.\n",
        "\n",
        "        Args:\n",
        "            embed_dim (int): size of the embedding in the layer input and output.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embed_dim = embed_dim\n",
        "        \n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim//num_heads\n",
        "\n",
        "        if self.head_dim * num_heads != embed_dim:\n",
        "            raise ValueError(f\"embed_dim must be divisible by num_heads ({embed_dim}/{num_heads} is not integer).\")\n",
        "\n",
        "\n",
        "        #Initialize weights\n",
        "\n",
        "        #d_model = dv = dk = embed_dim\n",
        "        #h = 1\n",
        "\n",
        "        wQ = torch.Tensor(embed_dim, embed_dim) #embed, embed\n",
        "        wK = torch.Tensor(embed_dim, embed_dim) #embed, dk\n",
        "        wV = torch.Tensor(embed_dim, embed_dim) #embed, dv\n",
        "        w0 = torch.Tensor(embed_dim, embed_dim) #embed, embed\n",
        "\n",
        "        self.wQ = torch.nn.Parameter(wQ)\n",
        "        self.wK = torch.nn.Parameter(wK)\n",
        "        self.wV = torch.nn.Parameter(wV)\n",
        "        self.w0 = torch.nn.Parameter(w0)\n",
        "\n",
        "        self.register_buffer(\"dk_root\", torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32)))\n",
        "\n",
        "        for w in [self.wQ, self.wK, self.wV, self.w0]:\n",
        "            torch.nn.init.kaiming_normal_(w)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, query:torch.Tensor, key:torch.Tensor, value:torch.Tensor, is_causal:bool=False) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Process the inputs using the attention process.\n",
        "\n",
        "        Input tensors must be in [batch, sentence, embed] order.\n",
        "\n",
        "        Args:\n",
        "            query (torch.Tensor): queries tensor, are compared against the keys.\n",
        "            key (torch.Tensor): keys tensor, represents the keys.\n",
        "            value (torch.Tensor): values tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: the layer output, the values pondered by the compability between the keys and queries.\n",
        "        \"\"\"\n",
        "\n",
        "        #Check input\n",
        "        if query.shape[2] != self.embed_dim:\n",
        "            raise ValueError(f\"Inputs must have embed dimension of {self.embed_dim} ({query.shape[2]} != {self.embed_dim})\")\n",
        "\n",
        "        #Get dimensions\n",
        "        batch_size = query.shape[0]\n",
        "        context_size = query.shape[1]\n",
        "\n",
        "        #Linear input transformation\n",
        "        #Transpose weights because PyTorch does that\n",
        "        Q = query @ self.wQ.T\n",
        "        K = key @ self.wK.T\n",
        "        V = value @ self.wV.T\n",
        "\n",
        "        #batch_size, sentence, embed\n",
        "        # to\n",
        "        #batch_size,  n_head, sentence, head_dim\n",
        "        Q = Q.transpose(0,1).reshape(context_size, batch_size*self.num_heads, self.head_dim).transpose(0,1)\n",
        "        K = K.transpose(0,1).reshape(context_size, batch_size*self.num_heads, self.head_dim).transpose(0,1)\n",
        "        V = V.transpose(0,1).reshape(context_size, batch_size*self.num_heads, self.head_dim).transpose(0,1)\n",
        "        #Now we have [\n",
        "        # [batch0word0part0, batch0word1part0], \n",
        "        # [batch0word0part1, batch0word1part1],\n",
        "        # [batch1word0part0, batch1word1part0], \n",
        "        # [batch1word0part1, batch1word1part1],\n",
        "        #]\n",
        "        \n",
        "        scores = Q @ K.transpose(-2, -1) #K.permute(0,1,3,2)\n",
        "        scores /= self.dk_root\n",
        "\n",
        "        #Apply causal bias\n",
        "        if is_causal:\n",
        "            mask = torch.ones((context_size, context_size), dtype=torch.bool)\n",
        "            mask = mask.tril() #Lower triangular is one\n",
        "            mask = torch.bitwise_not(mask) #Upper triangular without diagonal is ones\n",
        "\n",
        "            attention_bias = torch.zeros((context_size, context_size), device=query.device)\n",
        "            attention_bias[mask] = -torch.inf\n",
        "        \n",
        "            scores += attention_bias\n",
        "\n",
        "\n",
        "        probs = torch.softmax(scores, dim=-1)\n",
        "        E = probs @ V\n",
        "\n",
        "        #Return elements to correct place \n",
        "        E = E.reshape(batch_size, self.num_heads, context_size, self.head_dim)\n",
        "        E = E.transpose(-3,-2)\n",
        "        E = E.reshape(batch_size, context_size, self.embed_dim)\n",
        "        #Now we have [\n",
        "        #[batch0word0, batch0word1], \n",
        "        #[batch1word0, batch1word1]\n",
        "        #]\n",
        "\n",
        "        result = E @ self.w0.T \n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para testar a camadas implementada, podemos instanciar ela junto da implementação de referência do PyTorch, e certificar que as saídas das 2 camadas são as mesmas, dado os mesmos pesos e entradas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instaciamos as camadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_embed_dim = 4\n",
        "test_num_heads = 2\n",
        "test_context_size = 3\n",
        "\n",
        "our_version = MultiHeadAttention(test_embed_dim, num_heads=test_num_heads).eval()\n",
        "torch_version = torch.nn.MultiheadAttention(test_embed_dim, num_heads=test_num_heads, bias=False, batch_first=True ).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Igualamos todos os pesos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [],
      "source": [
        "wQ = our_version.wQ\n",
        "wK = our_version.wK\n",
        "wV = our_version.wV\n",
        "w0 = our_version.w0\n",
        "\n",
        "torch_version.in_proj_weight = torch.nn.Parameter(torch.concat((wQ, wK, wV)))\n",
        "torch_version.out_proj.weight = w0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Geramos os dados de teste randomicamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = torch.rand(2, test_context_size, test_embed_dim) #2 batchs, sequences of test_context_size words, embed_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realizamos as operações com as camadas e verificamos se os resultados são os mesmos, com e sem causalidade:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_mask = torch.nn.Transformer.generate_square_subsequent_mask(test_context_size)\n",
        "\n",
        "for is_causal in [False, True]:\n",
        "\n",
        "    result_our = our_version(test_data, test_data, test_data, is_causal)\n",
        "\n",
        "    if is_causal:\n",
        "        result_torch, _ = torch_version(test_data, test_data, test_data, need_weights=False, is_causal=True, attn_mask=attention_mask)\n",
        "    else:\n",
        "        result_torch, _ = torch_version(test_data, test_data, test_data, need_weights=False)\n",
        "\n",
        "    result_our = result_our.detach()\n",
        "    result_torch = result_torch.detach()\n",
        "\n",
        "    assert result_our.shape == result_torch.shape\n",
        "    assert_array_almost_equal(result_our, result_torch, decimal=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por fim, podemos comparar a performance entre as camadas utilizando a CPU.\n",
        "\n",
        "A célula está comentada devido ao custo de executá-lo, porém os resultados estão disponíveis a seguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%timeit our_version(test_data, test_data, test_data)\n",
        "#%timeit torch_version(test_data, test_data, test_data, need_weights=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Our: 208 µs ± 13.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
        "Torch: 260 µs ± 21.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Curiosamente a implementação do PyTorch é mais lenta, porém pode ser devido as maiores capacidades que possue e checagens que executa. É importante que ressaltar que esses resultados são apenas para a execução utilizando a CPU.\n",
        "\n",
        "Comparado com o exercício anterior (sem multi-head) o custo de execução praticamente dobrou, possivelmente pelo custo de manipular a configuração dos dados na memória para realizar as operações."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Positional Encoding\n",
        "\n",
        "A camada de encoding posicional é implementada com funções periódicas, assim como o paper \"Attention is All You Need\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SinePositionalEncoding(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Positional enconding using sine/cossine function.\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim:int, sequence_size:int) -> None:\n",
        "        \"\"\"\n",
        "        Creates the layer.\n",
        "\n",
        "        Args:\n",
        "            embed_dim (int): embedding size in the input and output.\n",
        "            sequence_size (int): size of the sequence in the input and output.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        #Caches the positions encodings:\n",
        "        position = torch.arange(sequence_size, dtype=torch.float32)\n",
        "        expoent = 2.0*torch.arange(embed_dim, dtype=torch.float32)/embed_dim\n",
        "\n",
        "        pe = torch.empty((sequence_size, embed_dim))\n",
        "\n",
        "        pe.T[:] = position\n",
        "        pe /= torch.pow(1e4, expoent)\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(pe[:, 0::2])\n",
        "        pe[:, 1::2] = torch.cos(pe[:, 1::2])\n",
        "\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, input_tensor:torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Adds the positions encodings to the input.\n",
        "\n",
        "        Args:\n",
        "            input_tensor (torch.Tensor): input tensor to receive the positions encodings\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: input + positional encoding.\n",
        "        \"\"\"\n",
        "        output = input_tensor + self.pe\n",
        "\n",
        "        return output\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testamos a camada utilizando uma entrada nula para verificar se as codificações estão corretas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_embed_dim = 5\n",
        "test_sequence_size = 3\n",
        "\n",
        "test_data = torch.zeros(2, test_sequence_size, test_embed_dim) #2 batchs, sequences of 3 words, embed_dim\n",
        "\n",
        "positional_encoding = SinePositionalEncoding(test_embed_dim, test_sequence_size)\n",
        "\n",
        "result = positional_encoding(test_data)\n",
        "\n",
        "assert_array_equal(result[0], result[1]) #Correct operation across batchs\n",
        "assert_array_not_equal(result[0, 0], result[0, 1]) #Different positions -> Different encodings\n",
        "assert_array_not_equal(result[0,:,0], result[0,:,1]) #Different dimensions -> Different encodings\n",
        "assert len(list(positional_encoding.parameters())) == 0 #No trainable parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para o embedding utilizamos uma matriz de look-up aprendível, assim como \"A Neural Probabilistic Language Model\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Embedding(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Converts codes to embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim:int, vocab_size:int) -> None:\n",
        "        \"\"\"\n",
        "        Creates a new Embedding layer.\n",
        "\n",
        "        Args:\n",
        "            embed_dim (int): size of the embedding in the output.\n",
        "            vocab_size (int): size of the vocabulary the words were coded.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        C = torch.Tensor(vocab_size, embed_dim)\n",
        "        torch.nn.init.xavier_uniform_(C)\n",
        "        self.C = torch.nn.Parameter(C)\n",
        "\n",
        "    def forward(self, input_tensor:torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Embeds the input sequences.\n",
        "\n",
        "        Args:\n",
        "            input_tensor (torch.Tensor): sequences to be embeded.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: result embeddings.\n",
        "        \"\"\"\n",
        "        \n",
        "        #OBS: I checked, \"index_select\" doesn't work with batchs, \"index\" (third parameter) must be 1-D\n",
        "        result = torch.stack([torch.index_select(self.C, 0, input_i) for input_i in input_tensor])\n",
        "        \n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E testamos se a camada gera o embedding corretamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_embed_dim = 2\n",
        "test_vocab_size = 3\n",
        "test_sequence_size = test_vocab_size\n",
        "\n",
        "test_data = torch.empty((2, test_sequence_size), dtype=int)\n",
        "test_data[:] = torch.arange(test_vocab_size)\n",
        "\n",
        "embedding = Embedding(test_embed_dim, test_vocab_size)\n",
        "\n",
        "result = embedding(test_data)\n",
        "result = result.detach()\n",
        "\n",
        "C = embedding.C.detach()\n",
        "\n",
        "assert_array_equal(C.shape, [test_vocab_size, test_embed_dim]) #C matrix have correct shape\n",
        "assert_array_equal(result.shape, [2, test_sequence_size, test_embed_dim])\n",
        "assert_array_equal(result[0], result[1]) #Correct operation across batchs\n",
        "assert_array_equal(result[0, 0], C[0]) #First result = embedding of first word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformDecoderBlock(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Block of a Transform Decoder.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim:int, n_head:int, dropout_rate:float=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attention = MultiHeadAttention(embed_dim, n_head)\n",
        "        self.dropout_attention = torch.nn.Dropout(dropout_rate)\n",
        "        self.layer_norm1 = torch.nn.LayerNorm(embed_dim)\n",
        "        self.linear1 = torch.nn.Linear(embed_dim, 4*embed_dim)\n",
        "        self.dropout_linear1 = torch.nn.Dropout(dropout_rate)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(4*embed_dim, embed_dim)\n",
        "        self.dropout_linear2 = torch.nn.Dropout(dropout_rate)\n",
        "        self.layer_norm2 = torch.nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        #Masked Multi-Head Attention\n",
        "        y1 = self.dropout_attention(self.attention(x, x, x, is_causal=True))\n",
        "        \n",
        "        #Add & Norm\n",
        "        y1 = x+y1\n",
        "        y1 = self.layer_norm1(y1)\n",
        "        \n",
        "        #Feed Forward\n",
        "        y2 = self.dropout_linear1(self.linear1(y1))\n",
        "        y2 = self.relu(y2)\n",
        "        y2 = self.dropout_linear2(self.linear2(y2))\n",
        "        \n",
        "        #Add & Norm\n",
        "        result = y1+y2\n",
        "        result = self.layer_norm2(result)\n",
        "\n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por fim, defimos o modelo de linguagem utilizando as camadas criadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "I2qKG9YczJ_K"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Language model using Decorder-only Transform.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim:int, vocab_size:int, sequence_size:int, n_head:int, n_block:int, dropout_rate:float=0.0) -> None:\n",
        "        \"\"\"\n",
        "        Creates a new model\n",
        "\n",
        "        Args:\n",
        "            embed_dim (int): size of the embeddings between layers.\n",
        "            vocab_size (int): size of the vocabulary the inputs were coded.\n",
        "            sequence_size (int): size of the input sequences.\n",
        "            n_head (int): number of attention heads in each attention layer.\n",
        "            n_block (int): number of decoder blocks in the model.\n",
        "            dropout_rate (float, optional): dropout between layers rate. Defaults to 0.0.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = Embedding(embed_dim, vocab_size)\n",
        "\n",
        "        self.positional_encoding = SinePositionalEncoding(embed_dim, sequence_size)\n",
        "        self.dropout_encoding = torch.nn.Dropout(dropout_rate)\n",
        "\n",
        "        blocks = [TransformDecoderBlock(embed_dim, n_head, dropout_rate) for _ in range(n_block)]\n",
        "        self.decoder_blocks = torch.nn.Sequential(*blocks)\n",
        "\n",
        "\n",
        "        self.linear_out = torch.nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Predicts the next word of the sequence.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): sequence.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: next word predicted.\n",
        "        \"\"\"\n",
        "        y = self.embedding(x)\n",
        "        y = self.dropout_encoding(self.positional_encoding(y))\n",
        "\n",
        "        y = self.decoder_blocks(y)\n",
        "        \n",
        "        y = self.linear_out(y)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testamos o modelo com uma entrada aleatória para verificar se as saídas possuem tamanhos corretos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "7yjQ1KXOzJ_K"
      },
      "outputs": [],
      "source": [
        "test_embed_dim = 8\n",
        "test_vocab_size = 1000\n",
        "test_sequence_size = 10\n",
        "test_n_head = 2\n",
        "test_n_block = 2\n",
        "\n",
        "test_model = LanguageModel(test_embed_dim, test_vocab_size, test_sequence_size, test_n_head, test_n_block)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "xmsD59TfzJ_K"
      },
      "outputs": [],
      "source": [
        "test_input, test_target = next(iter(test_train_loader))\n",
        "\n",
        "output = test_model(test_input)\n",
        "\n",
        "assert_array_equal(output.shape, [test_batch_size, test_sequence_size, test_vocab_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50])"
            ]
          },
          "execution_count": 292,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_target.reshape(-1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50, 1000])"
            ]
          },
          "execution_count": 293,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.view(-1, test_vocab_size).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50, 1000])"
            ]
          },
          "execution_count": 294,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.view(-1, output.shape[-1]).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UngUhyu7zJ_L"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Com o modelo e dados definidos, podemos iniciar o treinamento.\n",
        "\n",
        "Começamos definindo qual será o dispositivo utilizado para o treino:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wntaV50nzJ_L",
        "outputId": "a054092b-d801-4c60-eb75-85abfe57151d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 296,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Criamos algumas funções que serão utilizadas durante o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ppl(loss:torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the perplexity from the loss.\n",
        "\n",
        "    Args:\n",
        "        loss (torch.Tensor): loss to compute the perplexity.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: corresponding perplexity.\n",
        "    \"\"\"\n",
        "    return torch.exp(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_loss(model:torch.nn.Module, loader:DataLoader, criterion:torch.nn.Module) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the loss from a model across a dataset, without gradient and in eval mode.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): model to evaluate.\n",
        "        loader (DataLoader): dataset.\n",
        "        criterion (torch.nn.Module): loss function to compute.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: resulting loss.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        n = 0\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            targets = targets.reshape(-1)\n",
        "            targets = targets.to(device)\n",
        "            \n",
        "            logits = model(inputs)\n",
        "            logits = logits.view(-1, logits.shape[-1])\n",
        "\n",
        "            loss = criterion(logits.squeeze(), targets)\n",
        "            total_loss += loss*targets.size(0)\n",
        "\n",
        "            n += targets.size(0)\n",
        "\n",
        "        total_loss /= n \n",
        "    \n",
        "    return total_loss.detach()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_info(loss_value:torch.Tensor, epoch:int, total_epochs:int, time:float=0.0):\n",
        "    \"\"\"\n",
        "    Prints the information of a epoch.\n",
        "\n",
        "    Args:\n",
        "        loss_value (torch.Tensor): epoch loss.\n",
        "        epoch (int): epoch number.\n",
        "        total_epochs (int): total number of epochs. \n",
        "        time (float, optional): time to run the epoch. Don't print if is 0.0. Defaults to 0.0.\n",
        "    \"\"\"\n",
        "    ppl_value = ppl(loss_value)\n",
        "\n",
        "    \n",
        "    print(f'Epoch [{epoch+1}/{total_epochs}], \\\n",
        "            Loss: {loss_value.item():.4f}, \\\n",
        "            Perplexity: {ppl_value.item():.4f}', end=\"\")\n",
        "    \n",
        "    if time != 0:\n",
        "        print(f\", Elapsed Time: {time:.2f} sec\")    \n",
        "    else:\n",
        "        print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E realizamos o processo de treino, iniciando pela definição dos parâmetros que serão utilizados. Neste caso estão aqui os parâmetros que geraram o melhor treinamento, com todos os resultados de todas as variações testadas disponíveis em [https://api.wandb.ai/links/eltoncn/hgqa8mss](https://api.wandb.ai/links/eltoncn/hgqa8mss)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32 # Tamanho do batch\n",
        "context_size = 9 # n palavras de entrada. O target é a próxima palavra\n",
        "dropout_rate = 0.15 #Dropout entre as camadas\n",
        "embed_dim = 64 # Tamanho do feature vector de cada palavra\n",
        "epochs = 10 # Quantidade de epochs que serão treinadas\n",
        "lr = 2.5e-3 # Taxa de treinamento\n",
        "optimizer_class = torch.optim.Adam #torch.optim.SGD\n",
        "vocab_size = 3000 # Quantidade de palavras no vocabulário\n",
        "weight_decay = 3e-4 # Regularização L2\n",
        "\n",
        "n_block = 4\n",
        "n_head = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E se será realizado o logging utilizando o wandb:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_wandb = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para garantir reprodutibilidade, a geração de todos os datasets e todos os treinos são realizados as mesmas sementes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {},
      "outputs": [],
      "source": [
        "reset_seeds()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instanciamos todos os objetos necessários:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab, inverse_vocab, train_loader, val_loader, test_loader = create_data_loaders(cleaned_paragraphs, vocab_size, context_size, batch_size)\n",
        "\n",
        "model = LanguageModel(embed_dim, vocab_size, context_size, n_head, n_block, dropout_rate)\n",
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optimizer_class(model.parameters(), lr=lr, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Iniciamos o logging:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"vocab_size\": vocab_size,\n",
        "    \"context_size\": context_size,\n",
        "    \"embed_dim\": embed_dim,\n",
        "    \"epochs\": epochs,\n",
        "    \"lr\": lr,\n",
        "    \"weight_decay\": weight_decay,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"optimizer_class\": optimizer_class.__name__,\n",
        "    \"dropout_rate\": dropout_rate\n",
        "}\n",
        "\n",
        "if use_wandb:\n",
        "    wandb.init(project=\"IA024-03-Attention\", config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E realizamos o treino:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 366,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/10],             Loss: 8.0923,             Perplexity: 3269.2993\n",
            "Epoch [1/10],             Loss: 6.2013,             Perplexity: 493.3946, Elapsed Time: 4.54 sec\n",
            "VAL Epoch [1/10],             Loss: 6.1152,             Perplexity: 452.6650\n",
            "Epoch [2/10],             Loss: 6.1123,             Perplexity: 451.3926, Elapsed Time: 4.46 sec\n",
            "VAL Epoch [2/10],             Loss: 6.1103,             Perplexity: 450.4702\n",
            "Epoch [3/10],             Loss: 6.0390,             Perplexity: 419.4547, Elapsed Time: 4.41 sec\n",
            "VAL Epoch [3/10],             Loss: 5.7073,             Perplexity: 301.0711\n",
            "Epoch [4/10],             Loss: 5.3561,             Perplexity: 211.8882, Elapsed Time: 4.26 sec\n",
            "VAL Epoch [4/10],             Loss: 4.9352,             Perplexity: 139.0987\n",
            "Epoch [5/10],             Loss: 4.7341,             Perplexity: 113.7593, Elapsed Time: 4.20 sec\n",
            "VAL Epoch [5/10],             Loss: 4.4758,             Perplexity: 87.8663\n",
            "Epoch [6/10],             Loss: 4.3704,             Perplexity: 79.0736, Elapsed Time: 4.24 sec\n",
            "VAL Epoch [6/10],             Loss: 4.1952,             Perplexity: 66.3681\n",
            "Epoch [7/10],             Loss: 4.1514,             Perplexity: 63.5230, Elapsed Time: 4.24 sec\n",
            "VAL Epoch [7/10],             Loss: 4.0339,             Perplexity: 56.4813\n",
            "Epoch [8/10],             Loss: 3.9884,             Perplexity: 53.9692, Elapsed Time: 4.54 sec\n",
            "VAL Epoch [8/10],             Loss: 3.9382,             Perplexity: 51.3274\n",
            "Epoch [9/10],             Loss: 3.8570,             Perplexity: 47.3253, Elapsed Time: 4.68 sec\n",
            "VAL Epoch [9/10],             Loss: 3.8061,             Perplexity: 44.9753\n",
            "Epoch [10/10],             Loss: 3.7464,             Perplexity: 42.3695, Elapsed Time: 4.32 sec\n",
            "VAL Epoch [10/10],             Loss: 3.7077,             Perplexity: 40.7611\n"
          ]
        }
      ],
      "source": [
        "hist = {}\n",
        "hist[\"loss_train\"] = []\n",
        "hist[\"loss_val\"] = []\n",
        "hist[\"ppl_train\"] = []\n",
        "hist[\"ppl_val\"] = []\n",
        "\n",
        "prev_loss = compute_loss(model, train_loader, criterion)\n",
        "print_info(prev_loss, -1, epochs, 0)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time() \n",
        "\n",
        "    model.train()\n",
        "\n",
        "    loss_train = torch.tensor(0, dtype=torch.float32, device=device)\n",
        "    n_train = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        \n",
        "        targets = targets.reshape(-1)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        logits = model(inputs)\n",
        "        logits = logits.view(-1, vocab_size)\n",
        "\n",
        "        loss : torch.Tensor = criterion(logits.squeeze(), targets)\n",
        "\n",
        "        loss_train += loss*targets.size(0)\n",
        "        n_train += targets.size(0)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    end_time = time.time() \n",
        "    epoch_duration = end_time - start_time \n",
        "\n",
        "    loss_train /= n_train\n",
        "    ppl_train = ppl(loss_train)\n",
        "\n",
        "    print_info(loss_train, epoch, epochs, epoch_duration)\n",
        "    \n",
        "    print(\"VAL \", end=\"\")\n",
        "    loss_val = compute_loss(model, val_loader, criterion)\n",
        "    ppl_val = ppl(loss_val)\n",
        "    print_info(loss_val, epoch, epochs)\n",
        "\n",
        "    hist[\"loss_train\"].append(loss_train.item())\n",
        "    hist[\"loss_val\"].append(loss_val.item())\n",
        "    hist[\"ppl_train\"].append(ppl_train.item())\n",
        "    hist[\"ppl_val\"].append(ppl_val.item())\n",
        "\n",
        "    log = {\n",
        "        \"loss_train\": loss_train.item(),\n",
        "        \"loss_val\": loss_val.item(),\n",
        "        \"ppl_train\": ppl_train.item(),\n",
        "        \"ppl_val\": ppl_val.item()\n",
        "    }\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.log(log)\n",
        "\n",
        "for key in hist:\n",
        "    hist[key] = np.array(hist[key])\n",
        "\n",
        "if use_wandb:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos checar a perda e perplexidade obtidas durante o treino. Um ponto relevante é o rápido overfitting que ocorre, possivelmente pelo tamanho limitado pelo conjunto de treino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 367,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(hist[\"loss_train\"], \"o-\")\n",
        "plt.plot(hist[\"loss_val\"], \"o-\")\n",
        "\n",
        "plt.legend([\"Train\", \"Val\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss history\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 368,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(hist[\"ppl_train\"]/vocab_size, \"o-\")\n",
        "plt.plot(hist[\"ppl_val\"]/vocab_size, \"o-\")\n",
        "\n",
        "plt.legend([\"Train\", \"Val\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Normalized PPL\")\n",
        "plt.title(\"Perplexity history\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-374-e4c8e09828d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "raise ValueError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSXfwYISDoPN"
      },
      "source": [
        "## Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A avaliação é realizada calculando a perplexidade do modelo no conjunto de teste. É calculada apenas a perplexidade do melhor modelo nos dados de validação, para reportar a capacidade de generalização do modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXXO78GSDqPg"
      },
      "outputs": [],
      "source": [
        "test_loss = compute_loss(model, test_loader, criterion)\n",
        "test_ppl = ppl(test_loss)\n",
        "\n",
        "test_ppl.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculamos também a quantidade total de parâmetros utilizados pelo modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 404,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "585912"
            ]
          },
          "execution_count": 404,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_param = sum([p.numel() for p in model.parameters()])\n",
        "n_param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1zhxVqfzJ_M"
      },
      "source": [
        "## Exemplo de uso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para uso do modelo, definimos uma função para gerar mais texto até obter o tamanho máximo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 402,
      "metadata": {
        "id": "3PExkoWOzJ_M"
      },
      "outputs": [],
      "source": [
        "def generate_text(model:torch.nn.Module, vocab:Dict, inverse_vocab:List, text:str, max_length:int) -> str:\n",
        "    \"\"\"\n",
        "    Generates a text to complete the previous.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): language model to use.\n",
        "        vocab (Dict): vocabulary. Maps words to codes.\n",
        "        inverse_vocab (List): inverse vocabulary. Maps codes to words.\n",
        "        text (str): text to complete.\n",
        "        max_length (int): maximum length to obtain.\n",
        "\n",
        "    Returns:\n",
        "        str: generated text.\n",
        "    \"\"\"\n",
        "\n",
        "    text = clean_text(text)\n",
        "\n",
        "    total_length = len(text.split(\" \"))\n",
        "\n",
        "    last_sequence = create_sequences([text], context_size, vocab)[-1][1:]\n",
        "    last_sequence = torch.tensor(last_sequence)-1\n",
        "    last_sequence = last_sequence.to(device)\n",
        "\n",
        "    new_characters = []\n",
        "\n",
        "    while total_length < max_length:\n",
        "                \n",
        "        output = model(torch.unsqueeze(last_sequence, 0))\n",
        "\n",
        "        next_encoded = output[0][-1].argmax()\n",
        "\n",
        "        last_sequence = torch.cat((last_sequence[1:], torch.tensor([next_encoded]).to(device)))\n",
        "        \n",
        "        new_characters.append(next_encoded.item())\n",
        "\n",
        "        total_length += 1\n",
        "\n",
        "    new_characters = np.array(new_characters)+1\n",
        "\n",
        "    new_text = \" \".join(decode_sentence(new_characters, inverse_vocab))\n",
        "\n",
        "    return new_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "E geramos um texto de exemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OLD\n",
            "nesse instante erguia a cabeça e fitava os olhos n'uma sebe de folhas que se elevava a vinte passos de distancia , e se\n",
            "\n",
            "GENERATED CONTINUATION\n",
            "de novo ao rio , e o italiano , e de novo ao mesmo tempo , e o italiano , e de um homem de sua senhora , e a sua senhora , e a sua senhora , e a sua senhora , e a sua\n"
          ]
        }
      ],
      "source": [
        "text = cleaned_paragraphs[200]#300]\n",
        "max_length = 70\n",
        "\n",
        "new_text = generate_text(model, vocab, inverse_vocab, text, max_length)\n",
        "\n",
        "print(\"OLD\")\n",
        "print(text)\n",
        "print(\"\")\n",
        "print(\"GENERATED CONTINUATION\")\n",
        "print(new_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "É perceptível como que o modelo rapidamente colapsa para uma sequência fixa."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
