{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhjrdWXuPMeW"
      },
      "source": [
        "## Module 2 - Fine-tuning Phi-1.5 for sentence classification using QLoRA\n",
        "\n",
        "This notebook presents an example of how to fine-tune Phi-1.5 for sentence classification using QLoRA.\n",
        "\n",
        "QLoRA is a fine-tuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. For more details, please refer to the [QLoRA paper](https://arxiv.org/abs/2106.09647).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dFZ6y7XMXD4"
      },
      "source": [
        "# Installing required packages\n",
        "\n",
        "In this example, we have to install the following libraries:  `transformers`, `datasets`, `torch`, `peft`, `bitsandbytes`, and `trl`.\n",
        "\n",
        "**`transformers`**:\n",
        "\n",
        "Transformers is an open-source library for NLP developed by Hugging Face. It provides state-of-the-art pre-trained models for various NLP tasks, such as text classification, sentiment analysis, question-answering, named entity recognition, etc.\n",
        "\n",
        "**`datasets`**:\n",
        "\n",
        "Datasets is another open-source library developed by Hugging Face that provides a collection of preprocessed datasets for various NLP tasks, such as sentiment analysis, natural language inference, machine translation, and many more.\n",
        "\n",
        "\n",
        "**`torch`**:\n",
        "\n",
        "PyTorch is an open-source machine learning library that provides a wide range of tools and utilities for building and training custom deep learning models. It is already installed in the Colab environment, but we need to install its latest version.\n",
        "\n",
        "**`peft`**:\n",
        "\n",
        "ðŸ¤— PEFT, or Parameter-Efficient Fine-Tuning (PEFT), is a library for efficiently adapting pre-trained language models (PLMs) to various downstream applications without fine-tuning all the modelâ€™s parameters. We use PEFT in this example because it supports QLoRA.\n",
        "\n",
        "\n",
        "**`bitsandbytes`**:\n",
        "\n",
        "BitsAndBytes is a library designed to optimize the training of neural networks on modern GPUs. It offers efficient implementations of 8-bit optimizers, which significantly reduce the memory footprint of model parameters and gradients. This reduction in memory usage enables training larger models or using larger batch sizes within the same memory constraints.\n",
        "\n",
        "\n",
        "**`trl`**:\n",
        "\n",
        "ðŸ¤— TRL, or Transfer Learning Library, is a library for training and evaluating transfer learning models. It provides a unified API for training and evaluating various transfer learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdrBm7o4LPRb",
        "outputId": "594166b1-ca3f-405f-ddd2-4deb08929a35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import load_entry_point\n",
            "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
            "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import load_entry_point\n",
            "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 542 kB 18.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.19.5)\n",
            "Collecting pyarrow>=12.0.0\n",
            "  Downloading pyarrow-16.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.9 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40.9 MB 62.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pyarrow-hotfix\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116 kB 10.0 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.63.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194 kB 14.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.16-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132 kB 25.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2024.3.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.9.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3 MB 37.2 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.21.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.4.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240 kB 40.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129 kB 29.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (308 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308 kB 20.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0; python_version < \"3.11\"\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow, pyarrow-hotfix, dill, xxhash, multiprocess, frozenlist, aiosignal, multidict, yarl, async-timeout, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.19.0 dill-0.3.8 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 pyarrow-16.0.0 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n",
            "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import load_entry_point\n",
            "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
            "\u001b[31mERROR: torchaudio 0.12.1 has requirement torch==1.12.1, but you'll have torch 2.2.2 which is incompatible.\u001b[0m\n",
            "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import load_entry_point\n",
            "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
            "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import load_entry_point\n",
            "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#!pip install -q torch\n",
        "!pip install -q git+https://github.com/huggingface/transformers #huggingface transformers for downloading models weights\n",
        "!pip install datasets\n",
        "!pip install -q peft  # Parameter efficient finetuning - for qLora Finetuning\n",
        "!pip install -q bitsandbytes  # For Model weights quantization\n",
        "!pip install -q trl  # Transformer Reinforcement Learning - For Finetuning using Supervised Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install seaborn\n",
        "!pip install pynvml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "from collections import Counter\n",
        "import json\n",
        "import re\n",
        "from pprint import pprint\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from huggingface_hub import notebook_login\n",
        "from peft import LoraConfig, PeftModel\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from trl import SFTTrainer # For supervised finetuning\n",
        "import pynvml\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGdm9g9fkjxE"
      },
      "source": [
        "# Setting the device\n",
        "\n",
        "In this example, we will use a GPU to speed up the fine-tuning process. GPUs (Graphics Processing Units) are specialized processors that are optimized for performing large-scale computations in parallel. By using a GPU, we can accelerate the training and inference of a machine learning model, which can significantly reduce the time required to complete these tasks.\n",
        "\n",
        "Before we begin, we need to check whether a GPU is available and select it as the default device for our PyTorch operations. This is because PyTorch can use either a CPU or a GPU to perform computations, and by default, it will use the CPU.\n",
        "\n",
        "For using a GPU in Google Colab:\n",
        "1. Click on the \"Runtime\" menu at the top of the screen.\n",
        "2. From the dropdown menu, click on \"Change runtime type\".\n",
        "3. In the popup window that appears, select \"A100 GPU\" as the hardware accelerator.\n",
        "4. Click on the \"Save\" button.\n",
        "\n",
        "That's it! Now you can use the GPU for faster computations in your notebook.\n",
        "\n",
        "**IMPORTANT**: This example requires a GPU with at least 40GB of memory. If you are using Google Colab, you can select a GPU with 40GB of memory by following the steps above. If you are using a different environment, please make sure that your GPU has at least 40GB of memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiV9Y1ZweR2Y",
        "outputId": "83273329-9f44-4211-a02a-a48c5cf14d1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Apr 22 16:14:54 2024       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Quadro RTX 8000     On   | 00000000:3D:00.0 Off |                  Off |\n",
            "| 33%   28C    P8    32W / 260W |      5MiB / 48601MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwYGaELZMwvZ"
      },
      "source": [
        "# Downloading Dataset\n",
        "\n",
        "The SST-2 dataset, or the Stanford Sentiment Treebank, is popular for sentiment analysis tasks in Natural Language Processing (NLP). It consists of movie reviews from the Rotten Tomatoes website that are labeled with either a positive or negative sentiment. The dataset contains 10,662 sentence-level movie reviews, with approximately half of the reviews labeled as positive and the other half labeled as negative. The reviews are also relatively evenly distributed in length, with a median length of 18 tokens.\n",
        "\n",
        "The SST-2 dataset has become a benchmark dataset for sentiment analysis in NLP, and many researchers use it to evaluate the performance of their models. The dataset's popularity is partly due to its high-quality labels and the task's relative simplicity, making it an accessible starting point for researchers and developers new to NLP.\n",
        "\n",
        "In this example, we're using the **`datasets`** library to download and load the training and validation sets of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbX4laO5M6FC",
        "outputId": "5da92422-8eed-470d-cd9c-8e4d50af8bd1"
      },
      "outputs": [],
      "source": [
        "test_dataset = load_dataset('imdb', split='test')\n",
        "train_dataset = load_dataset('imdb', split='train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OyZ3D_rKEK2"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "Now, we will prepare the data for training our model. First, we define a template with the fields `sentence` and `class`. Then, we use the `map` method to apply this template to the dataset. This will create a new dataset with the fields `sentence` and `class` for each example in the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EBjlqME6VUJn"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"<s>[INST] Your task is to classify sentences' sentiment as 'positive' or 'negative'.\n",
        "\n",
        "Sentence: {text} [\\INST]\n",
        "{class}</s>\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1ZalJmCxLn9"
      },
      "source": [
        "Before, we need to convert the labels from 0 and 1 to \"negative\" and \"positive\". We can do this by using the `map` method to apply a function to each example in the dataset. The function will take the label as input and return the corresponding string and store in the column `class`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4fc5d8efd4164cf98c78817dca300750",
            "69db67eed1ac460cb00fd7ae57fb8336",
            "f27c32a8a41e4766852235fe7657eb18",
            "9054a08a953b4664af94a5d834945950",
            "c0e35d69570b4f0bb45967d7e420226c",
            "ccdf7cde1a834ffdb45261016e8018da",
            "ae9b48d0776e453a961aad557a490be5",
            "ab21c7ec21104159ab595d7d65913e24",
            "79e14c8e280f4bb7a860825f85737a93",
            "731e3053925a411b9357632b78aa0dc0",
            "ba875b0928a74707b6ca9cf23e66c2f9"
          ]
        },
        "id": "65ew6vQDKEz7",
        "outputId": "61be84b5-d4e8-48f3-856b-a8eaa9171faa"
      },
      "outputs": [],
      "source": [
        "POSITIVE_LABEL = \"positive\"\n",
        "NEGATIVE_LABEL = \"negative\"\n",
        "\n",
        "train_dataset = train_dataset.map(lambda example: {'class': POSITIVE_LABEL if example[\"label\"] == 1 else NEGATIVE_LABEL})\n",
        "train_dataset = train_dataset.map(lambda example: {\"text\": template.format(**example)})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE2EQjQ69uLJ"
      },
      "source": [
        "The code below converts the `label` column of the test dataset into a list of strings with `\"positive\"` and `\"negative\"` labels. This is for comparing the model's predictions with the actual labels of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jCts-_zF9uLM"
      },
      "outputs": [],
      "source": [
        "test_dataset = test_dataset.map(lambda example: {'class': POSITIVE_LABEL if example[\"label\"] == 1 else NEGATIVE_LABEL})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyAho1DLxg7z"
      },
      "source": [
        "# Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-_4YGOYRpmu"
      },
      "source": [
        "## Setting Model Parameters\n",
        "\n",
        "We need to set various parameters for our fine-tuning process, including QLoRA (Quantization LoRA) parameters, bitsandbytes parameters, and training arguments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H76_erzt1-on"
      },
      "outputs": [],
      "source": [
        "# The model that you want to train from the Hugging Face hub\n",
        "# model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "model_name = \"microsoft/phi-1_5\"\n",
        "\n",
        "# Fine-tuned model name\n",
        "new_model = \"phi-1_5-IMDB\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKzTy9MbR2DY"
      },
      "source": [
        "Setting the QLora Parameters\n",
        "\n",
        "1. **lora_r (LoRA attention dimension)**:\n",
        "   - the rank of the update matrices, expressed in int. Lower rank results in smaller update matrices with fewer trainable parameters.\n",
        "\n",
        "2. **lora_alpha (Alpha parameter for LoRA scaling)**:\n",
        "   - This parameter is the LoRA scaling factor applied to the modifications.\n",
        "\n",
        "3. **lora_dropout (Dropout probability for LoRA layers)**:\n",
        "   - This parameter represents the dropout rate applied to the LoRA layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pXH06fiYybTF"
      },
      "outputs": [],
      "source": [
        "# LoRA attention dimension\n",
        "lora_r = 64 # @param\n",
        "\n",
        "# Alpha parameter for LoRA scaling\n",
        "lora_alpha = 16 # @param\n",
        "\n",
        "# Dropout probability for LoRA layers\n",
        "lora_dropout = 0.1 # @param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g69uRG5jzCEZ"
      },
      "source": [
        "Bitsandbytes parameters. These parameters focus on the implementation of 4-bit precision in model loading and computation. Here's an explanation of each:\n",
        "\n",
        "1. **use_4bit (Activate 4-bit precision base model loading)**:\n",
        "   - This parameter, when set to `True`, indicates that the base model (i.e., the pre-trained model or initial model weights) should be loaded using 4-bit precision.\n",
        "2. **bnb_4bit_compute_dtype (Compute dtype for 4-bit base models)**:\n",
        "   - This parameter specifies the data type to be used for computations in the context of 4-bit base models.\n",
        "   - The value `\"float16\"` indicates that computations should be done using 16-bit floating-point numbers.\n",
        "\n",
        "3. **bnb_4bit_quant_type (Quantization type)**:\n",
        "   - This parameter determines the type of quantization to be used for the 4-bit models.\n",
        "   - The options `\"fp4\"` and `\"nf4\"` refer to different quantization schemes.\n",
        "\n",
        "4. **use_nested_quant (Activate nested quantization for 4-bit base models)**:\n",
        "   - When set to `True`, this parameter enables nested quantization for 4-bit base models.\n",
        "   - Nested quantization, often referred to as double quantization, involves applying a second layer of quantization on top of an already quantized model. This can be used for further reducing the model size or for specialized computational optimizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MtraXCCMzJAc"
      },
      "outputs": [],
      "source": [
        "# Activate 4-bit precision base model loading\n",
        "use_4bit = True # @param\n",
        "\n",
        "# Compute dtype for 4-bit base models\n",
        "bnb_4bit_compute_dtype = \"float16\" # @param\n",
        "\n",
        "# Quantization type (fp4 or nf4)\n",
        "bnb_4bit_quant_type = \"nf4\" # @param [\"nf4\",\"fp4\"]\n",
        "\n",
        "# Activate nested quantization for 4-bit base models (double quantization)\n",
        "use_nested_quant = True # @param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHTSrnU00F2u"
      },
      "source": [
        "Now, let's define the training arguments.\n",
        "\n",
        "1. **output_dir**:\n",
        "   - Specifies the directory where the model predictions and checkpoints will be stored.\n",
        "\n",
        "2. **num_train_epochs**:\n",
        "   - Sets the number of epochs for training, where one epoch means one pass through the entire training dataset. We set it to `1`\n",
        "\n",
        "3. **fp16, bf16**:\n",
        "   - Enable training with 16-bit floating-point precision (`fp16`) or 16-bit bfloat precision (`bf16`).\n",
        "\n",
        "4. **per_device_train_batch_size**:\n",
        "   - Determines the batch size for training per GPU. This will depend on the GPU used. For an A100, we can use a batch size of 16 examples.\n",
        "\n",
        "5. **per_device_eval_batch_size**:\n",
        "   - Sets the batch size for evaluation per GPU.\n",
        "\n",
        "6. **gradient_accumulation_steps**:\n",
        "   - Indicates the number of update steps over which to accumulate gradients.\n",
        "\n",
        "7. **gradient_checkpointing**:\n",
        "   - When enabled, saves memory by trading compute for memory. Useful for training large models that would otherwise not fit in memory.\n",
        "\n",
        "8. **max_grad_norm (Maximum gradient norm)**:\n",
        "   - Specifies the maximum norm of gradients for gradient clipping, a technique to prevent exploding gradients in deep networks.\n",
        "\n",
        "9. **learning_rate**:\n",
        "   - Sets the initial learning rate for the AdamW optimizer.\n",
        "\n",
        "10. **weight_decay**:\n",
        "    - Specifies the weight decay to apply to all layers except those with bias or LayerNorm weights, as a regularization technique.\n",
        "\n",
        "11. **optim**:\n",
        "    - Defines the optimizer to use, here specified as a variant of AdamW optimized for certain hardware configurations.\n",
        "\n",
        "12. **lr_scheduler_type**:\n",
        "    - Determines the learning rate schedule to use. \"constant\" means the learning rate stays the same throughout training.\n",
        "\n",
        "13. **max_steps**:\n",
        "    - Overrides `num_train_epochs` by setting the number of training steps. If set to a negative value, it's ignored. We set this to `100` to reduce the training time. That means, that our example training does not use the entire traing set.\n",
        "\n",
        "14. **warmup_ratio**:\n",
        "    - Indicates the proportion of total training steps to use for linear warmup of the learning rate.\n",
        "\n",
        "15. **group_by_length**:\n",
        "    - When enabled, sequences are grouped by length into batches. This can save memory and speed up training.\n",
        "\n",
        "16. **save_steps**:\n",
        "    - Determines how often to save a model checkpoint in terms of training steps.\n",
        "\n",
        "17. **logging_steps**:\n",
        "    - Sets the frequency, in terms of training steps, for logging training progress.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ayWlSa-s0SJ2"
      },
      "outputs": [],
      "source": [
        "# Output directory where the model predictions and checkpoints will be stored\n",
        "output_dir = \"./results\" # @param\n",
        "\n",
        "# Number of training epochs\n",
        "num_train_epochs = 1 # @param\n",
        "\n",
        "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
        "fp16 = False # @param\n",
        "bf16 = False # @param\n",
        "\n",
        "# Batch size per GPU for training\n",
        "per_device_train_batch_size = 4 # @param\n",
        "\n",
        "# Batch size per GPU for evaluation\n",
        "per_device_eval_batch_size = 4 # @param\n",
        "\n",
        "# Number of update steps to accumulate the gradients for\n",
        "gradient_accumulation_steps = 1 # @param\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "gradient_checkpointing = True # @param\n",
        "\n",
        "# Maximum gradient normal (gradient clipping)\n",
        "max_grad_norm = 0.3 # @param\n",
        "\n",
        "# Initial learning rate (AdamW optimizer)\n",
        "learning_rate = 5e-4 # @param\n",
        "\n",
        "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
        "weight_decay = 0.001 # @param\n",
        "\n",
        "# Optimizer to use\n",
        "optim = \"paged_adamw_32bit\" # @param\n",
        "\n",
        "# Learning rate schedule (constant a bit better than cosine)\n",
        "lr_scheduler_type = \"constant\" # @param\n",
        "\n",
        "# Number of training steps (overrides num_train_epochs)\n",
        "max_steps = 100 # @param\n",
        "\n",
        "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
        "warmup_ratio = 0.03 # @param\n",
        "\n",
        "# Group sequences into batches with same length\n",
        "# Saves memory and speeds up training considerably\n",
        "group_by_length = True # @param\n",
        "\n",
        "# Save checkpoint every X updates steps\n",
        "save_steps = 25 # @param\n",
        "\n",
        "# Log every X updates steps\n",
        "logging_steps = 25 # @param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypfndp911mbp"
      },
      "source": [
        "Now let's defint the SFTTrainer parameters\n",
        "\n",
        "1. **max_seq_length**:\n",
        "   - This parameter specifies the maximum sequence length to be used.\n",
        "\n",
        "2. **packing**:\n",
        "   - This parameter indicates whether or not to pack multiple short examples into the same input sequence.\n",
        "   - When set to `True`, this technique can be used to increase computational efficiency, particularly in batch processing.\n",
        "\n",
        "3. **device_map**:\n",
        "   - This parameter is a dictionary that maps parts of the model to specific computing devices.\n",
        "   - The entry `{\"\": 0}` specifies that the entire model will be loaded onto GPU 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A_Yi1p_BR0bA"
      },
      "outputs": [],
      "source": [
        "# Maximum sequence length to use\n",
        "max_seq_length = None\n",
        "\n",
        "# Pack multiple short examples in the same input sequence to increase efficiency\n",
        "packing = False\n",
        "\n",
        "# Load the entire model on the GPU 0\n",
        "device_map = {\"\": 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "269-A6vtSNfg"
      },
      "source": [
        "### Lets Load the base model\n",
        "Let's load the Mistral 7B Instruct base model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd00Qz6P2LDn"
      },
      "source": [
        "Load the base model with QLoRA configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QrBd2aB95aoj"
      },
      "outputs": [],
      "source": [
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")\n",
        "\n",
        "base_model.config.use_cache = False\n",
        "base_model.config.pretraining_tp = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_zPMcIO2M4S"
      },
      "source": [
        "Load tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5STGmYHw2ORV"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxYdQFqo5aol"
      },
      "source": [
        "## Fine-Tuning with QLoRA and Supervised Fine-Tuning\n",
        "\n",
        "We're ready to fine-tune our model using QLoRA. For this tutorial, we'll use the `SFTTrainer` from the `trl` library.\n",
        "\n",
        "In the context of the code below, `target_modules` refers to specific components or layers of a neural network model that will be modified or adapted using LoRA (Low-Rank Adaptation). LoRA is a technique used to adapt pre-trained models with minimal additional parameters, often used in the context of Transformer models. Here's a breakdown of what each module likely represents:\n",
        "\n",
        "1. **q_proj, k_proj, v_proj, o_proj**:\n",
        "   - These refer to the projections for query (q), key (k), value (v), and output (o) in the attention mechanism of a Transformer model.\n",
        "\n",
        "2. **gate_proj**:\n",
        "   - This refer to a projection layer associated with gating mechanisms in the model, such as those found in Gated Recurrent Units (GRUs) or similar structures.\n",
        "\n",
        "3. **up_proj, down_proj**:\n",
        "   - These refer to projection layers used in upsampling or downsampling within the model.\n",
        "\n",
        "4. **lm_head**:\n",
        "   - This refers to the language model head of a Transformer, which is the final layer that produces the output (like the next word in a sequence)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "7b6dde22828c44729f28309d65eae1c6",
            "bb1c6d418b3e40f2bfa5d1258ef6e197",
            "4f36c9b0b6fc4fcfa25ca317731ffd2b",
            "9c7a81a7d03a4b32b2021b750c7cc73c",
            "c0cb94e4f9f64db99d533613742a60ac",
            "f81e097860984800970910f17ed127cc",
            "9bb6773b3281465cb1533261035e686a",
            "c3193cae4e594a238bf8fae3a613ba57",
            "b910b8b28bb348648ec5cb689cd31fe5",
            "19a4e1b8f531484ead63d60ab7610f7c",
            "b43906472dbb401fbd0eb3dfa1e68c4e"
          ]
        },
        "id": "nFjA8D0d2oNz",
        "outputId": "3e6b724e-e9bb-4194-d337-223be8cc96a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [00:08<00:00, 2974.73 examples/s]\n",
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "# Load LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "# Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=base_model,\n",
        "    train_dataset=train_dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i187wmtT5aol"
      },
      "source": [
        "## Let's start the training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def get_used_memory():\n",
        "    pynvml.nvmlInit()\n",
        "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "    info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
        "    mem = info.used/1024**2\n",
        "    \n",
        "    return mem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2476.875"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_used_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "xWxi9tqgEhyZ",
        "outputId": "0f31a0be-e972-487d-b8ea-f0bd011d8aaf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 01:38, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3.300300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.706000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>3.109400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.836300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.8/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.8/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.8/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.8/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Save trained model\n",
        "trainer.model.save_pretrained(new_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28248.875"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_used_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PixsfVRz38YA"
      },
      "source": [
        "## Merge the fine-tuned model\n",
        "\n",
        "After fine-tuning, we can merge the fine-tuned model with the base model to get a single model that can be used for inference. This is done by using the PEFT. First, let's clean up the GPU memory by deleting the fine-tuned model. You can also restart the runtime to clear the GPU memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujf17z-7--l5",
        "outputId": "bdac249e-61e7-4637-acfb-981a4f67eb03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20729"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Empty VRAM\n",
        "\n",
        "del base_model\n",
        "gc.collect()\n",
        "\n",
        "del trainer\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ypNIoSou-_3j"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-cOpLlC_A48",
        "outputId": "430ede60-296c-4c4e-f3c7-00f87413d8cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1312.875"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_used_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAYoqNyp7m7n"
      },
      "source": [
        "Now, let's load the base model and fine-tuned model and merge them using PEFT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IRWhV5WZ3-BO"
      },
      "outputs": [],
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map={\"\": 0},\n",
        ")\n",
        "merged_model= PeftModel.from_pretrained(base_model, new_model,)\n",
        "merged_model= merged_model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NlvU92-7xnR"
      },
      "source": [
        "Let's save our merged model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "oIYyv_y07zrZ"
      },
      "outputs": [],
      "source": [
        "# Save the merged model\n",
        "merged_model.save_pretrained(\"merged_model\", safe_serialization=True)\n",
        "tokenizer.save_pretrained(\"merged_model\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_hU2be-5aom"
      },
      "source": [
        "## Test the merged model\n",
        "\n",
        "The following code performs the inference stage of the evaluation finetuned Mistral-7B-Instruct model. We define a function called **`classify_sentence`** that is designed to use a pretrained model, likely a variant of a large language model similar to GPT, for sentiment analysis. The description below outlines the steps taken in the function to classify the sentiment of a given sentence as either positive, negative, or possibly neutral. I'll expand on the description by going through the function step-by-step:\n",
        "\n",
        "1. The function accepts a single parameter, `sentence`, which is the text input whose sentiment is to be classified.\n",
        "\n",
        "2. The `sentence` is formatted with the predefined prompt template. This prompt engineering is a common practice when using language models for specific tasks, as it provides context to the model about the task it is supposed to perform.\n",
        "\n",
        "3. The `tokenizer` is applied to the formatted text. Tokenizers convert text into a format that models can understand, which in this case is a series of tokens. The tokenizer is configured to:\n",
        "   - Return tensors compatible with PyTorch (`return_tensors=\"pt\"`).\n",
        "   - Not add special tokens that are usually used to indicate the start and end of a sequence (`add_special_tokens=False`).\n",
        "\n",
        "4. The tokenized input (`encodeds`) is then converted to a PyTorch tensor and moved to the appropriate device (GPU) for inference.\n",
        "\n",
        "5. The inference is performed inside a `torch.no_grad()` context manager, which disables gradient calculations. This is used because we are making predictions, not training the model, and therefore do not need gradients, which would only use extra memory and computational power.\n",
        "\n",
        "6. The `model.generate` function is called to generate a response. This function takes several parameters, such as:\n",
        "   - `**model_inputs`: The tokenized inputs prepared earlier.\n",
        "   - `max_length=8000`: This sets the maximum length of the model's output. The choice of 8000 seems unusually high for sentence classification and might be tailored to specific requirements of the task or the model's capacity.\n",
        "   - `bos_token_id=model.config.bos_token_id`: This specifies the beginning-of-sentence token id, signaling the model where a new sentence starts.\n",
        "   - `eos_token_id=model.config.eos_token_id`: This specifies the end-of-sentence token id, signaling the model where a sentence ends.\n",
        "   - `pad_token_id=model.config.eos_token_id`: This is used for padding shorter sentences to a uniform length. It's unusual to see the end-of-sentence token used for padding, which could be a specific requirement of this model or a mistake.\n",
        "\n",
        "7. After the model generates a response, `torch.cuda.empty_cache()` is called to free up unused memory on the GPU. This is helpful in managing GPU resources, especially when processing multiple requests or dealing with large models.\n",
        "\n",
        "8. Finally, the `tokenizer.decode` function is used to convert the model's output tokens back into human-readable text. The `skip_special_tokens=True` argument removes any special tokens (like padding or end-of-sentence tokens) from the output. The function also skips the input tokens (`outputs[0][len(model_inputs[\"input_ids\"][0]):]`) to only return the newly generated text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lf05Fbfe224z",
        "outputId": "53383d91-c5d1-44bf-9216-d6aa13d4ca0d"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\"\n",
        "prompt = \"\"\"<s>[INST]You are a sentiment classifier. Use only \"positive\" or \"negative\".\n",
        "\n",
        "Sentence: {sentence}[\\INST]\n",
        "\"\"\"\n",
        "def classify_sentence(sentence, model, print_memory:bool=False, max_new_tokens:int=1):\n",
        "  text = prompt.format(sentence=sentence)\n",
        "  encodeds = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
        "  model_inputs = encodeds.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model.generate(**model_inputs,max_new_tokens=max_new_tokens,bos_token_id=model.config.bos_token_id,\n",
        "                                eos_token_id=model.config.eos_token_id,\n",
        "                                pad_token_id=model.config.eos_token_id\n",
        "                             )\n",
        "    \n",
        "    if print_memory:\n",
        "      mem = get_used_memory()\n",
        "      print(f\"Used {mem} MB for inference\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  return tokenizer.decode(outputs[0][len(model_inputs[\"input_ids\"][0]):], skip_special_tokens=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classify_sentence(\"This movie is too bad\", merged_model, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O28cCRIP4ZsJ"
      },
      "source": [
        "The code below uses the **`classify_sentence`** function to make predictions on the test dataset. We loop through the test dataset and apply the **`classify_sentence`** function to each example. The predictions are stored in a list called **`predictions`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "references = test_dataset[\"class\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3awVyved9AgW",
        "outputId": "d18eac4f-08c7-4d7c-e64e-f62eed377655"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25000 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 13151/25000 [10:48<10:42, 18.43it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2259 > 2048). Running this sequence through the model will result in indexing errors\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [19:39<00:00, 21.19it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions = []\n",
        "for item in tqdm(test_dataset):\n",
        "  predicted = classify_sentence(item['text'], merged_model)\n",
        "  predictions.append(predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlWk2IL9L_ay",
        "outputId": "b28144f1-5ecf-4282-dbcb-19d60ccad920"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('positive', 20497),\n",
              " ('negative', 3974),\n",
              " ('\\n', 264),\n",
              " ('', 183),\n",
              " ('<', 46),\n",
              " ('-', 20),\n",
              " ('2', 10),\n",
              " ('4', 3),\n",
              " ('*', 3)]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "Counter(predictions).most_common()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'positive': 20497,\n",
              "         'negative': 3974,\n",
              "         '\\n': 264,\n",
              "         '': 183,\n",
              "         '2': 10,\n",
              "         '<': 46,\n",
              "         '-': 20,\n",
              "         '4': 3,\n",
              "         '*': 3})"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "XXEyUMHwVKJ-"
      },
      "outputs": [],
      "source": [
        "predictions = [\"positive\" if p == \"pos\" else p for p in predictions] #Useless"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyKJR-CmVwxF"
      },
      "source": [
        "# Evaluation Metric\n",
        "\n",
        "To compute accuracy, we need to define a custom **`string_accuracy`** function since model outputs text rather than numerical values. Therefore, we cannot use the built-in accuracy function directly, which expects numerical values as inputs.\n",
        "\n",
        "The following code defines the **`string_accuracy`** function. It takes two lists of strings as inputs, **`predictions`** and **`references`**. The function computes accuracy by counting the number of predictions that match the corresponding reference and dividing by the total number of predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZtITggRdVvsD"
      },
      "outputs": [],
      "source": [
        "def string_accuracy(predictions, references):\n",
        "    correct = sum([1 for p, r in zip(predictions, references) if p.lower() == r.lower()])\n",
        "    total = len(predictions)\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SltQDZS9zyt",
        "outputId": "551e7431-501e-4230-d0e8-ae0d354a5c5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.645"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy = string_accuracy(predictions=predictions, references=references)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "predictions_np = np.array(predictions)\n",
        "mask = predictions_np == \"positive\"\n",
        "mask = np.bitwise_or(mask, predictions_np == \"negative\")\n",
        "\n",
        "predictions_changed = np.array(predictions)\n",
        "predictions_changed[np.bitwise_not(mask)] = \"negative\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "qO0ibw-L-Y8t",
        "outputId": "2a7ce594-b983-4fc2-ca76-de02f0c88531"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Convert labels to a numerical form\n",
        "labels = {\"positive\": 1, \"negative\": 0}\n",
        "y_true_num = [labels[label] for label in references]\n",
        "y_pred_num = [labels[label] for label in predictions_changed]\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.array(y_true_num), np.array(y_pred_num))\n",
        "\n",
        "# Plot the confusion matrix using seaborn\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\n",
        "\n",
        "# Labels, title, and ticks\n",
        "ax.set_ylabel('Actual Label')\n",
        "ax.set_xlabel('Predicted Label')\n",
        "ax.set_title('Confusion Matrix')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['negative', 'positive'], dtype='<U8'), array([12500, 12500]))"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(np.array(train_dataset[\"class\"]), return_counts=True) #Dataset balanceado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AcurÃ¡cia prÃ©-finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.875"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "    del base_model\n",
        "    gc.collect()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    del merged_model\n",
        "    gc.collect()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    del new_model\n",
        "    gc.collect()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "get_used_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map={\"\": 0},\n",
        ")\n",
        "\n",
        "base_model.config.use_cache = False\n",
        "base_model.config.pretraining_tp = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def batch_classify_sentence(sentences, model, print_memory:bool=False, max_new_tokens:int=1):\n",
        "  texts = []\n",
        "  for sentence in sentences:\n",
        "      text = prompt.format(sentence=sentence)\n",
        "      texts.append(text)\n",
        "\n",
        "  encodeds = tokenizer(texts, return_tensors=\"pt\", add_special_tokens=False, padding=True)\n",
        "  model_inputs = encodeds.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model.generate(**model_inputs,max_new_tokens=max_new_tokens,bos_token_id=model.config.bos_token_id,\n",
        "                                eos_token_id=model.config.eos_token_id,\n",
        "                                pad_token_id=model.config.eos_token_id\n",
        "                             )\n",
        "    \n",
        "    if print_memory:\n",
        "      mem = get_used_memory()\n",
        "      print(f\"Used {mem} MB for inference\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  decodeds = []\n",
        "  for i in range(outputs.shape[0]):\n",
        "      decoded = tokenizer.decode(outputs[i][len(model_inputs[\"input_ids\"][i]):], skip_special_tokens=True)\n",
        "\n",
        "      decodeds.append(decoded)\n",
        "\n",
        "  del outputs, model_inputs\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  return decodeds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ordenamos o dataset de teste pelo tamanho do texto para uso eficiente da GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cmp_func(series):\n",
        "    sizes = []\n",
        "    for element in series:\n",
        "        sizes.append(len(element))\n",
        "    return sizes\n",
        "\n",
        "df = test_dataset.to_pandas()\n",
        "df.sort_values(by=[\"text\"], key=cmp_func, #By text size\n",
        "                inplace=True, #Inplace \n",
        "                ascending=False) #Descending (if memory error, first)\n",
        "test_datset_sorted = Dataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3492.875"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_used_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realiza a inferÃªncia por batchs, agrupando as sentenÃ§as atÃ© uma quantidade mÃ¡xima de caractÃ©res (considerando que as sentenÃ§as menores no batch irÃ£o receber padding):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3002 > 2048). Running this sequence through the model will result in indexing errors\n",
            "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [12:18<00:00, 33.86it/s]\n"
          ]
        }
      ],
      "source": [
        "max_size = 250000\n",
        "max_batch_size = 32\n",
        "\n",
        "predictions_base = []\n",
        "sentences = []\n",
        "total_size = 0\n",
        "bigger = 0\n",
        "for i in tqdm(range(len(test_datset_sorted))):\n",
        "    sentences.append(test_datset_sorted[i]['text'])\n",
        "\n",
        "    if len(test_datset_sorted[i]['text']) > bigger:\n",
        "        bigger = len(test_datset_sorted[i]['text'])\n",
        "\n",
        "    total_size = bigger*len(sentences)\n",
        "\n",
        "    if total_size >= max_size or len(sentences) >= max_batch_size:\n",
        "\n",
        "        predictions_base += batch_classify_sentence(sentences, base_model, max_new_tokens=8)\n",
        "\n",
        "        total_size = 0\n",
        "        bigger = 0\n",
        "        sentences = []\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('\\nOnce upon a time, in a', 4904),\n",
              " ('\\n\\n\\n\\nOnce upon a time,', 2727),\n",
              " ('\\n\\n\\n\\n\\nOnce upon a', 1666),\n",
              " ('\\n\\n\\n\\n(1). [Person', 1119),\n",
              " ('\\n\\n\\n(1). [Person1', 1088),\n",
              " ('\\n\\n\\n\\n\\n\\nOnce upon a', 1075),\n",
              " ('\\n\\n\\n\\nOnce upon a time', 1057),\n",
              " ('\\n\\n\\n\\n\\nOnce upon a time', 998),\n",
              " ('\\n\\n\\n\\n# In[ ]:', 374),\n",
              " ('\\n\\n\\n\\nTemplate 1: [Person', 354),\n",
              " ('\\n\\n\\n\\nTemplate 3: [Person', 309),\n",
              " ('\\n<|begin of the story using', 296),\n",
              " ('\\n\\n\\n\\n# Importing the libraries', 287),\n",
              " ('\\n\\n\\n\\nimport nltk\\n', 251),\n",
              " ('\\n\\n\\n\\n\\n\\nQuestion 1:', 249),\n",
              " ('\\nExercise 1: Identify the', 186),\n",
              " ('\\n\\n\\n\\n<p>\\n\\n', 171),\n",
              " ('\\n\\n\\n\\n# In[1]:', 169),\n",
              " ('\\nExercise 1: What is the', 165),\n",
              " ('\\n1. To make a delicious cake', 160),\n",
              " ('\\n<s>[INST]You are', 138),\n",
              " ('\\n1. The movie \"You are', 118),\n",
              " ('\\n\\n\\n\\n# Importing the necessary', 91),\n",
              " ('\\nExercise 2:\\n\\nRead', 90),\n",
              " ('\\n\\n\\n\\nPossible story:\\n', 88),\n",
              " ('\\n1. The film \"You are', 87),\n",
              " ('\\n\\n\\n\\n<|begin of one', 77),\n",
              " ('\\n\\n\\n\\n\\n# Chapter:', 72),\n",
              " ('\\n<|begin of one example|', 55),\n",
              " ('\\nSentence: The movie is a', 50),\n",
              " ('\\n\\n\\n\\n# Solution\\n\\n#', 49),\n",
              " ('\\n\\n\\n\\n[\\\\s]\\n', 45),\n",
              " ('\\n\\n\\n\\n\\n## TAKING', 44),\n",
              " ('\\n1. How to make a delicious', 42),\n",
              " ('\\n\\n\\n\\n[\\\\INST]You', 42),\n",
              " ('\\nSentence: The movie was a', 41),\n",
              " ('\\nAnswer:\\n\\nSentence:', 41),\n",
              " ('\\nExercise: What is the main', 40),\n",
              " ('\\n1. To make a delicious smooth', 40),\n",
              " ('\\n\\n\\n\\n#importing the libraries', 38),\n",
              " ('\\nSentence: The film is a', 37),\n",
              " ('\\nOnce upon a time in a small', 37),\n",
              " ('\\n\\n\\n\\n\\n\\nTitle: The', 37),\n",
              " ('\\n\\n\\n\\n\\n## THE IMP', 36),\n",
              " ('\\nSentence: The [noun', 35),\n",
              " ('\\n\\nOnce upon a time,', 34),\n",
              " ('\\n\\n\\n\\n<p>\\n<', 31),\n",
              " ('\\n1. To understand the concept of', 29),\n",
              " ('\\nExercise 1:\\nWhat is', 29),\n",
              " ('\\nExercise 2:\\n\\nWrite', 29),\n",
              " ('\\n\\n\\n\\n<s>You are', 29),\n",
              " ('\\n\\n\\n\\n<s>The story', 29),\n",
              " ('\\n\\n\\n\\n# Chapter: The use', 29),\n",
              " ('\\n\\n\\n\\n# The use of Python', 28),\n",
              " (\"\\n<s>I'm sorry,\", 27),\n",
              " ('\\n\\n\\nOnce upon a time, in', 27),\n",
              " ('\\n\\n\\n\\n\\n## Chapter:', 25),\n",
              " ('\\nExercise 2:\\n\\nWhat', 24),\n",
              " ('\\n\\n\\n\\n# This is the main', 22),\n",
              " ('\\n\\n\\nTemplate 3: [Person1', 21),\n",
              " ('\\n<b>Template 1:</', 20),\n",
              " ('\\n1. The protagonist of the story', 19),\n",
              " ('\\n1. The movie is a comedy', 17),\n",
              " (\"\\nSentence: I'm not sure\", 17),\n",
              " ('\\nSentence: The movie \"The', 16),\n",
              " ('\\n\\n\\n\\n\\n## THE SC', 16),\n",
              " ('\\n1. To understand the impact of', 15),\n",
              " ('\\n1. To understand the meaning of', 14),\n",
              " (\"\\n1. The film's lack of\", 13),\n",
              " ('\\n1. The film is a comedy', 13),\n",
              " ('\\nSentence: I am a sentiment', 13),\n",
              " ('\\n<s>[VERB1]', 13),\n",
              " ('\\n\\n\\n\\n<|begin of story', 13),\n",
              " ('\\n1. The movie was a disaster', 12),\n",
              " ('\\n1. The movie was a disappointment', 12),\n",
              " ('\\nSentence: The [s]', 12),\n",
              " ('\\n1. The film is a masterpiece', 11),\n",
              " (\"\\n1. The film's plot is\", 11),\n",
              " ('\\n1. The movie \"You Are', 11),\n",
              " ('\\n\\n\\n\\n<s>The movie', 11),\n",
              " ('\\n\\n\\n\\n[\\\\s]*', 11),\n",
              " ('\\n<|begin of story|>', 10),\n",
              " ('\\n<|begin of template|>', 10),\n",
              " (\"\\nSentence: I'm sorry,\", 10),\n",
              " ('\\n1. How to analyze a film', 10),\n",
              " ('\\n<br /><br />\\n', 10),\n",
              " ('\\n1. The detective was able to', 10),\n",
              " ('\\n\\n\\n\\n<s>[INST]', 10),\n",
              " ('\\n1. To create a sense of', 10),\n",
              " ('\\n\\n\\n\\n# import the necessary packages', 10),\n",
              " ('\\nSentence: The film was a', 9),\n",
              " ('\\n1. How can I improve my', 9),\n",
              " ('\\n<b>Template 2:</', 9),\n",
              " ('\\n1. The movie was a hit', 9),\n",
              " ('\\n<s>The movie was a', 9),\n",
              " ('\\nExercise 2:\\n\\nEx', 9),\n",
              " ('\\n1. To create a captivating', 9),\n",
              " ('\\nSentence: I am a movie', 9),\n",
              " ('\\n1. To create a suspenseful', 9),\n",
              " ('\\n\\n\\n\\n<s>I am', 9),\n",
              " ('\\n```python\\nimport nlt', 9),\n",
              " ('\\n1. The teacher assigned a project', 8),\n",
              " ('\\n1. The movie was a terrible', 8),\n",
              " ('\\n1. The movie is a terrible', 8),\n",
              " ('\\n<s>\\n\\n\\n', 8),\n",
              " ('\\n\\n\\n\\n<s>[VERB', 8),\n",
              " ('\\n1. To understand the plot of', 8),\n",
              " ('\\nAnswer: The sentence is a positive', 8),\n",
              " ('\\n1. The film is a horror', 7),\n",
              " ('\\n1. The movie \"The Man', 7),\n",
              " ('\\nExercise: Identify the genre', 7),\n",
              " ('\\n\\n\\n\\n# This is the code', 7),\n",
              " ('\\n1. How to analyze a poem', 7),\n",
              " ('\\n1. The movie \"Crossfire', 6),\n",
              " ('\\n1. The film \"Don\\'t', 6),\n",
              " ('\\nExercise: Identify the tone', 6),\n",
              " ('\\n1. The movie adaptation of \"', 6),\n",
              " ('\\n1. The protagonist of the film', 6),\n",
              " ('\\n<br /><br />I', 6),\n",
              " (\"\\nSentence: I'm a movie\", 6),\n",
              " (\"\\nSentence: I'm a sentiment\", 6),\n",
              " ('\\nSentence: The man tried to', 6),\n",
              " ('\\n<s>I am a sentiment', 6),\n",
              " ('\\n<s>You are a sentiment', 6),\n",
              " ('\\nAnswer: Positive\\n\\nExercise', 6),\n",
              " ('\\n<p>\\n\\nOnce upon', 6),\n",
              " ('\\nAnswer:\\n\\n1. Positive', 6),\n",
              " ('\\n\\n\\n\\n<br /><br', 6),\n",
              " ('\\n# In[ ]:\\n\\n\\n', 6),\n",
              " ('\\n1. The film \"Apocalypse', 5),\n",
              " ('\\n1. The film \"The Be', 5),\n",
              " ('\\n1. The film was a success', 5),\n",
              " ('\\n1. What is the main theme', 5),\n",
              " ('\\n1. The film is a classic', 5),\n",
              " ('\\n1. The film is a great', 5),\n",
              " ('\\n1. How do you analyze a', 5),\n",
              " ('\\n1. The movie \"Kramer', 5),\n",
              " ('\\n1. The film \"Flesh', 5),\n",
              " ('\\n1. The movie \"Opera', 5),\n",
              " ('\\n1. The movie \"Throw M', 5),\n",
              " (\"\\n1. The film's budget was\", 5),\n",
              " ('\\n1. The director of the film', 5),\n",
              " ('\\n1. The movie \"The Last', 5),\n",
              " (\"\\nSentence: I can't believe\", 5),\n",
              " ('\\n1. How can I make a', 5),\n",
              " (\"\\nSentence: I'm not a\", 5),\n",
              " ('\\n1. The movie \"Tourist', 5),\n",
              " (\"\\n1. The actor's performance was\", 5),\n",
              " ('\\n1. The film opens with a', 5),\n",
              " ('\\n1. The movie is boring because', 5),\n",
              " ('\\n1. The movie was disappointing because', 5),\n",
              " ('\\n1. The film is based on', 5),\n",
              " ('\\n1. The film \"You Are', 5),\n",
              " ('\\nSentence: I was really looking', 5),\n",
              " ('\\n1. The movie was terrible because', 5),\n",
              " ('\\n1. The film begins with a', 5),\n",
              " ('\\nExercise 2:\\n\\nRew', 5),\n",
              " ('\\n\\n\\n\\n<s>\\n\\n', 5),\n",
              " ('\\n<s>I am a movie', 5),\n",
              " ('\\nAnswer: The sentence is a negative', 5),\n",
              " ('\\n\\n\\n\\n#importing the necessary', 5),\n",
              " ('\\n\\n\\n\\n[\\\\s]The', 5),\n",
              " ('\\n\\n\\n\\n<s>The following', 5),\n",
              " ('\\n\\n\\n\\nExercise 2:\\n', 5),\n",
              " ('\\n\\n\\n\\n# Solution\\n\\nimport', 5),\n",
              " ('\\n\\n\\nTemplate 1: [Person1', 5),\n",
              " ('\\n<br /><br />The', 5),\n",
              " ('\\nAnswer:\\n\\n```python', 5),\n",
              " ('\\n1. The film \"2001:', 4),\n",
              " ('\\n1. The film \"The Man', 4),\n",
              " ('\\n1. The film \"Wallace', 4),\n",
              " ('\\n1. The movie \"The Great', 4),\n",
              " ('\\n1. The film is about a', 4),\n",
              " ('\\n1. The film \"The English', 4),\n",
              " (\"\\n1. Charlie Wilson's War is\", 4),\n",
              " ('\\n1. The movie \"Talk Radio', 4),\n",
              " ('\\n1. The film \"Northfork', 4),\n",
              " ('\\n1. The movie \"The Cure', 4),\n",
              " ('\\n1. The movie \"Night of', 4),\n",
              " ('\\n1. The movie was a lot', 4),\n",
              " ('\\n1. The movie \"Piran', 4),\n",
              " (\"\\n1. The film's cinematography\", 4),\n",
              " ('\\nSentence: The first time I', 4),\n",
              " ('\\n1. The film \"The Violent', 4),\n",
              " ('\\n1. The film is a terrible', 4),\n",
              " ('\\nSentence: I am a big', 4),\n",
              " ('\\n1. The movie \"Murder', 4),\n",
              " ('\\n1. How do you make a', 4),\n",
              " ('\\n1. The movie \"Man with', 4),\n",
              " ('\\n1. The film is terrible because', 4),\n",
              " ('\\n1. The movie \"The Big', 4),\n",
              " ('\\n1. The film \"Death Bed', 4),\n",
              " ('\\n1. The film \"Midnight', 4),\n",
              " ('\\n1. The sentence is about a', 4),\n",
              " ('\\n1. The movie was boring because', 4),\n",
              " ('\\n<s>I have to say', 4),\n",
              " ('\\nExercise 1:\\n\\nWhat', 4),\n",
              " ('\\nExercise 2:\\n\\nIdent', 4),\n",
              " ('\\nSentence: This film is a', 4),\n",
              " ('\\nExercise 1:\\nIdentify', 4),\n",
              " ('\\nSentence: I think this movie', 4),\n",
              " ('\\nSentence: This is one of', 4),\n",
              " ('\\n1. To understand the emotions of', 4),\n",
              " ('\\nSentence: When I first saw', 4),\n",
              " ('\\n<s>I have always been', 4),\n",
              " ('\\n1. To make a delicious apple', 4),\n",
              " ('\\nSentence: This movie is a', 4),\n",
              " ('\\nSentence: The movie was terrible', 4),\n",
              " ('\\n\\n\\n\\n\\nQuestion 1: A', 4),\n",
              " (\"\\n1. To analyze the film's\", 4),\n",
              " ('\\n\\n\\n\\n# This is a program', 4),\n",
              " ('\\nAnswer:\\n\\nThe sentence is', 4),\n",
              " ('\\n1. The film \"Never Say', 3),\n",
              " ('\\n1. The film \"Fata', 3),\n",
              " (\"\\n1. The film's opening scene\", 3),\n",
              " (\"\\n1. The playwright's use\", 3),\n",
              " ('\\n1. The movie \"Wicked', 3),\n",
              " ('\\n1. The movie \"They Died', 3),\n",
              " ('\\n1. To create a beautiful painting', 3),\n",
              " ('\\n1. The movie \"House of', 3),\n",
              " ('\\n1. The movie \"The Thing', 3),\n",
              " ('\\n1. The film was a masterpiece', 3),\n",
              " ('\\nSentence: **SPOILERS', 3),\n",
              " ('\\n1. The Lone Ranger is a', 3),\n",
              " (\"\\n1. The film's use of\", 3),\n",
              " ('\\n1. The film \"The Vampire', 3),\n",
              " ('\\n1. The film \"Crossfire', 3),\n",
              " ('\\n1. The film \"My Architect', 3),\n",
              " ('\\n1. The film \"The Deer', 3),\n",
              " ('\\n1. The movie \"The Shaw', 3),\n",
              " ('\\n1. The movie \"Fright', 3),\n",
              " ('\\n1. The film \"House of', 3),\n",
              " ('\\n1. The film \"Shadows', 3),\n",
              " ('\\n1. The movie \"Bloody', 3),\n",
              " ('\\n1. The movie is a great', 3),\n",
              " ('\\n1. The film \"River\\'s', 3),\n",
              " ('\\nSentence: The teacher assigned a', 3),\n",
              " ('\\n1. The film \"The Railway', 3),\n",
              " ('\\n1. The film \"Strangers', 3),\n",
              " ('\\n1. The movie \"Ray\"', 3),\n",
              " ('\\n1. The movie \"The Buddy', 3),\n",
              " ('\\n1. The movie \"Graduation', 3),\n",
              " ('\\n1. The film adaptation of \"', 3),\n",
              " ('\\nSentence: I was really disappointed', 3),\n",
              " ('\\n1. The movie \"Flat', 3),\n",
              " ('\\n1. The film \"The Best', 3),\n",
              " ('\\n1. The film \"KÃ¶r', 3),\n",
              " ('\\n1. The film \"Batman Returns', 3),\n",
              " ('\\nSentence: If you are a', 3),\n",
              " ('\\n1. The movie is terrible because', 3),\n",
              " ('\\nSentence: The [sport', 3),\n",
              " ('\\n1. The movie \"Strangers', 3),\n",
              " ('\\n1. The movie starts with a', 3),\n",
              " ('\\n1. The film \"National Velvet', 3),\n",
              " ('\\n1. The movie \"The Haunted', 3),\n",
              " ('\\n1. The film \"The Secret', 3),\n",
              " ('\\n1. The movie \"The Cell', 3),\n",
              " ('\\n1. To analyze the plot of', 3),\n",
              " ('\\n1. The main character in the', 3),\n",
              " ('\\nReply 1:\\nSubject: Re', 3),\n",
              " ('\\n1. The movie \"Northfork', 3),\n",
              " ('\\n1. The movie \"La P', 3),\n",
              " ('\\n1. The movie \"Christmas in', 3),\n",
              " ('\\n1. The movie was a great', 3),\n",
              " ('\\n1. The film \"Death in', 3),\n",
              " (\"\\n1. The film's director,\", 3),\n",
              " (\"\\n1. The film's pacing is\", 3),\n",
              " ('\\n1. The movie \"Fame', 3),\n",
              " ('\\n1. The movie \"Rest Stop', 3),\n",
              " ('\\n1. The film \"Sherlock', 3),\n",
              " ('\\n1. The movie \"Sabote', 3),\n",
              " ('\\n1. The movie \"The Dark', 3),\n",
              " ('\\n<p>\\n\\n<strong', 3),\n",
              " ('\\n<s>The story continues with', 3),\n",
              " ('\\n1. The movie \"Death Wish', 3),\n",
              " ('\\n1. The movie \"Hell Ride', 3),\n",
              " ('\\n1. The film \"Classe', 3),\n",
              " ('\\n1. The movie \"Nurse', 3),\n",
              " ('\\n1. The movie \"It\\'s', 3),\n",
              " (\"\\n1. The film's plot revolves\", 3),\n",
              " ('\\n\\n\\n\\n<|begin of the', 3),\n",
              " ('\\n<s>I was really disappointed', 3),\n",
              " ('\\nSentence: I agree with you', 3),\n",
              " ('\\n1. The movie \"In the', 3),\n",
              " ('\\nSentence: The movie \"You', 3),\n",
              " ('\\n<s>I agree with you', 3),\n",
              " ('\\nExercise: Identify the negative', 3),\n",
              " (\"\\n1. The film's storyline is\", 3),\n",
              " ('\\n1. <br /><br', 3),\n",
              " ('\\n1. The movie \"Focus\"', 3),\n",
              " ('\\n1. The movie is based on', 3),\n",
              " ('\\n1. To solve the mystery of', 3),\n",
              " ('\\n<s>[Noun1]', 3),\n",
              " ('\\nSentence: I am a fan', 3),\n",
              " ('\\nSentence: The [NOUN', 3),\n",
              " ('\\n\\n\\n\\n[s]You are', 3),\n",
              " ('\\n<s>[NOUN1]', 3),\n",
              " ('\\nSentence: The new restaurant in', 3),\n",
              " ('\\nSentence: I was so excited', 3),\n",
              " ('\\nAnswer:\\n\\n- The sentence', 3),\n",
              " ('\\nSentence: I think that the', 3),\n",
              " (\"\\n\\n\\n\\n<s>I'm\", 3),\n",
              " (\"\\nSentence: I'm a big\", 3),\n",
              " ('\\n\\n\\n\\n[s]I am', 3),\n",
              " ('\\nAnswer:\\n\\nPositive:', 3),\n",
              " ('\\n\\n\\n\\n[s]entiment', 3),\n",
              " ('\\n```python\\n# Solution\\n', 3),\n",
              " ('\\nSentence: I watched this movie', 3),\n",
              " ('\\nAnswer:\\n\\nThe sentiment class', 3),\n",
              " ('\\n1. The film adaptation of the', 2),\n",
              " ('\\n1. The film \"Batt', 2),\n",
              " ('\\n1. The film \"Dead Man', 2),\n",
              " ('\\n1. The English Patient is a', 2),\n",
              " ('\\n1. The film \"Favel', 2),\n",
              " ('\\n1. The film \"The Egyptian', 2),\n",
              " ('\\n1. The Kite Runner is', 2),\n",
              " ('\\n1. The opening scene of \"', 2),\n",
              " ('\\n<p>\\n\\n<b', 2),\n",
              " ('\\n1. The movie is about a', 2),\n",
              " ('\\n1. The film is a disaster', 2),\n",
              " ('\\n1. The film \"The Wind', 2),\n",
              " ('\\n1. The movie \"Crash\"', 2),\n",
              " ('\\n1. The film \"Fires', 2),\n",
              " ('\\n1. The film \"Alexander Nev', 2),\n",
              " ('\\n1. The film \"K-', 2),\n",
              " ('\\n1. The film \"Robo', 2),\n",
              " ('\\n1. The movie \"Wet', 2),\n",
              " ('\\n1. The movie \"One of', 2),\n",
              " ('\\n1. The film \"Queen of', 2),\n",
              " ('\\n1. The movie \"The English', 2),\n",
              " ('\\n1. The film \"Heaven', 2),\n",
              " ('\\n1. How can you make a', 2),\n",
              " ('\\n1. The movie \"Where\\'s', 2),\n",
              " ('\\n1. The movie \"The Battle', 2),\n",
              " ('\\n1. The film was terrible because', 2),\n",
              " ('\\n1. The movie \"Tart', 2),\n",
              " ('\\n1. The movie \"Black Snake', 2),\n",
              " ('\\n1. The movie \"Rend', 2),\n",
              " ('\\n1. The Messengers is a', 2),\n",
              " ('\\n1. The protagonist causes greater grief', 2),\n",
              " ('\\n1. The film \"Today You', 2),\n",
              " ('\\n1. The movie \"Staling', 2),\n",
              " ('\\n1. The film \"Ray\"', 2),\n",
              " ('\\n1. The film \"Pony', 2),\n",
              " (\"\\n1. The director's decision to\", 2),\n",
              " (\"\\n1. Babette's Feast is\", 2),\n",
              " ('\\n1. The show was a hit', 2),\n",
              " ('\\n1. The movie \"Pink Fl', 2),\n",
              " ('\\n1. The movie \"Cadd', 2),\n",
              " ('\\n1. What is the main topic', 2),\n",
              " ('\\n1. The film \"Everything is', 2),\n",
              " ('\\n1. The movie \"Blind', 2),\n",
              " ('\\n1. The movie is a thriller', 2),\n",
              " ('\\n1. The movie \"Embry', 2),\n",
              " ('\\n1. The movie \"On the', 2),\n",
              " ('\\n1. The movie \"Skeleton', 2),\n",
              " ('\\n1. The film \"Broadcast', 2),\n",
              " ('\\n1. The Big Trail is a', 2),\n",
              " ('\\n1. The film \"Pun', 2),\n",
              " ('\\n1. The film is directed by', 2),\n",
              " ('\\n1. The movie \"Be Cool', 2),\n",
              " ('\\n1. The film \"More\"', 2),\n",
              " ('\\n1. The film \"Begotten', 2),\n",
              " ('\\n1. The movie \"Wagon', 2),\n",
              " ('\\n1. The movie \"They Made', 2),\n",
              " ('\\n1. The film is set in', 2),\n",
              " (\"\\n1. The film's title,\", 2),\n",
              " ('\\n1. The movie \"Killshot', 2),\n",
              " ('\\n1. The film \"Por', 2),\n",
              " ('\\n1. The film \"Bloody', 2),\n",
              " ('\\n1. Betty Sizemore', 2),\n",
              " ('\\n1. The film \"Thursday\"', 2),\n",
              " ('\\n1. The film \"L\\'', 2),\n",
              " ('\\n1. The movie \"Kitchen', 2),\n",
              " ('\\n1. The film \"Guest House', 2),\n",
              " ('\\nSentence: I am a huge', 2),\n",
              " ('\\n1. The movie \"Desperate', 2),\n",
              " ('\\n1. The movie \"The M', 2),\n",
              " ('\\n1. The film \"Gull', 2),\n",
              " ('\\n1. The movie \"The Curse', 2),\n",
              " ('\\n1. The film was a comedy', 2),\n",
              " ('\\n1. The movie is full of', 2),\n",
              " ('\\n1. The film \"Kron', 2),\n",
              " ('\\n1. The film \"Seeing Other', 2),\n",
              " ('\\n1. The movie \"Intr', 2),\n",
              " ('\\n1. The film \"The Big', 2),\n",
              " ('\\n1. The film is filled with', 2),\n",
              " ('\\n1. The film \"Slaughter', 2),\n",
              " ('\\n1. The film is interesting because', 2),\n",
              " ('\\n1. The film \"Naked', 2),\n",
              " ('\\n1. The film \"Wagon', 2),\n",
              " ('\\n1. The movie \"Grandma', 2),\n",
              " ('\\n1. The film \"The King', 2),\n",
              " ('\\n1. The movie Mulholl', 2),\n",
              " ('\\n1. The film is a re', 2),\n",
              " ('\\n1. The movie \"Pitch', 2),\n",
              " ('\\n1. The Merchant of Four Seasons', 2),\n",
              " ('\\nSentence: The film \"The', 2),\n",
              " ('\\n1. The Black Castle is a', 2),\n",
              " ('\\n1. The movie \"15 Park', 2),\n",
              " ('\\n1. The movie \"Angels', 2),\n",
              " ('\\n1. The film \"Four Friends', 2),\n",
              " ('\\n1. The movie \"Tommy', 2),\n",
              " ('\\n1. The movie \"All in', 2),\n",
              " ('\\n1. The movie \"The Wild', 2),\n",
              " ('\\n1. The film \"Broken', 2),\n",
              " ('\\n1. The film \"Just Before', 2),\n",
              " ('\\n1. The film \"Idi', 2),\n",
              " ('\\n1. The film \"Wise', 2),\n",
              " ('\\n1. The movie \"A S', 2),\n",
              " ('\\n1. The film \"Lif', 2),\n",
              " ('\\n1. The film Max and Grace', 2),\n",
              " ('\\n1. The movie \"Kom', 2),\n",
              " ('\\n1. The film \"Cat in', 2),\n",
              " ('\\n1. The film \"Sabote', 2),\n",
              " ('\\n1. The movie \"Flashd', 2),\n",
              " ('\\n1. The movie \"Evan', 2),\n",
              " ('\\n1. The movie is filled with', 2),\n",
              " ('\\n1. How can you go wrong', 2),\n",
              " ('\\n1. The film is a cult', 2),\n",
              " ('\\n1. The movie \"Nightbre', 2),\n",
              " ('\\n1. The film \"Let Me', 2),\n",
              " ('\\n1. The film \"Late Chrys', 2),\n",
              " ('\\n1. The film Chop Shop is', 2),\n",
              " ('\\n1. The movie \"You,', 2),\n",
              " ('\\n1. The film \"Fat Man', 2),\n",
              " ('\\n1. The movie \"Lif', 2),\n",
              " ('\\n1. The film \"Revenge', 2),\n",
              " ('\\n1. The movie is a thrilling', 2),\n",
              " ('\\n1. The China Syndrome is a', 2),\n",
              " ('\\n1. The movie \"Cabal', 2),\n",
              " ('\\n1. The movie is an excellent', 2),\n",
              " ('\\n1. The movie \"Driving', 2),\n",
              " ('\\n1. The movie was a complete', 2),\n",
              " ('\\n1. The film is about the', 2),\n",
              " ('\\n1. The film is worth watching', 2),\n",
              " ('\\n1. The film is bundled along', 2),\n",
              " ('\\n1. The movie is a horror', 2),\n",
              " ('\\n1. The film \"The Mayor', 2),\n",
              " ('\\n1.5/10.\\n', 2),\n",
              " ('\\n1. The Hand of Death aka', 2),\n",
              " ('\\n1. The film was a disappointment', 2),\n",
              " (\"\\n1. The writer's use of\", 2),\n",
              " ('\\n1. The movie was so boring', 2),\n",
              " ('\\n1. The movie \"Cold Mountain', 2),\n",
              " ('\\n1. The film is well-', 2),\n",
              " ('\\n1. The film \"An Epic', 2),\n",
              " ('\\n1. The film \"Checking', 2),\n",
              " ('\\n1. The film \"Subconscious', 2),\n",
              " ('\\n1. The movie \"Miner', 2),\n",
              " ('\\n1. The film \"Charlie Wilson', 2),\n",
              " (\"\\nSentence: If you're looking\", 2),\n",
              " ('\\n<s>I watched this movie', 2),\n",
              " ('\\n1. The film struck me as', 2),\n",
              " ('\\n1. The movie \"Red Son', 2),\n",
              " ('\\n1. The movie is a masterpiece', 2),\n",
              " ('\\n1. The movie \"Radio\"', 2),\n",
              " ('\\n1. The movie \"TNT', 2),\n",
              " ('\\n1. The movie \"Pun', 2),\n",
              " ('\\n1. The film is a crime', 2),\n",
              " ('\\n1. The movie \"Joe\"', 2),\n",
              " ('\\n1. The movie \"Island', 2),\n",
              " ('\\n1. The movie \"A Tale', 2),\n",
              " ('\\n1. The film \"City of', 2),\n",
              " ('\\nOnce upon a time in the small', 2),\n",
              " ('\\n1. The film \"The Number', 2),\n",
              " ('\\n1. The movie \"Slaughter', 2),\n",
              " ('\\n1. The movie \"Big Fat', 2),\n",
              " ('\\n1. The film \"Shir', 2),\n",
              " ('\\n1. The movie \"Scream', 2),\n",
              " ('\\n1. The movie \"The Greatest', 2),\n",
              " (\"\\n1. The show's contestants are\", 2),\n",
              " ('\\n1. The movie \"Scarlett', 2),\n",
              " ('\\n1. The movie \"The Monster', 2),\n",
              " (\"\\n1. The film River's Edge\", 2),\n",
              " ('\\n1. The film \"Princess', 2),\n",
              " ('\\n1. The film \"Tipping', 2),\n",
              " ('\\n1. The film is a mix', 2),\n",
              " ('\\nSentence: As an avid reader', 2),\n",
              " ('\\nExercise: Identify the main', 2),\n",
              " ('\\n1. The movie was directed by', 2),\n",
              " ('\\nExercise: Identify the type', 2),\n",
              " ('\\n1. The movie \"The House', 2),\n",
              " ('\\n1. The film, a B', 2),\n",
              " ('\\nSentence: **May Contain', 2),\n",
              " ('\\n1. The movie \"Three\"', 2),\n",
              " ('\\n1. The movie \"MAME', 2),\n",
              " ('\\n1. The film \"The China', 2),\n",
              " ('\\nSentence: The movie \"M', 2),\n",
              " ('\\n1. The movie \"National Velvet', 2),\n",
              " ('\\nSentence: I hate this movie', 2),\n",
              " ('\\n1. The film \"The F', 2),\n",
              " ('\\n1. The movie \"Black Water', 2),\n",
              " ('\\n1. The movie \"Star Wars', 2),\n",
              " ('\\n1. The use of the word', 2),\n",
              " ('\\n1. The film was shot on', 2),\n",
              " ('\\n1. The movie \"Beware', 2),\n",
              " ('\\nSentence: The movie \"K', 2),\n",
              " ('\\n1. The movie \"Aside from', 2),\n",
              " ('\\nSentence: The Beguiled', 2),\n",
              " ('\\n1. The movie \"Two Hands', 2),\n",
              " ('\\n1. The film \"Horror', 2),\n",
              " ('\\n1. The movie \"River\\'s', 2),\n",
              " ('\\n1. The film follows the story', 2),\n",
              " ('\\n1. The soap is worse than', 2),\n",
              " ('\\n1. The film was directed by', 2),\n",
              " ('\\n1. The film starts off great', 2),\n",
              " ('\\n1. To understand the struggles of', 2),\n",
              " ('\\n1. The movie \"Ninja', 2),\n",
              " ('\\n1. The lack of \"mem', 2),\n",
              " ('\\n1. The film \"Edge of', 2),\n",
              " ('\\nSentence: I think the movie', 2),\n",
              " ('\\nSentence: The movie was boring', 2),\n",
              " ('\\n<s>I have a question', 2),\n",
              " ('\\nExercise 2: Rewrite the', 2),\n",
              " ('\\n1. The film \"Beware', 2),\n",
              " ('\\n1. The movie is a disappointment', 2),\n",
              " ('\\n1. To analyze the sentence,', 2),\n",
              " ('\\n1. The movie \"Hitch', 2),\n",
              " ('\\n1. The film tells the true', 2),\n",
              " ('\\n1. The film \"The Dancing', 2),\n",
              " ('\\n<s>The story of the', 2),\n",
              " ('\\n1. The movie was a big', 2),\n",
              " ('\\nSentence: <br /><', 2),\n",
              " ('\\n1. The movie \"On a', 2),\n",
              " ('\\n1. The movie \"The Lost', 2),\n",
              " ('\\n1. The film \"Junior', 2),\n",
              " ('\\n<s>I hate how the', 2),\n",
              " ('\\n1. The movie \"C.', 2),\n",
              " ('\\n1. The film \"Nazarin', 2),\n",
              " ('\\n\\n\\n(1). The [n', 2),\n",
              " ('\\n1. To understand the complexities of', 2),\n",
              " ('\\n1. The film tells the story', 2),\n",
              " ('\\nSentence: I never heard of', 2),\n",
              " ('\\n1. To understand the theme of', 2),\n",
              " ('\\n1. The film is full of', 2),\n",
              " ('\\n1. The film is a romantic', 2),\n",
              " ('\\n1. The novel \"Moby', 2),\n",
              " (\"\\n1. The Russian space station '\", 2),\n",
              " ('\\n<s>I</s>', 2),\n",
              " ('\\n<s>I was sitting in', 2),\n",
              " (\"\\nSentence: I didn't really\", 2),\n",
              " ('\\n1. To create a masterpiece,', 2),\n",
              " ('\\n1. The Falcon and the Snow', 2),\n",
              " ('\\n1. The film \"Disapp', 2),\n",
              " ('\\n1. The film was praised for', 2),\n",
              " ('\\n1. The film \"Embry', 2),\n",
              " ('\\n1. The movie is well-', 2),\n",
              " ('\\n1. To analyze the movie,', 2),\n",
              " ('\\n1. The movie was uninspired', 2),\n",
              " ('\\n1. The movie \"Seag', 2),\n",
              " ('\\nSentence: This is a pretty', 2),\n",
              " ('\\n1. To create a realistic portrayal', 2),\n",
              " (\"\\n1. The film's overall sets\", 2),\n",
              " ('\\n1. To analyze the impact of', 2),\n",
              " ('\\nSentence: I saw this film', 2),\n",
              " ('\\nSentence: I have seen this', 2),\n",
              " ('\\nSentence: I was expecting a', 2),\n",
              " ('\\n\\n\\nQuestion 1:\\nIn the', 2),\n",
              " ('\\nSentence: The teacher gave the', 2),\n",
              " ('\\nSentence: ***SPOILERS', 2),\n",
              " ('\\nSentence: I watched Pola', 2),\n",
              " ('\\nSentence: This is a thought', 2),\n",
              " ('\\n1. How to analyze a sentence', 2),\n",
              " ('\\n\\n\\n\\n#!/usr/bin', 2),\n",
              " ('\\nSentence: I have to admit', 2),\n",
              " ('\\n\\n\\nTemplate 2: [Person1', 2),\n",
              " ('\\nSentence: This movie is so', 2),\n",
              " ('\\n<s>The film is a', 2),\n",
              " ('\\nSentence: I have to say', 2),\n",
              " ('\\nSentence: I thought the movie', 2),\n",
              " ('\\nSentence: If you have ever', 2),\n",
              " ('\\nSentence: The [Noun', 2),\n",
              " ('\\n\\n\\n\\n[\\\\INST]The', 2),\n",
              " ('\\n\\n\\n\\n#1. What is', 2),\n",
              " (\"\\nSentence: This film isn't\", 2),\n",
              " ('\\n\\n\\n\\n<|beginofstory', 2),\n",
              " ('\\n\\n\\n\\n[s]he is', 2),\n",
              " ('\\nSentence: What can I say', 2),\n",
              " ('\\n1. To analyze the sentiment of', 2),\n",
              " ('\\nAnswer:\\n\\nPositive Sent', 2),\n",
              " (\"\\nSentence: I don't know\", 2),\n",
              " (\"\\nSentence: I'm afraid I\", 2),\n",
              " ('\\n\\n\\n\\n# This is a simple', 2),\n",
              " ('\\n\\n\\n\\n<p>\\n    ', 2),\n",
              " ('\\n\\n\\n\\n<s>This is', 2),\n",
              " ('\\n\\n\\n\\n[s]This is', 2),\n",
              " ('\\n\\n\\n\\n[s]upport', 2),\n",
              " ('\\n<b <a.\\n\\n', 1),\n",
              " ('\\n\\n<br />\\n\\n\"', 1),\n",
              " ('\\n\\n\\n\\n\\n\\n\\n\\n', 1),\n",
              " ('\\n1. The film \"Blind', 1),\n",
              " ('\\n1. The Sea Inside is a', 1),\n",
              " ('\\n1. The film \"Hero\"', 1),\n",
              " (\"\\n1. The film 'The Evil\", 1),\n",
              " ('\\n1. The film \"Laj', 1),\n",
              " (\"\\n1. The film 'Heaven\", 1),\n",
              " ('\\n1. The Lone Ranger and the', 1),\n",
              " ('\\n1. The film Strangers on', 1),\n",
              " ('\\n1. The film industry has treated', 1),\n",
              " ('\\n1. The movie \"The Beast', 1),\n",
              " ('\\n1. The movie \"Navy', 1),\n",
              " ('\\n1. The movie \"Shocking', 1),\n",
              " ('\\n1. The movie \"Homicide', 1),\n",
              " ('\\n1. The protagonist of \"Only', 1),\n",
              " ('\\n1. The movie The Postman', 1),\n",
              " ('\\nAb Tak Chappan is a', 1),\n",
              " ('\\n1. The movie \"Leland', 1),\n",
              " ('\\n1. The film \"Que Ser', 1),\n",
              " ('\\n1. The film Mulholl', 1),\n",
              " ('\\n1. The movie \"Surve', 1),\n",
              " ('\\n1. The movie is a boring', 1),\n",
              " ('\\n1. Helen was devastated when she', 1),\n",
              " ('\\n1. The main achievement of this', 1),\n",
              " ('\\n1. The film \"Alien and', 1),\n",
              " (\"\\n1. The movie's pacing is\", 1),\n",
              " ('\\n1. The movie Meltdown:', 1),\n",
              " ('\\n1. The film \"The Dism', 1),\n",
              " ('\\n1. The movie \"Here on', 1),\n",
              " ('\\n1. What is the genre of', 1),\n",
              " ('\\n1. The film version offers numerous', 1),\n",
              " ('\\n1. The film \"Criss', 1),\n",
              " ('\\n1. The Concorde was a', 1),\n",
              " (\"\\n1. The film's budget is\", 1),\n",
              " ('\\nSentence: May 2nd:', 1),\n",
              " ('\\n1. The film \"Elfried', 1),\n",
              " ('\\n1. The 1970s were often', 1),\n",
              " ('\\n1. The film Lifeforce', 1),\n",
              " ('\\n1. The film \"My Boss', 1),\n",
              " ('\\n1. Dead Bodies is a', 1),\n",
              " ('\\n1. The film \"Dr.', 1),\n",
              " ('\\n1. The movie \"The Fall', 1),\n",
              " ('\\n1. The beach scene in MOR', 1),\n",
              " ('\\n1. The horror genre has always', 1),\n",
              " ('\\n1. The movie \"More American', 1),\n",
              " ('\\n1. The movie \"Groundhog', 1),\n",
              " ('\\n1. The film is lacking in', 1),\n",
              " ('\\n1. The film is both hilarious', 1),\n",
              " ('\\n1. The horror is the realization', 1),\n",
              " ('\\n1. The movie \"They Call', 1),\n",
              " ('\\n1. The movie House of the', 1),\n",
              " (\"\\n1. The bothersome man's\", 1),\n",
              " ('\\n1. The film \"Bab', 1),\n",
              " ('\\n<p>\\n\\n\\n', 1),\n",
              " ('\\n1. The film \"Now I', 1),\n",
              " ('\\n1. The Concorde... Airport', 1),\n",
              " ('\\n1. The film \"Black Rain', 1),\n",
              " ('\\n1. The film Donnie Dark', 1),\n",
              " ('\\n1. The film LOST HOR', 1),\n",
              " ('\\n1. The documentary series was frustrating', 1),\n",
              " ('\\n1. The Vindicator opens', 1),\n",
              " ('\\n1. The Thing is a blend', 1),\n",
              " ('\\n1. The movie CROSSFI', 1),\n",
              " ('\\n1. The movie \"Ern', 1),\n",
              " ('\\n1. The movie \"The 9', 1),\n",
              " ('\\n1. The film \"The Ball', 1),\n",
              " (\"\\n1. The film 'Boogie\", 1),\n",
              " ('\\n1. The film \"The Caribbean', 1),\n",
              " (\"\\n1. The old judge's tale\", 1),\n",
              " ('\\n1. The show \"Happy Days', 1),\n",
              " ('\\n1. The film \"St.', 1),\n",
              " ('\\n1. The movie \"They Live', 1),\n",
              " ('\\n1. Demon Warrior is best described', 1),\n",
              " ('\\n1. The film, STRANG', 1),\n",
              " ('\\n1. The film opens strongly with', 1),\n",
              " ('\\n1. The film lacked consistency and', 1),\n",
              " ('\\n1. The movie \"The Human', 1),\n",
              " ('\\n1. The film by the well', 1),\n",
              " ('\\n1. The Siege:\\nIn', 1),\n",
              " ('\\n1. The movie \"Respiro', 1),\n",
              " (\"\\nSentence: As Salinger's\", 1),\n",
              " (\"\\n1. The Sheriff's role in\", 1),\n",
              " ('\\n1. The Bone Collector is set', 1),\n",
              " ('\\n1. To speak relatively, if', 1),\n",
              " (\"\\n1. The film's first shot\", 1),\n",
              " ('\\n1. Jackie Chan is a talented', 1),\n",
              " ('\\n1. The film \"Fall and', 1),\n",
              " ('\\n1. The movie \"I Sm', 1),\n",
              " ('\\n1. The film \"The Corn', 1),\n",
              " ('\\n1. The film \"Frisk', 1),\n",
              " ('\\n1. Aslan Adam, or', 1),\n",
              " ('\\n1. The film (a sequel', 1),\n",
              " ('\\n1. The film was made simply', 1),\n",
              " ('\\n1. The Bell Witch is a', 1),\n",
              " (\"\\n1. The film's message about\", 1),\n",
              " ('\\n1. The movie \"Blue\"', 1),\n",
              " ('\\nSentence: The show \"Home', 1),\n",
              " ('\\n1. The film \"You the', 1),\n",
              " ('\\n1. The movie \"Robin Hood', 1),\n",
              " ('\\n1. The film \"Saw', 1),\n",
              " ('\\n1. The film \"Daisy', 1),\n",
              " ('\\n1. The film is a complex', 1),\n",
              " ('\\n1. The lack of consistency throughout', 1),\n",
              " ('\\n1. The movie \"The Wrong', 1),\n",
              " ('\\n1. The movie \"The Come', 1),\n",
              " ('\\n1. The film is often so', 1),\n",
              " ('\\n1. The movie \"Mom\"', 1),\n",
              " ('\\n1. The film \"The Red', 1),\n",
              " ('\\n1. The film \"Stranger', 1),\n",
              " ('\\n1. The movie \"The Cap', 1),\n",
              " ('\\n1. The movie \"The Tool', 1),\n",
              " ('\\n1. The film \"The 400', 1),\n",
              " ('\\n1. The film \"The Valley', 1),\n",
              " ('\\n1. The film \"Murder', 1),\n",
              " ('\\n1. The bone eater is set', 1),\n",
              " ('\\n1. The Toll Gate is a', 1),\n",
              " ('\\nExplanation:\\n\\nIn', 1),\n",
              " ('\\n1. The movie \"Yellow\"', 1),\n",
              " ('\\n1. The movie \"Creep', 1),\n",
              " ('\\n1. The film \"Plank', 1),\n",
              " (\"\\n1. The Monkees' film\", 1),\n",
              " ('\\n1. The film \"Popstar', 1),\n",
              " ('\\n1. The Mikado is a', 1),\n",
              " ('\\n1. To create a realistic atmosphere', 1),\n",
              " ('\\n1. The film \"The Edge', 1),\n",
              " ('\\n1. The movie \"Hammers', 1),\n",
              " ('\\n1. The film \"Bagh', 1),\n",
              " (\"\\n1. The film's weak ending\", 1),\n",
              " ('\\n1. The REVUE is', 1),\n",
              " ('\\n1. The group of friends received', 1),\n",
              " ('\\n1. The film \"Son of', 1),\n",
              " ('\\n1. The film \"Showtime', 1),\n",
              " ('\\n1. The story of Gerald Mc', 1),\n",
              " (\"\\n1. The film 'Traff\", 1),\n",
              " ('\\n1. The movie \"Fires', 1),\n",
              " ('\\n1. The study of history is', 1),\n",
              " ('\\n1. The film \"Retro', 1),\n",
              " ('\\n1. How would Shakespeare have felt', 1),\n",
              " (\"\\n1. The film's opening images\", 1),\n",
              " ('\\nSentence: This movie is the', 1),\n",
              " ('\\n1. The movie \"The Revenge', 1),\n",
              " ('\\n1. The show \"Oz', 1),\n",
              " ('\\n1. The film Marigold', 1),\n",
              " ('\\n1. The film \"Human Pork', 1),\n",
              " ('\\n1. The Wind is a film', 1),\n",
              " ('\\n1. The show \"Family Guy', 1),\n",
              " ('\\n1. The film \"How I', 1),\n",
              " ('\\n1. The film \"STRANG', 1),\n",
              " ('\\n1. The movie \"Pride', 1),\n",
              " ('\\n1. The movie \"Volcano', 1),\n",
              " ('\\n1. The Box and the Button', 1),\n",
              " ('\\n1. The Farscape series', 1),\n",
              " ('\\n1. The Time Machine is a', 1),\n",
              " ('\\n1. The film \"The K', 1),\n",
              " ('\\n1. The TV series is a', 1),\n",
              " ('\\n1. The movie \"Over the', 1),\n",
              " (\"\\n1. The protagonist's scru\", 1),\n",
              " ('\\n1. The movie \"Eaten', 1),\n",
              " ('\\n1. The scariest thing', 1),\n",
              " ('\\n1. To view the fictionalized', 1),\n",
              " ('\\n1. The Merchant of Venice is', 1),\n",
              " ('\\n1. The movie \"One Night', 1),\n",
              " (\"\\n1. The mannequin's\", 1),\n",
              " (\"\\n1. Charlie Wilson's book,\", 1),\n",
              " ('\\n1. The movie \"Erika', 1),\n",
              " ('\\n1. The film \"Rock Star', 1),\n",
              " (\"\\n1. The director's constant nit\", 1),\n",
              " ('\\n1. Being a self confessed sl', 1),\n",
              " ('\\n1. The growth of tax funds', 1),\n",
              " ('\\n1. The Coen Brothers are', 1),\n",
              " ('\\n1. The movie \"Garden', 1),\n",
              " ('\\n1. The film \"Straight', 1),\n",
              " ('\\n1. The film \"Beach', 1),\n",
              " ('\\n1. The story of the Railway', 1),\n",
              " ('\\n1. The movie \"Hust', 1),\n",
              " ('\\n1. The Milkwoman is a', 1),\n",
              " ('\\n1. The movie is a deceit', 1),\n",
              " ('\\n1. The film \"We Dive', 1),\n",
              " ('\\n1. The movie \"Music School', 1),\n",
              " ('\\n1. The movie \"QUAY', 1),\n",
              " ('\\n1. The creative team behind Evan', 1),\n",
              " ('\\nSentence: From the fertile imagination', 1),\n",
              " ('\\n1. Webs is a terrible film', 1),\n",
              " ('\\n1. The film \"Kill Bill', 1),\n",
              " ('\\n1. The process of Extraordinary', 1),\n",
              " ('\\n1. The teacher, being the', 1),\n",
              " ('\\n1. The brain of blood starts', 1),\n",
              " ('\\n1. The film follows a group', 1),\n",
              " ('\\n1. The film accurately portrays the', 1),\n",
              " ('\\n1. The film \"Cheer', 1),\n",
              " ('\\n1. Why pick Rourke to', 1),\n",
              " ('\\n1. The movie \"Softcore', 1),\n",
              " (\"\\n1. The film's poor drawing\", 1),\n",
              " ('\\n1. The movie \"Psycho', 1),\n",
              " ('\\nSentence: I walked into Block', 1),\n",
              " (\"\\n1. The film 'The English\", 1),\n",
              " ('\\n1. The monkeys were excited to', 1),\n",
              " (\"\\n1. Almodovar's\", 1),\n",
              " ('\\n1. The film Eisenstein created', 1),\n",
              " ('\\n1. The show \"America\\'s', 1),\n",
              " ('\\n1. How does the film \"', 1),\n",
              " ('\\n1. The film \"The Cell', 1),\n",
              " ('\\n1. The film \"Caribe', 1),\n",
              " ('\\n1. The film \"Critters', 1),\n",
              " ('\\n1. The film \"Marig', 1),\n",
              " ('\\n1. The film \"Goodbye', 1),\n",
              " ('\\n1. The best love scene I', 1),\n",
              " ('\\n1. The film \"Potem', 1),\n",
              " ('\\n1. The film portrays the journey', 1),\n",
              " ('\\n1. The movie \"Unfaith', 1),\n",
              " ('\\n1. The film \"Sending', 1),\n",
              " ('\\n1. The movie \"The Road', 1),\n",
              " ('\\n1. The film \"101\"', 1),\n",
              " ('\\n1. The movie \"End of', 1),\n",
              " ('\\n1. The film \"Lucy', 1),\n",
              " ('\\n1. The movie \"Hood', 1),\n",
              " ('\\n1. The production design of Batman', 1),\n",
              " ('\\n1. The story involves on the', 1),\n",
              " ('\\n1. The artist used vibrant colors', 1),\n",
              " ('\\n1. The movie \"Snake Island', 1),\n",
              " ('\\n1. The film \"15 Park', 1),\n",
              " ('\\nSentence: A young theater actress', 1),\n",
              " ('\\nSentence: They must be.', 1),\n",
              " ('\\n1. The movie \"Drac', 1),\n",
              " ('\\n1. The film seems to make', 1),\n",
              " ('\\n1. The movie Leland follows', 1),\n",
              " ('\\n1. The movie \"Blurry', 1),\n",
              " ('\\n1. Watchers is a good', 1),\n",
              " ('\\n1. The movie \"The Nun', 1),\n",
              " ('\\n1. The movie \"The Fault', 1),\n",
              " ('\\n1. When the new Outer Limits', 1),\n",
              " ('\\n1. The film \"The End', 1),\n",
              " ('\\n1. The film was a complete', 1),\n",
              " ('\\nSentence: To call this film', 1),\n",
              " ('\\n1. The movie \"The Terror', 1),\n",
              " ('\\n1. The movie \"Cann', 1),\n",
              " ('\\n1. The movie \"The Top', 1),\n",
              " ('\\n1. The Best Years of Our', 1),\n",
              " ('\\n1. The hospital is in a', 1),\n",
              " ('\\n1. The film \"Comanche', 1),\n",
              " ('\\n1. The movie \"Critters', 1),\n",
              " ('\\n1. The movie \"Mud', 1),\n",
              " ('\\n1. The film \"SUBC', 1),\n",
              " ('\\n1. The film Blackwater Valley', 1),\n",
              " ('\\n1. The film \"From the', 1),\n",
              " (\"\\n1. The film's tagline\", 1),\n",
              " ('\\nSentence: The Toxic Avenger,', 1),\n",
              " ('\\n1. The WWE decided to wind', 1),\n",
              " (\"\\n1. The film 'Black Snake\", 1),\n",
              " ('\\n1. The director imposed no value', 1),\n",
              " ('\\n1. The movie \"The Cats', 1),\n",
              " (\"\\n1. The 1970's saw a\", 1),\n",
              " ('\\n1. The film \"The Thing', 1),\n",
              " ('\\nExercise: What is the meaning', 1),\n",
              " ('\\n1. The film \"The Good', 1),\n",
              " ('\\n1. The film \"Intr', 1),\n",
              " ('\\n1. The movie shocks the audience', 1),\n",
              " ('\\n1. The movie \"The Sea', 1),\n",
              " ('\\n1. The Grudge 2 is', 1),\n",
              " ('\\n1. The scientist conducted an experiment', 1),\n",
              " ('\\n1. The movie HAD to', 1),\n",
              " ('\\n1. The movie \"Lost Horizon', 1),\n",
              " ('\\n1. The film \"Imag', 1),\n",
              " ('\\n1. The movie is rich in', 1),\n",
              " ('\\n1. The movie \"Beyond Fear', 1),\n",
              " ('\\n1. The movie \"movement', 1),\n",
              " ('\\n1. The movie \"The Box', 1),\n",
              " ('\\n1. The film \"O\"', 1),\n",
              " ('\\n1. The film \"Angels', 1),\n",
              " ('\\nSentence: Even with all the', 1),\n",
              " ('\\n1. The movie \"Imper', 1),\n",
              " ('\\n1. The film You, the', 1),\n",
              " ('\\n1. The movie Tourist Trap', 1),\n",
              " ('\\n1. The show \"Et', 1),\n",
              " ('\\n1. The movie \"True Stories', 1),\n",
              " ('\\n1. Gargoyle is a terrible', 1),\n",
              " ('\\n1. The movie \"Back in', 1),\n",
              " ('\\n1. The Fantastic Four is a', 1),\n",
              " ('\\n1. The movie Chokher', 1),\n",
              " ('\\n1. The film \"These Girls', 1),\n",
              " ('\\n1. The Turner Classic Movie Channel', 1),\n",
              " ('\\nSentence: I was unfamiliar with', 1),\n",
              " (\"\\n1. The film's climax is\", 1),\n",
              " ('\\n1. The film was obviously very', 1),\n",
              " ('\\n1. The film \"Beatrice', 1),\n",
              " ('\\n1. The film \"Octop', 1),\n",
              " ('\\n1. The Daily Show is a', 1),\n",
              " (\"\\n1. The film 'A New\", 1),\n",
              " (\"\\n1. The movie 'The Last\", 1),\n",
              " ('\\n1. The film \"Breaking Dawn', 1),\n",
              " ('\\n1. The TV news producer,', 1),\n",
              " ('\\n1. The film was not edited', 1),\n",
              " ('\\n1. The movie \"Death in', 1),\n",
              " (\"\\n1. The series 'Rocket To\", 1),\n",
              " ('\\n1. The film \"Wesley', 1),\n",
              " ('\\n1. The other movie is a', 1),\n",
              " ('\\n1. The film \"Button\"', 1),\n",
              " ('\\n1. The film is a series', 1),\n",
              " ('\\nSentence: A brilliant Sherlock Holmes', 1),\n",
              " ('\\n1. The movie \"Camp Fear', 1),\n",
              " ('\\n1. The film \"Caged', 1),\n",
              " ('\\n1. The film \"Best Years', 1),\n",
              " ('\\n1. Dead or Alive: Final', 1),\n",
              " (\"\\nSentence: I'm a math\", 1),\n",
              " ('\\n1. The feeling of the need', 1),\n",
              " ('\\n1. The Cave is a movie', 1),\n",
              " ('\\n1. The movie \"Joline', 1),\n",
              " ('\\n1. The film \"Thirst', 1),\n",
              " ('\\n1. The movie \"Edge Of', 1),\n",
              " ('\\n1. The Beguiled is', 1),\n",
              " ('\\n1. The film \"WES', 1),\n",
              " ('\\n1. The film \"AfterLife', 1),\n",
              " ('\\n1. The first of the Italian', 1),\n",
              " ('\\nSentence: I really wanted to', 1),\n",
              " ('\\n1. The film \"The Book', 1),\n",
              " ('\\nSentence: The Mallachi Brothers', 1),\n",
              " ('\\nSentence: \"The bad dreams', 1),\n",
              " ('\\n1. The movie \"Tesis', 1),\n",
              " ('\\n1. The movie \"Fare', 1),\n",
              " ('\\n1. The story and the characters', 1),\n",
              " ('\\nSentence: The editing of this', 1),\n",
              " ('\\n1. The film MacBeth', 1),\n",
              " ('\\n1. The film industry has always', 1),\n",
              " ('\\n1. The film \"Funny', 1),\n",
              " ('\\n1. The show \"Inu', 1),\n",
              " ('\\n1. Sentence: ***SP', 1),\n",
              " ('\\n1. The Prey is a', 1),\n",
              " ('\\n1. The protagonist, Titta', 1),\n",
              " ('\\nExercise 1: What was the', 1),\n",
              " ('\\n1. The novel \"Heart of', 1),\n",
              " ('\\n1. The movie \"The Horse', 1),\n",
              " ('\\n1. The movie \"Tomorrow at', 1),\n",
              " ('\\n1. The movie \"The Body', 1),\n",
              " (\"\\n1. The film's setting up\", 1),\n",
              " ('\\nSentence: One of the more', 1),\n",
              " (\"\\n1. The film 'Assass\", 1),\n",
              " ('\\n1. The film \"YOUNG', 1),\n",
              " ('\\n1. The film \"Robbery', 1),\n",
              " ('\\n1. The film \"THE POWER', 1),\n",
              " ('\\n1. The show revolves around the', 1),\n",
              " ('\\n1. The movie opens with beautiful', 1),\n",
              " ('\\n1. The film \"Fals', 1),\n",
              " ('\\n1. The Brave One seems to', 1),\n",
              " ('\\n1. The scene where the contemporary', 1),\n",
              " ('\\nSentence: I had been interested', 1),\n",
              " ('\\n1. The movie \"Melt', 1),\n",
              " (\"\\n1. The film's structure is\", 1),\n",
              " ('\\nSentence: Beginning in 1942,', 1),\n",
              " ('\\n1. The movie \"Alien from', 1),\n",
              " ('\\n1. What is the main question', 1),\n",
              " ('\\n1. The movie \"Death Machines', 1),\n",
              " ('\\n1. The Dead End Kids film', 1),\n",
              " ('\\n1. The film \"ONE DARK', 1),\n",
              " ('\\n1. The film Cold Mountain is', 1),\n",
              " (\"\\n1. The movie Ocean's Eleven\", 1),\n",
              " ('\\n1. The concept of choice is', 1),\n",
              " ('\\n1. Christopher Nolan had his goals', 1),\n",
              " ('\\n1. The film \"Solomon', 1),\n",
              " ('\\n1. The movie \"A Chinese', 1),\n",
              " ('\\nSentence: This film is an', 1),\n",
              " ('\\n1. The movie was a horror', 1),\n",
              " (\"\\n1. Veronica Lake's rise to\", 1),\n",
              " ('\\nSentence: OK. First said', 1),\n",
              " ('\\n1. The movie Le Cercle', 1),\n",
              " ('\\n1. The film \"Fat Girls', 1),\n",
              " ('\\n1. The movie \"The Poll', 1),\n",
              " ('\\nSentence: The movie \"Cover', 1),\n",
              " ('\\nSentence: If (as I', 1),\n",
              " ('\\n1. The movie is incredibly bad', 1),\n",
              " ('\\n1. The film \"The Great', 1),\n",
              " ('\\n1. The film is a thought', 1),\n",
              " (\"\\n1. The film's setting is\", 1),\n",
              " (\"\\n1. Betty's luxury apartment is\", 1),\n",
              " ('\\n1. The show is a comedy', 1),\n",
              " ('\\n1. The film is a major', 1),\n",
              " ('\\n1. The movie \"Bon Voy', 1),\n",
              " (\"\\n1. The film 'Solomon\", 1),\n",
              " ('\\n1. The film \"Anat', 1),\n",
              " ('\\n1. The movie Fat Man and', 1),\n",
              " ('\\n1. The movie \"Tenacious', 1),\n",
              " (\"\\n1. The film 'The Battles\", 1),\n",
              " ('\\n1. The film \"Webmaster', 1),\n",
              " ('\\n1. The play Romeo & Juliet', 1),\n",
              " ('\\n1. The film Boogie Nights', 1),\n",
              " ('\\n1. The fact that a film', 1),\n",
              " ('\\n1. The show was originally set', 1),\n",
              " ('\\n1. The film \"La P', 1),\n",
              " ('\\n1. The film \"The Greatest', 1),\n",
              " ('\\n1. The Ealing Comedies', 1),\n",
              " ('\\n1. The film \"Two Hands', 1),\n",
              " ('\\n1. The film was little more', 1),\n",
              " ('\\n1. The movie \"Air Bud', 1),\n",
              " ('\\nSentence: Of course I have', 1),\n",
              " ('\\n1. The film \"Kairo', 1),\n",
              " ('\\n1. Steven Seagal is', 1),\n",
              " ('\\n1. The movie \"The Italian', 1),\n",
              " (\"\\n1. The Monkees' music\", 1),\n",
              " ('\\n1. The film, Fata', 1),\n",
              " ('\\n1. The film \"9 Souls', 1),\n",
              " ('\\n1. The movie \"Flight to', 1),\n",
              " ('\\n1. The movie \"Extraordinary', 1),\n",
              " ('\\n1. The Royal Rumble Match was', 1),\n",
              " ('\\n1. The film \"Cold Mountain', 1),\n",
              " ('\\n1. The film \"See No', 1),\n",
              " ('\\n1. The movie Night Hunter is', 1),\n",
              " ('\\n1. The Melancholy of', 1),\n",
              " ('\\n1. The film \"The Star', 1),\n",
              " ('\\n1. The movie \"Pulse', 1),\n",
              " (\"\\n1. The film 'Mar Ad\", 1),\n",
              " ('\\nSentence: The Monkees were', 1),\n",
              " ...]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(predictions_base).most_common()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_base_filtered = []\n",
        "for pred in predictions_base:\n",
        "    if \"positive\" in pred:\n",
        "        predictions_base_filtered.append(\"positive\")\n",
        "    elif \"negative\" in pred:\n",
        "        predictions_base_filtered.append(\"negative\")\n",
        "    else:\n",
        "        predictions_base_filtered.append(\"NONE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'NONE': 24947, 'negative': 9, 'positive': 12})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(predictions_base_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0005206664530599167"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_base = string_accuracy(predictions=predictions_base_filtered, references=references)\n",
        "accuracy_base"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19a4e1b8f531484ead63d60ab7610f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f36c9b0b6fc4fcfa25ca317731ffd2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3193cae4e594a238bf8fae3a613ba57",
            "max": 67349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b910b8b28bb348648ec5cb689cd31fe5",
            "value": 67349
          }
        },
        "4fc5d8efd4164cf98c78817dca300750": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69db67eed1ac460cb00fd7ae57fb8336",
              "IPY_MODEL_f27c32a8a41e4766852235fe7657eb18",
              "IPY_MODEL_9054a08a953b4664af94a5d834945950"
            ],
            "layout": "IPY_MODEL_c0e35d69570b4f0bb45967d7e420226c"
          }
        },
        "69db67eed1ac460cb00fd7ae57fb8336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccdf7cde1a834ffdb45261016e8018da",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ae9b48d0776e453a961aad557a490be5",
            "value": "Map:â€‡100%"
          }
        },
        "731e3053925a411b9357632b78aa0dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79e14c8e280f4bb7a860825f85737a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b6dde22828c44729f28309d65eae1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb1c6d418b3e40f2bfa5d1258ef6e197",
              "IPY_MODEL_4f36c9b0b6fc4fcfa25ca317731ffd2b",
              "IPY_MODEL_9c7a81a7d03a4b32b2021b750c7cc73c"
            ],
            "layout": "IPY_MODEL_c0cb94e4f9f64db99d533613742a60ac"
          }
        },
        "9054a08a953b4664af94a5d834945950": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_731e3053925a411b9357632b78aa0dc0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ba875b0928a74707b6ca9cf23e66c2f9",
            "value": "â€‡67349/67349â€‡[00:10&lt;00:00,â€‡3977.15â€‡examples/s]"
          }
        },
        "9bb6773b3281465cb1533261035e686a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c7a81a7d03a4b32b2021b750c7cc73c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19a4e1b8f531484ead63d60ab7610f7c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b43906472dbb401fbd0eb3dfa1e68c4e",
            "value": "â€‡67349/67349â€‡[00:09&lt;00:00,â€‡6706.48â€‡examples/s]"
          }
        },
        "ab21c7ec21104159ab595d7d65913e24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae9b48d0776e453a961aad557a490be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b43906472dbb401fbd0eb3dfa1e68c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b910b8b28bb348648ec5cb689cd31fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba875b0928a74707b6ca9cf23e66c2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb1c6d418b3e40f2bfa5d1258ef6e197": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f81e097860984800970910f17ed127cc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9bb6773b3281465cb1533261035e686a",
            "value": "Map:â€‡100%"
          }
        },
        "c0cb94e4f9f64db99d533613742a60ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0e35d69570b4f0bb45967d7e420226c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3193cae4e594a238bf8fae3a613ba57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccdf7cde1a834ffdb45261016e8018da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f27c32a8a41e4766852235fe7657eb18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab21c7ec21104159ab595d7d65913e24",
            "max": 67349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79e14c8e280f4bb7a860825f85737a93",
            "value": 67349
          }
        },
        "f81e097860984800970910f17ed127cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
