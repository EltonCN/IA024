{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor \n",
    "import threading\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "import groq\n",
    "import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroqInterface:\n",
    "    _client = None \n",
    "\n",
    "    LLAMA3_70B = \"llama3-70b-8192\"\n",
    "\n",
    "    rate_lock = threading.Lock()\n",
    "    error = None\n",
    "\n",
    "    def __init__(self, model:Optional[str]=None):\n",
    "        if GroqInterface._client is None:\n",
    "            api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "            if api_key is None:\n",
    "                raise RuntimeError(\"API key is not in the environment variables ('GROQ_API_KEY' variable is not set).\")\n",
    "\n",
    "            GroqInterface._client = groq.Groq(api_key=api_key)\n",
    "\n",
    "        if model is None:\n",
    "            model = GroqInterface.LLAMA3_70B\n",
    "        self._model = model\n",
    "\n",
    "    def __call__(self, prompt:str):\n",
    "        done = False\n",
    "        while not done:\n",
    "\n",
    "            try:\n",
    "                GroqInterface.rate_lock.acquire()\n",
    "                GroqInterface.rate_lock.release()\n",
    "\n",
    "                chat_completion = GroqInterface._client.chat.completions.create(\n",
    "                        messages=[\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": prompt,\n",
    "                            }\n",
    "                        ],\n",
    "                        model=self._model,\n",
    "                    )\n",
    "                \n",
    "                done = True\n",
    "            except groq.RateLimitError as exception:\n",
    "                GroqInterface.error = exception\n",
    "                if not GroqInterface.rate_lock.locked():\n",
    "                    GroqInterface.rate_lock.acquire()\n",
    "                    time.sleep(2)\n",
    "                    GroqInterface.rate_lock.release()\n",
    "\n",
    "        return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_interface = GroqInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_interface(\"Hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE = 1\n",
    "NEGATIVE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroqSentimentInterface(GroqInterface):\n",
    "\n",
    "    def __call__(self, prompt: str):\n",
    "        response = super().__call__(prompt)\n",
    "        response = response.lower()\n",
    "\n",
    "        if \"positive\" in response and \"negative\" not in response:\n",
    "            return POSITIVE\n",
    "        if \"negative\" in response and \"positive\" not in response:\n",
    "            return NEGATIVE\n",
    "        \n",
    "        return random.choice([POSITIVE, NEGATIVE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sentiment = GroqSentimentInterface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = ThreadPoolExecutor(max_workers=2)\n",
    "\n",
    "trainbase_future = executor.submit(datasets.load_dataset, \"imdb\", split=\"train\")\n",
    "test_future = executor.submit(datasets.load_dataset, \"imdb\", split='test')\n",
    "\n",
    "trainbase_dataset = trainbase_future.result()\n",
    "testbase_dataset = test_future.result()\n",
    "\n",
    "train_val_dataset = trainbase_dataset.train_test_split(test_size=100, shuffle=True, seed=78)\n",
    "discard_test_dataset = testbase_dataset.train_test_split(test_size=100, shuffle=True, seed=78)\n",
    "\n",
    "train_dataset = train_val_dataset[\"train\"]\n",
    "val_dataset = train_val_dataset[\"test\"]\n",
    "test_dataset = discard_test_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24900, 100, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt_zero = '''Classify if the movie review is POSITIVE or NEGATIVE: \n",
    "                Review:\n",
    "                {review}\n",
    "\n",
    "                Sentiment:\n",
    "                POSITIVE OR NEGATIVE: \n",
    "                '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = base_prompt_zero.format(review=train_dataset[-1][\"text\"])\n",
    "\n",
    "groq_sentiment(prompt), train_dataset[-1][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_zero(text, label):\n",
    "    prompt = base_prompt_zero.format(review=text)\n",
    "    result = groq_sentiment(prompt)\n",
    "\n",
    "    return result == label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:30<00:00,  4.50s/it] \n"
     ]
    }
   ],
   "source": [
    "executor = ThreadPoolExecutor(max_workers=4) #More workers -> More RateLimit exceptions\n",
    "\n",
    "futures = []\n",
    "for data in val_dataset:\n",
    "    future = executor.submit(evaluate_zero, **data)\n",
    "    futures.append(future)\n",
    "\n",
    "correct_zero = 0\n",
    "for future in tqdm.tqdm(futures):\n",
    "    correct_zero += future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia - Zero-shot - Validação: 88.0%\n"
     ]
    }
   ],
   "source": [
    "accuracy_zero = correct_zero/len(val_dataset)\n",
    "print(f\"Acurácia - Zero-shot - Validação: {accuracy_zero*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia - Zero-shot - Validação: 88.0%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prompt_few = '''Classify if the movie review is positive or negative: \n",
    "                Review:\n",
    "                Movie review\n",
    "\n",
    "                Sentiment:\n",
    "                ONLY POSITIVE OR NEGATIVE\n",
    "\n",
    "                Classify if this movie review is positive or negative:\n",
    "                Review:\n",
    "                {example1}\n",
    "\n",
    "                Sentiment:\n",
    "                {response1}\n",
    "\n",
    "                Classify if this movie review is positive or negative:\n",
    "                Review:\n",
    "                {example2}\n",
    "\n",
    "                Sentiment:\n",
    "                {response2}\n",
    "\n",
    "                Classify if this movie review is positive or negative:\n",
    "                Review:\n",
    "                {{review}}\n",
    "                \n",
    "                Sentiment:\n",
    "                \n",
    "                '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_example = None\n",
    "negative_example = None\n",
    "\n",
    "i = 0\n",
    "while positive_example is None or negative_example is None:\n",
    "    if train_dataset[i][\"label\"] == POSITIVE:\n",
    "        positive_example = train_dataset[i]\n",
    "    else:\n",
    "        negative_example = train_dataset[i]\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify if the movie review is positive or negative: \n",
      "                Review:\n",
      "                Movie review\n",
      "\n",
      "                Sentiment:\n",
      "                ONLY POSITIVE OR NEGATIVE\n",
      "\n",
      "                Classify if this movie review is positive or negative:\n",
      "                Review:\n",
      "                but I want to say I cannot agree more with Moira.<br /><br />What a wonderful film.<br /><br />I was thinking about it just this morning, wanting to give advice to some dopey sod who'd lost money on his debit card through fraud, and wanted to say 'Keep thy money in thine pocket' and realised I was talking like James Mason.<br /><br />Even tho he didn't say those words, I still think he would! I've never forgotten 'Are ye carrying?' in his reconciliation with his son, Hywel Bennet: 'Always have money in thine pocket!' Good advice.<br /><br />Not enough kids have fathers with such unforgiving but well-meant attitudes any more. Or any father at all.<br /><br />It would be a good thing for us to reinstate 'thee', 'thy' and 'thine' in our language to show we care. It is only the same as 'tutoyer' in French or 'du' in German.<br /><br />Addendum: I just realised that a lot of my remarks were about James Mason in The Family Way!<br /><br />I think it's because I mixed up Susan George with Hayley Mills. Well, easy mistake.<br /><br />I stand by the comments tho'.<br /><br />And Spring and Port Wine is so very similar to The Family Way.<br /><br />When you took a girlfriend to the pictures in those days, you really had something to say and talk about afterwards, something that affected your knowledge of the world and your personal development.<br /><br />Theatrical experiences are almost real, and they are important in helping young people to grow up.<br /><br />It doesn't happen now, I think, that teenagers can just go to the pics like we did.\n",
      "\n",
      "                Sentiment:\n",
      "                POSITIVE\n",
      "\n",
      "                Classify if this movie review is positive or negative:\n",
      "                Review:\n",
      "                \"A total waste of time\" Just throw in a few explosions, non stop fighting, exotic cars a deranged millionaire, slow motion computer generated car crashes and last but not least a Hugh Hefner like character with wall to wall hot babes, and mix in a blender and you will have this sorry excuse for a movie. I really got a laugh out of the \"Dr. Evil\" like heavily fortified compound. The plot was somewhere between preposterous and non existent. How many millionaires are willing to make a 25 million dollar bet on a car race? Answer: 4 but, didn't they become millionaires through fiscal responsibility? This was written for pubescent males, it plays like a video game. I did enjoy the Gulfstream II landing in the desert though.\n",
      "\n",
      "                Sentiment:\n",
      "                NEGATIVE\n",
      "\n",
      "                Classify if this movie review is positive or negative:\n",
      "                Review:\n",
      "                {review}\n",
      "                \n",
      "                Sentiment:\n",
      "                \n",
      "                \n"
     ]
    }
   ],
   "source": [
    "base_prompt_few = raw_prompt_few.format(example1=positive_example[\"text\"], response1=\"POSITIVE\", \n",
    "                                        example2=negative_example[\"text\"], response2=\"NEGATIVE\")\n",
    "\n",
    "print(base_prompt_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = base_prompt_few.format(review=train_dataset[-1][\"text\"])\n",
    "\n",
    "groq_sentiment(prompt), train_dataset[-1][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_few(text, label):\n",
    "    prompt = base_prompt_few.format(review=text)\n",
    "    result = groq_sentiment(prompt)\n",
    "\n",
    "    return result == label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_few(**train_dataset[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:14<00:00,  6.15s/it]\n"
     ]
    }
   ],
   "source": [
    "executor = ThreadPoolExecutor(max_workers=4) #More workers -> More RateLimit exceptions\n",
    "\n",
    "futures = []\n",
    "for data in val_dataset:\n",
    "    future = executor.submit(evaluate_few, **data)\n",
    "    futures.append(future)\n",
    "\n",
    "correct_few = 0\n",
    "for future in tqdm.tqdm(futures):\n",
    "    correct_few += future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia - Few-shot - Validação: 98.0%\n"
     ]
    }
   ],
   "source": [
    "accuracy_few = correct_few/len(val_dataset)\n",
    "print(f\"Acurácia - Few-shot - Validação: {accuracy_few*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Dinâmico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')\n",
    "bert = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-cased')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
