{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício: ReAct\n",
    "\n",
    "Elton Cardoso do Nascimento, 233840\n",
    "\n",
    "Enunciado:\n",
    "\n",
    "- Implementar a ReAct  com LLaMa 3 70B (groq) `→Implementado`\n",
    "- Testar no dataset do IIRC - 50 primeiras perguntas com resposta (test_questions.json em anexo) `→Arquivo não utilizado pois não tem todos os documentos relacionados as perguntas`\n",
    "- Usar o prompt do LLaMAIndex: https://github.com/run-llama/llama_index/blob/a87b63fce3cc3d24dc71ae170a8d431440025565/llama_index/agent/react/prompts.py `→Prompt semelhante utilizado`\n",
    "- Salvar as respostas finais das 50 perguntas no JSON para exercício futuro de avaliação `→[Arquivo JSON](https://github.com/EltonCN/IA024-NLP/blob/main/10-ReAct/results.json) salvo`\n",
    "- Instruir o modelo a seguir a sequência Thougth, Action, Input, Observation (a observação não é do próprio modelo, mas resultado da busca) `→Sequência possível, mas permitindo ao modelo escolher qual será a próxima etapa`\n",
    "- É necessário usar o parâmetro stop_sequence=\"Observation:\", para o modelo parar de gerar texto e esperar o retorno da busca. Implementem o código da busca e retornem os top-k documentos pro modelo (sugestão: k=5). `→Código de busca implementado. Parâmetro de parada não foi necessário`\n",
    "- Instruir o modelo agir passo-a-passo (decomposição da pergunta). `→Modelo age passo-a-passo, mas sem necessariamente decompor a pergunta`\n",
    "- Podem usar o LangChain, LLaMAindex ou outro framework. Ou implementar na mão. `→Implementado na mão`\n",
    "- Usar a busca como ferramenta `→Implementado`\n",
    "- Usar o BM25 como buscador (repetir indexação do exercício passado) `→BM25 utilizado`\n",
    "- Usar a indexação do Visconde: https://github.com/neuralmind-ai/visconde/blob/main/iirc_create_indices.ipynb `→Indexação do Visconde utilizada`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos começar importanto todos os módulos que serão utilizados nesta atividade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #Operações com o SO (arquivos)\n",
    "import json #Leitura/escrita de arquivos JSON\n",
    "import time #Sleep\n",
    "import threading #Multithreading\n",
    "import unicodedata #Normalização de string\n",
    "import collections #Estrutura de contador e fila\n",
    "import string #Operações com strings\n",
    "import re #Expressões regulares\n",
    "import abc #Classes abstratas\n",
    "import warnings #Lançamento de warnings\n",
    "from typing import Optional, Dict, Tuple, Any #Type hints\n",
    "\n",
    "import torch #spacy não carrega sem importar antes (??)\n",
    "import spacy #Separador em sentenças\n",
    "import tqdm #Barra de progresso\n",
    "import groq #API para o Llama 3 70B\n",
    "from pyserini.search import SimpleSearcher #Busca nos documentos\n",
    "import sentence_transformers #Rerankeamento\n",
    "import bs4 #Remoção de tags HTML\n",
    "import numpy as np #Operações com arrays\n",
    "import matplotlib.pyplot as plt #Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos dados\n",
    "\n",
    "Antes de começar a implementação em si, precisamos preparar os dados que serão utilizados. O código desta seção é principalmente uma modificação do código do [Visconde](https://github.com/neuralmind-ai/visconde/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começamos pelo download e leitura dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "if not os.path.isfile(\"data\\\\context_articles.json\"):\n",
    "    !curl -LO https://iirc-dataset.s3.us-west-2.amazonaws.com/context_articles.tar.gz\n",
    "    !move context_articles.tar.gz data\n",
    "    !tar -xf data/context_articles.tar.gz\n",
    "    !move context_articles.json data\n",
    "\n",
    "if not os.path.isfile(\"data\\\\iirc_test.json\"):\n",
    "    !curl -LO https://iirc-dataset.s3.us-west-2.amazonaws.com/iirc_test.json\n",
    "    !move iirc_test.json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data\\\\context_articles.json\", \"r\")\n",
    "articles = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data\\\\iirc_test.json\", \"r\")\n",
    "test_data = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E partimos para a extração das perguntas, respostas e documentos que serão utilizados.\n",
    "\n",
    "(menção ao [@fabiograssiotto](https://github.com/fabiograssiotto/IA024/blob/main/Aula_9_10/RA890441%20-%20Aula9_10.ipynb) pelo código para remoção de tags HTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_question = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "documents_titles = set()\n",
    "documents = []\n",
    "documents_not_found = set()\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    item = test_data[i]\n",
    "\n",
    "    #Get the main document\n",
    "    name = item['title'].lower()\n",
    "    if name not in documents_titles:\n",
    "        text = item[\"text\"]\n",
    "        soup = bs4.BeautifulSoup(text, \"html.parser\")\n",
    "        clean_text = soup.get_text()\n",
    "\n",
    "        document = {\n",
    "                    \"title\": item['title'],\n",
    "                    \"content\": clean_text\n",
    "                }\n",
    "        \n",
    "        documents.append(document)\n",
    "        documents_titles |= {name}\n",
    "\n",
    "    #Get the documents\n",
    "    for link in item[\"links\"]:\n",
    "        name : str = link['target'].lower()\n",
    "        if name in articles and name not in documents_titles:\n",
    "            text = articles[link['target'].lower()]\n",
    "            soup = bs4.BeautifulSoup(text, \"html.parser\")\n",
    "            clean_text = soup.get_text()\n",
    "            \n",
    "            document = {\n",
    "                \"title\": link['target'],\n",
    "                \"content\": clean_text\n",
    "            }\n",
    "\n",
    "            documents.append(document)\n",
    "            documents_titles |= {name}\n",
    "        \n",
    "        else:\n",
    "            documents_not_found |= {name}\n",
    "\n",
    "    #Get the questions\n",
    "    for q in item[\"questions\"]:\n",
    "        question = {}\n",
    "        \n",
    "        #Get and format the answer\n",
    "        if q[\"answer\"][\"type\"] == \"span\":\n",
    "            question[\"answer\"] = q[\"answer\"][\"answer_spans\"][0][\"text\"]\n",
    "        elif q[\"answer\"][\"type\"] == \"value\":\n",
    "            question[\"answer\"] = q[\"answer\"][\"answer_value\"]+\" \"+q[\"answer\"][\"answer_unit\"]\n",
    "        elif  q[\"answer\"][\"type\"] == \"none\":\n",
    "            continue\n",
    "        elif q[\"answer\"][\"type\"] == \"binary\":\n",
    "            question[\"answer\"] = q[\"answer\"][\"answer_value\"]\n",
    "        else:\n",
    "            raise ValueError\n",
    "        \n",
    "        question[\"question\"] = q[\"question\"]\n",
    "\n",
    "        questions.append(question)\n",
    "\n",
    "        if len(questions) == n_question:\n",
    "            break\n",
    "    if len(questions) == n_question:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 419)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_not_found), len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E extraímos sentenças dos documentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 419/419 [00:03<00:00, 129.78it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "#12345\n",
    "#   45678\n",
    "stride = 3#2\n",
    "max_length = 5#3\n",
    "\n",
    "def window(documents, stride, max_length):\n",
    "    treated_documents = []\n",
    "\n",
    "    for j,document in enumerate(tqdm.tqdm(documents)):\n",
    "        doc_text = document['content']\n",
    "        doc = nlp(doc_text[:10000])\n",
    "        sentences = [sent.text.strip() for sent in doc.sents]\n",
    "        for i in range(0, len(sentences), stride):\n",
    "            segment = ' '.join(sentences[i:i + max_length])\n",
    "            treated_documents.append({\n",
    "                \"title\": document['title'],\n",
    "                \"contents\": document['title']+\". \"+segment,\n",
    "                \"segment\": segment\n",
    "            })\n",
    "            if i + max_length >= len(sentences):\n",
    "                break\n",
    "    return treated_documents\n",
    "\n",
    "treated_documents = window(documents, stride, max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escrevemos os documentos em um arquivo JSONL e criamos o índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"data\\iirc_indices\"):\n",
    "    !mkdir data\\iirc_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/iirc_indices/contents.jsonl\",'w')\n",
    "\n",
    "for i, doc in enumerate(treated_documents):\n",
    "    doc['id'] = i\n",
    "    if doc['segment'] != \"\":\n",
    "        file.write(json.dumps(doc)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyserini.index is deprecated, please use pyserini.index.lucene.\n",
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2024-05-14 15:05:18,277 INFO  [main] index.IndexCollection (IndexCollection.java:380) - Setting log level to INFO\n",
      "2024-05-14 15:05:18,280 INFO  [main] index.IndexCollection (IndexCollection.java:383) - Starting indexer...\n",
      "2024-05-14 15:05:18,280 INFO  [main] index.IndexCollection (IndexCollection.java:384) - ============ Loading Parameters ============\n",
      "2024-05-14 15:05:18,280 INFO  [main] index.IndexCollection (IndexCollection.java:385) - DocumentCollection path: data/iirc_indices\n",
      "2024-05-14 15:05:18,280 INFO  [main] index.IndexCollection (IndexCollection.java:386) - CollectionClass: JsonCollection\n",
      "2024-05-14 15:05:18,281 INFO  [main] index.IndexCollection (IndexCollection.java:387) - Generator: DefaultLuceneDocumentGenerator\n",
      "2024-05-14 15:05:18,281 INFO  [main] index.IndexCollection (IndexCollection.java:388) - Threads: 1\n",
      "2024-05-14 15:05:18,281 INFO  [main] index.IndexCollection (IndexCollection.java:389) - Language: en\n",
      "2024-05-14 15:05:18,281 INFO  [main] index.IndexCollection (IndexCollection.java:390) - Stemmer: porter\n",
      "2024-05-14 15:05:18,281 INFO  [main] index.IndexCollection (IndexCollection.java:391) - Keep stopwords? false\n",
      "2024-05-14 15:05:18,281 INFO  [main] index.IndexCollection (IndexCollection.java:392) - Stopwords: null\n",
      "2024-05-14 15:05:18,282 INFO  [main] index.IndexCollection (IndexCollection.java:393) - Store positions? false\n",
      "2024-05-14 15:05:18,282 INFO  [main] index.IndexCollection (IndexCollection.java:394) - Store docvectors? false\n",
      "2024-05-14 15:05:18,282 INFO  [main] index.IndexCollection (IndexCollection.java:395) - Store document \"contents\" field? false\n",
      "2024-05-14 15:05:18,283 INFO  [main] index.IndexCollection (IndexCollection.java:396) - Store document \"raw\" field? true\n",
      "2024-05-14 15:05:18,283 INFO  [main] index.IndexCollection (IndexCollection.java:397) - Additional fields to index: []\n",
      "2024-05-14 15:05:18,283 INFO  [main] index.IndexCollection (IndexCollection.java:398) - Optimize (merge segments)? false\n",
      "2024-05-14 15:05:18,283 INFO  [main] index.IndexCollection (IndexCollection.java:399) - Whitelist: null\n",
      "2024-05-14 15:05:18,284 INFO  [main] index.IndexCollection (IndexCollection.java:400) - Pretokenized?: false\n",
      "2024-05-14 15:05:18,284 INFO  [main] index.IndexCollection (IndexCollection.java:401) - Index path: data/iirc_index\n",
      "2024-05-14 15:05:18,289 INFO  [main] index.IndexCollection (IndexCollection.java:481) - ============ Indexing Collection ============\n",
      "2024-05-14 15:05:18,302 INFO  [main] index.IndexCollection (IndexCollection.java:468) - Using DefaultEnglishAnalyzer\n",
      "2024-05-14 15:05:18,302 INFO  [main] index.IndexCollection (IndexCollection.java:469) - Stemmer: porter\n",
      "2024-05-14 15:05:18,302 INFO  [main] index.IndexCollection (IndexCollection.java:470) - Keep stopwords? false\n",
      "2024-05-14 15:05:18,302 INFO  [main] index.IndexCollection (IndexCollection.java:471) - Stopwords file: null\n",
      "2024-05-14 15:05:18,458 INFO  [main] index.IndexCollection (IndexCollection.java:510) - Thread pool with 1 threads initialized.\n",
      "2024-05-14 15:05:18,458 INFO  [main] index.IndexCollection (IndexCollection.java:512) - Initializing collection in data\\iirc_indices\n",
      "2024-05-14 15:05:18,462 INFO  [main] index.IndexCollection (IndexCollection.java:521) - 1 file found\n",
      "2024-05-14 15:05:18,462 INFO  [main] index.IndexCollection (IndexCollection.java:522) - Starting to index...\n",
      "2024-05-14 15:05:19,724 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - iirc_indices\\contents.jsonl: 7038 docs added.\n",
      "2024-05-14 15:05:20,064 INFO  [main] index.IndexCollection (IndexCollection.java:578) - Indexing Complete! 7.038 documents indexed\n",
      "2024-05-14 15:05:20,065 INFO  [main] index.IndexCollection (IndexCollection.java:579) - ============ Final Counter Values ============\n",
      "2024-05-14 15:05:20,065 INFO  [main] index.IndexCollection (IndexCollection.java:580) - indexed:            7.038\n",
      "2024-05-14 15:05:20,065 INFO  [main] index.IndexCollection (IndexCollection.java:581) - unindexable:            0\n",
      "2024-05-14 15:05:20,066 INFO  [main] index.IndexCollection (IndexCollection.java:582) - empty:                  0\n",
      "2024-05-14 15:05:20,066 INFO  [main] index.IndexCollection (IndexCollection.java:583) - skipped:                0\n",
      "2024-05-14 15:05:20,066 INFO  [main] index.IndexCollection (IndexCollection.java:584) - errors:                 0\n",
      "2024-05-14 15:05:20,073 INFO  [main] index.IndexCollection (IndexCollection.java:587) - Total 7.038 documents indexed in 00:00:01\n"
     ]
    }
   ],
   "source": [
    "!python -m pyserini.index -collection JsonCollection -generator DefaultLuceneDocumentGenerator -threads 1 -input data/iirc_indices -index data/iirc_index -storeRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = \"./data/iirc_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groq API\n",
    "\n",
    "Uma classe base é definida para uso da API do Groq:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroqInterface:\n",
    "    '''\n",
    "    Interface for using the Groq API\n",
    "\n",
    "    Implements a rate limit control for multi-threading use. \n",
    "    '''\n",
    "\n",
    "    _client :groq.Groq = None \n",
    "\n",
    "    LLAMA3_70B = \"llama3-70b-8192\"\n",
    "\n",
    "    inference_lock = threading.Lock()\n",
    "    time_waiter_lock = threading.Lock()\n",
    "    SINGLE_THREAD = True\n",
    "\n",
    "    def __init__(self, model:Optional[str]=None, api_key:Optional[str]=None, json_mode:bool=False, system_message:Optional[str]=None, n_retry:int=5):\n",
    "        '''\n",
    "        GroqInterface constructor.\n",
    "\n",
    "        Args:\n",
    "            model (str, optional): model to use. Llama3 70B is used if None. Default is None\n",
    "            api_key (str, optional): Groq API key to use, if None will check the environment 'GROQ_API_KEY' variable. Default is None.\n",
    "            json_mode (bool): if the model need to output in JSON. Default is False.\n",
    "            system_message (str): the system message to send to the model, if needed. Default is None.\n",
    "            n_retyr (int): number of times to retry if the model fails (not considering RateLimitError). Default is 5.\n",
    "        '''\n",
    "        \n",
    "        if GroqInterface._client is None:\n",
    "\n",
    "            if api_key is None:\n",
    "                api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "            if api_key is None:\n",
    "                raise RuntimeError(\"API key is not in the environment variables ('GROQ_API_KEY' variable is not set).\")\n",
    "\n",
    "            GroqInterface._client = groq.Groq(api_key=api_key)\n",
    "\n",
    "        if model is None:\n",
    "            model = GroqInterface.LLAMA3_70B\n",
    "        self._model = model\n",
    "\n",
    "        self._system_message = system_message\n",
    "\n",
    "\n",
    "        if json_mode:\n",
    "            self._response_format = {\"type\": \"json_object\"}\n",
    "        else:\n",
    "            self._response_format = None\n",
    "        self._json_mode = json_mode\n",
    "\n",
    "        self._n_retry = n_retry\n",
    "\n",
    "    def __call__(self, prompt:str) -> str:\n",
    "        '''\n",
    "        Generates the model response\n",
    "\n",
    "        Args:\n",
    "            prompt (str): prompt to send to the model.\n",
    "\n",
    "        Returns:\n",
    "            str: model response. \n",
    "        '''\n",
    "        done = False\n",
    "        retry_count = 0\n",
    "        while not done:\n",
    "            try:\n",
    "                if not GroqInterface.SINGLE_THREAD:\n",
    "                    GroqInterface.inference_lock.acquire()\n",
    "                    GroqInterface.inference_lock.release()\n",
    "\n",
    "                messages = []\n",
    "                if self._system_message is not None:\n",
    "                    messages.append({\"role\":\"system\", \"content\":self._system_message})\n",
    "                \n",
    "                messages.append({\"role\":\"user\", \"content\":prompt})\n",
    "\n",
    "                chat_completion = GroqInterface._client.chat.completions.create(\n",
    "                        messages=messages,\n",
    "                        model=self._model,\n",
    "                        response_format=self._response_format\n",
    "                    )\n",
    "                \n",
    "                done = True\n",
    "            except groq.RateLimitError as exception: #Wait\n",
    "                print(\"ERROR\")\n",
    "                print(exception)\n",
    "                \n",
    "                GroqInterface.error = exception\n",
    "                if not GroqInterface.SINGLE_THREAD:\n",
    "                    if not GroqInterface.time_waiter_lock.locked():\n",
    "                        GroqInterface.time_waiter_lock.acquire()\n",
    "                        GroqInterface.inference_lock.acquire()\n",
    "                        time.sleep(2)\n",
    "                        GroqInterface.time_waiter_lock.release()\n",
    "                        GroqInterface.inference_lock.release()\n",
    "                else:\n",
    "                    time.sleep(2)\n",
    "\n",
    "            except KeyboardInterrupt as e: #Stop the code\n",
    "                raise e\n",
    "            except Exception as e: #Retry\n",
    "                retry_count += 1\n",
    "                if retry_count >= self._n_retry:\n",
    "                    raise e\n",
    "\n",
    "        return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_interface = GroqInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_interface(\"Hi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrica\n",
    "\n",
    "Três métricas serão definidas para avaliar o modelo:\n",
    "\n",
    "- Corretude (acurácia): se a resposta está correta. Estimado utilizando o próprio modelo comparando com a resposta correta.\n",
    "- F1 score\n",
    "- Resposta idêntica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroqAnswerEvaluator(GroqInterface):\n",
    "    \"\"\"\n",
    "    Evaluates if a answer is correct, comparing with the correct answer.\n",
    "    \"\"\"\n",
    "\n",
    "    _system_message = '''You are a answer comparator that outputs in JSON. \n",
    "The JSON object must use the schema: {'is_correct':'bool'}\n",
    "Please use a valid JSON format.'''\n",
    "\n",
    "    _base_prompt = '''Is the second answer correct, comparing to the first one? \n",
    "First answer: {answer_correct}\n",
    "Second answer: {answer} \n",
    "'''\n",
    "\n",
    "    def __init__(self, model: Optional[str] = None, api_key: Optional[str]=None):\n",
    "        '''\n",
    "        GroqAnswerEvaluator constructor.\n",
    "\n",
    "        Args:\n",
    "            model (str, optional): model to use. Llama3 70B is used if None. Default is None\n",
    "            api_key (str, optional): Groq API key to use, if None will check the environment 'GROQ_API_KEY' variable. Default is None.\n",
    "        '''\n",
    "\n",
    "        super().__init__(model, api_key, True, GroqAnswerEvaluator._system_message)\n",
    "\n",
    "    def __call__(self, answer_correct:str, answer:str) -> bool:\n",
    "        '''\n",
    "        Checks if the answer is correct\n",
    "\n",
    "        Args:\n",
    "            answer_correct (str): correct answer to compare.\n",
    "            answer (str): answer to evaluate.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if is correct.\n",
    "        '''\n",
    "\n",
    "        prompt = GroqAnswerEvaluator._base_prompt.format(answer_correct=answer_correct, answer=answer)\n",
    "\n",
    "        response = super().__call__(prompt)\n",
    "        response = json.loads(response)\n",
    "\n",
    "        return response[\"is_correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "  def remove_articles(text):\n",
    "    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "    return re.sub(regex, ' ', text)\n",
    "  def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "  def remove_accents(input_str):\n",
    "      nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "      only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "      return only_ascii.decode(\"utf-8\")\n",
    "\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(remove_accents(s)))))\n",
    "\n",
    "def get_tokens(s):\n",
    "  if not s: return []\n",
    "  return normalize_answer(s).split()\n",
    "\n",
    "def compute_exact(a_gold, a_pred):\n",
    "  return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
    "\n",
    "def compute_f1(a_gold, a_pred):\n",
    "  gold_toks = get_tokens(a_gold)\n",
    "  pred_toks = get_tokens(a_pred)\n",
    "  common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "  num_same = sum(common.values())\n",
    "  if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "    return int(gold_toks == pred_toks)\n",
    "  if num_same == 0:\n",
    "    return 0\n",
    "  precision = 1.0 * num_same / len(pred_toks)\n",
    "  recall = 1.0 * num_same / len(gold_toks)\n",
    "  f1 = (2 * precision * recall) / (precision + recall)\n",
    "  return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checamos o funcionamento das avaliações com um conjunto de resposta modelo, correta e errada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question is \"What is Zeus know for in Greek mythology?\"\n",
    "\n",
    "a_gold = \"sky and thunder god\"\n",
    "a_correct = \"Zeus is known as the king of the gods and the god of the sky and thunder in Greek mythology.\" #Correct and contains the expected answer \n",
    "a_wrong = \"Zeus is been depicted as using violence to get his way and terrorize humans.\" #±Correct, but not related to the expected answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_corrector = GroqAnswerEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_corrector(a_gold, a_correct), groq_corrector(a_gold, a_wrong),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(a_gold, a_correct), compute_exact(a_gold, a_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11111111111111112, 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(a_gold, a_wrong), compute_exact(a_gold, a_wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação do ReAct \n",
    "\n",
    "E podemos começar a implementação do ReAct. Ela é dividida entre a implementação das ferramentas que o agente terá disponível, e a implementação do código principal.\n",
    "\n",
    "O código é próximo ao ReAct, mas diverge em alguns pontos na manutenção do contexto (\"queries\" não são mantidas) e uso das ferramentas (\"think\" e \"answer\" são considerados ferramentas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ferramentas\n",
    "\n",
    "As ferramentas implementadas são \n",
    "- \"Search\": busca a partir de uma query no banco de documentos\n",
    "- \"Answer\": gera a resposta final\n",
    "- \"Think\": reflete sobre o contexto até o momento\n",
    "- \"Routing\": seleciona a próxima ferramenta a ser utilizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(abc.ABC):\n",
    "    '''\n",
    "    Base class for creating LLM agent tools.\n",
    "    '''\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def __call__(self, query:str, context:str) -> Dict[str, str]:\n",
    "        '''\n",
    "        Execute the tool.\n",
    "\n",
    "        Args:\n",
    "            query (str): query for the tool execution.\n",
    "            context (str): agent context in the tool execution moment.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, str]: tool results.\n",
    "        '''\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ferramenta de busca realiza uma busca inicial ampla nos documentos utilizando o BM25, e realiza um filtro e reranqueamento com um transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchTool(Tool):\n",
    "    '''\n",
    "    Search documents for some information.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, index_path:str, embedder_model:str=\"all-MiniLM-L6-v2\", search_k:int=20, rerank_k:int=5):\n",
    "        '''\n",
    "        SearchTool constructor.\n",
    "\n",
    "        Args:\n",
    "            index_path (str): path of the documents index.\n",
    "            embedder_model (str, optional): model to use for reranking. Defaults to \"all-MiniLM-L6-v2\".\n",
    "            search_k (int, optional): initial search size. Defaults to 20.\n",
    "            rerank_k (int, optional): rerank filter size. Defaults to 5.\n",
    "        '''\n",
    "        self.embedder = sentence_transformers.SentenceTransformer(embedder_model)\n",
    "        self.searcher = SimpleSearcher(index_path)\n",
    "\n",
    "        if search_k < rerank_k:\n",
    "            warnings.warn(f\"search_k is less than rerank_k. The result will be of search_k size. ({search_k} < {rerank_k})\")\n",
    "        \n",
    "        self.search_k = search_k\n",
    "        self.rerank_k = rerank_k\n",
    "    \n",
    "    def __call__(self, query:str, context:Optional[Any]=None) -> Dict[str, str]:\n",
    "        '''\n",
    "        Execute a search.\n",
    "\n",
    "        Args:\n",
    "            query (str): search term\n",
    "            context (Any, optional): not used. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, str]: search result. Have only the key \"result\" with the search result.\n",
    "        '''\n",
    "\n",
    "        \n",
    "        #Initial search\n",
    "        search_result = self.searcher.search(query, k=self.search_k)\n",
    "        \n",
    "        #Get documents\n",
    "        search_docs = []\n",
    "        for result in search_result:\n",
    "            result = json.loads(result.raw)\n",
    "\n",
    "            search_docs.append(result[\"segment\"])\n",
    "\n",
    "        #Rerank and filter\n",
    "        query_embedding = self.embedder.encode(query, convert_to_tensor=True)\n",
    "        search_embeddings = self.embedder.encode(search_docs, convert_to_tensor=True)\n",
    "\n",
    "        rerank_result = sentence_transformers.util.semantic_search(query_embedding, search_embeddings, top_k=self.rerank_k)\n",
    "\n",
    "        #Generate response with the selected documents\n",
    "        response = \"\"\n",
    "        for result in rerank_result[0]:\n",
    "            index = result[\"corpus_id\"]\n",
    "            result_doc = search_docs[index]\n",
    "\n",
    "            response += result_doc + \"\\n\"\n",
    "        \n",
    "        response = {\"result\":response}\n",
    "\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerTool(Tool, GroqInterface):\n",
    "    '''\n",
    "    Generates the final answer to a question.\n",
    "    '''\n",
    "\n",
    "\n",
    "    _system_message = '''You are a question answerer that outputs in JSON. \n",
    "The JSON object must use the schema: {'answer':'str'}\n",
    "Please use a valid JSON format.'''\n",
    "\n",
    "    _base_prompt = '''{context}\n",
    "\n",
    "Considering all this context, provide the FINAL ANSWER to the question:\n",
    "'''\n",
    "\n",
    "    def __init__(self, model: Optional[str] = None, api_key: Optional[str] = None):\n",
    "        '''\n",
    "        AnswerTool constructor.\n",
    "\n",
    "        Args:\n",
    "            model (str, optional): model to use. Llama3 70B is used if None. Default is None\n",
    "            api_key (str, optional): Groq API key to use, if None will check the environment 'GROQ_API_KEY' variable. Default is None.\n",
    "        '''\n",
    "\n",
    "        super().__init__(model, api_key, True, AnswerTool._system_message)\n",
    "\n",
    "    def __call__(self, query:Optional[Any]=None, context:str=None) -> Dict[str, str]:\n",
    "        '''\n",
    "        Answers a question considering the agent context.\n",
    "\n",
    "        Args:\n",
    "            query (Optional[Any], optional): not used. Defaults to None.\n",
    "            context (str): context of the agent, must contain the question.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, str]: agent response. Contains only the key \"answer\" with the answer.\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        prompt = AnswerTool._base_prompt.format(context=context)\n",
    "\n",
    "        return json.loads(GroqInterface.__call__(self, prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThinkTool(Tool, GroqInterface):\n",
    "    '''\n",
    "    Reflects about the agent context.\n",
    "    '''\n",
    "\n",
    "    _system_message = '''You are responsible for reflecting on provided information, and outputs in JSON. \n",
    "The JSON object must use the schema: {'reflection':'str'}\n",
    "Please use a valid JSON format.'''\n",
    "\n",
    "    _base_prompt = '''{context}\n",
    "\n",
    "Considering all this context, provide a useful reflection.\n",
    "'''\n",
    "\n",
    "    def __init__(self, model: Optional[str] = None, api_key: Optional[str] = None):\n",
    "        '''\n",
    "        ThinkTool constructor.\n",
    "\n",
    "        Args:\n",
    "            model (str, optional): model to use. Llama3 70B is used if None. Default is None\n",
    "            api_key (str, optional): Groq API key to use, if None will check the environment 'GROQ_API_KEY' variable. Default is None.\n",
    "        '''\n",
    "\n",
    "        super().__init__(model, api_key, True, ThinkTool._system_message)\n",
    "\n",
    "    def __call__(self, query:Optional[Any]=None, context: str=None) -> Dict[str, str]:\n",
    "        '''\n",
    "        Think about the agent context, generating a useful reflection.\n",
    "\n",
    "        Args:\n",
    "            query (Optional[Any], optional): not used. Defaults to None.\n",
    "            context (str): agent context to reflect about. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, str]: tool result. Contains only the key \"reflection\" with the reflection.\n",
    "        '''\n",
    "\n",
    "        prompt = ThinkTool._base_prompt.format(context=context)\n",
    "\n",
    "        return json.loads(GroqInterface.__call__(self, prompt=prompt))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutingTool(Tool, GroqInterface):\n",
    "    '''\n",
    "    Selects the next agent tool.\n",
    "    '''\n",
    "\n",
    "\n",
    "    _system_message = '''You are a tool selector that outputs in JSON.\n",
    "For each selection, you must provide a throught about the previous content and why you are selecting this tool.\n",
    "\n",
    "You have available the following tools:\n",
    "\n",
    "Name: 'search'\n",
    "Query content: the sentence to search\n",
    "Tool description: it searchs for documents with possible usefull information using the query.\n",
    "\n",
    "Name: 'answer'\n",
    "Query content: empty (''), is not used.\n",
    "Tool description: considering the previous content, provides the final answer for the question.\n",
    "\n",
    "Name: 'think'\n",
    "Query content: empty (''), is not used;\n",
    "Tool descripting: considering the previous content, generates a useful reflection.\n",
    "\n",
    "The JSON object must use the schema: {'throught':'str',\n",
    "'tool_name':'str',\n",
    "'query':'str'}\n",
    "\n",
    "Please use a valid JSON format.'''\n",
    "\n",
    "    _base_prompt = '''{context}\n",
    "    \n",
    "Considering all this context, select the next tool to use:\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: Optional[str] = None, api_key: Optional[str] = None):\n",
    "        '''\n",
    "        RoutingTool constructor.\n",
    "\n",
    "        Args:\n",
    "            model (str, optional): model to use. Llama3 70B is used if None. Default is None\n",
    "            api_key (str, optional): Groq API key to use, if None will check the environment 'GROQ_API_KEY' variable. Default is None.\n",
    "        '''\n",
    "\n",
    "        super().__init__(model, api_key, True, RoutingTool._system_message)\n",
    "\n",
    "    def __call__(self, query:Optional[Any]=None, context:str=None) -> Dict[str, str]:\n",
    "        '''\n",
    "        Select the next tool for the agent.\n",
    "\n",
    "        Args:\n",
    "            query (Optional[Any], optional): not used. Defaults to None.\n",
    "            context (str, optional): agent context to decide the next tool. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, str]: tool result. Have the keys 'tool_name' (next tool to use), \n",
    "                'throught' (why use this tool), 'query' (query to send to the tool).\n",
    "        '''\n",
    "        prompt = RoutingTool._base_prompt.format(context=context)\n",
    "\n",
    "        return json.loads(GroqInterface.__call__(self, prompt=prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar as ferramentas, vamos executar passo a passo um processo de resposta, chamando manualmente o código necessário e compondo o contexto. Observe que, pela re-execução do notebook, algumas sentenças nos contextos montados podem não coincidir exatamente com a resposta do modelo.\n",
    "\n",
    "Começamos pela definição da questão e criação das ferramentas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question = \"What is Zeus know for in Greek mythology?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleSearcher class has been deprecated, please use LuceneSearcher from pyserini.search.lucene instead\n"
     ]
    }
   ],
   "source": [
    "search_tool = SearchTool(index_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tool = AnswerTool()\n",
    "think_tool = ThinkTool()\n",
    "\n",
    "routing_tool = RoutingTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O contexto inicial contém apenas a questão, e é utilizado para selecionar a primeira ferramenta (não considerando a ferramenta de roteamento que sempre é utilizada entre as outras):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thought': 'The user has asked a question about Greek mythology, I need to find relevant information.',\n",
       " 'tool_name': 'search',\n",
       " 'query': 'What is Zeus known for in Greek mythology?'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_context = f'''Question: {test_question}'''\n",
    "\n",
    "routing_tool(context=test_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ferramenta de busca foi selecionada. Vamos executar a busca:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = search_tool(\"Zeus Greek mythology\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeus (British English , North American English ; , Zeús ) is the sky and thunder god in ancient Greek religion, who rules as king of the gods of Mount Olympus. His name is cognate with the first element of his Roman equivalent Jupiter. His mythologies and powers are similar, though not identical, to those of Indo-European deities such as Jupiter, Perkūnas, Perun, Indra and Thor. Zeus is the child of Cronus and Rhea, the youngest of his siblings to be born, though sometimes reckoned the eldest as the others required disgorging from Cronus's stomach. In most traditions, he is married to Hera, by whom he is usually said to have fathered Ares, Hebe, and Hephaestus.\n",
      "Since lightning is quite powerful and sometimes deadly, it is a bold sign when lightning strikes because it is known that Zeus most likely threw the bolt. In the Iliad. The Iliad is a poem by Homer about the Trojan war and the battle over the City of Troy, in which Zeus plays a major part. Scenes in which Zeus appears include:\n",
      "\n",
      "- Book 2: Zeus sends Agamemnon a dream and is able to partially control his decisions because of the effects of the dream\n",
      "- Book 4: Zeus promises Hera to ultimately destroy the City of Troy at the end of the war\n",
      "- Book 7: Zeus and Poseidon ruin the Achaeans fortress\n",
      "- Book 8: Zeus prohibits the other Gods from fighting each other and has to return to Mount Ida where he can think over his decision that the Greeks will lose the war\n",
      "- Book 14: Zeus is seduced by Hera and becomes distracted while she helps out the Greeks\n",
      "- Book 15: Zeus wakes up and realizes that Poseidon his own brother has been helping out the Greeks, while also sending Hector and Apollo to help fight the Trojans ensuring that the City of Troy will fall\n",
      "- Book 16: Zeus is upset that he couldn't help save Sarpedon's life because it would then contradict his previous decisions\n",
      "- Book 17: Zeus is emotionally hurt by the fate of Hector\n",
      "- Book 20: Zeus lets the other Gods help out their respective sides in the war\n",
      "- Book 24: Zeus demands that Achilles release the corpse of Hector to be buried honourably\n",
      "\n",
      "List of other deeds.- Zeus granted Callirrhoe's prayer that her sons by Alcmaeon, Acarnan and Amphoterus, grow quickly so that they might be able to avenger the death of their father by the hands of Phegeus and his two sons. - He unsuccessfully wooed Thetis, daughter of Nereus.\n",
      "Scenes in which Zeus appears include:\n",
      "\n",
      "- Book 2: Zeus sends Agamemnon a dream and is able to partially control his decisions because of the effects of the dream\n",
      "- Book 4: Zeus promises Hera to ultimately destroy the City of Troy at the end of the war\n",
      "- Book 7: Zeus and Poseidon ruin the Achaeans fortress\n",
      "- Book 8: Zeus prohibits the other Gods from fighting each other and has to return to Mount Ida where he can think over his decision that the Greeks will lose the war\n",
      "- Book 14: Zeus is seduced by Hera and becomes distracted while she helps out the Greeks\n",
      "- Book 15: Zeus wakes up and realizes that Poseidon his own brother has been helping out the Greeks, while also sending Hector and Apollo to help fight the Trojans ensuring that the City of Troy will fall\n",
      "- Book 16: Zeus is upset that he couldn't help save Sarpedon's life because it would then contradict his previous decisions\n",
      "- Book 17: Zeus is emotionally hurt by the fate of Hector\n",
      "- Book 20: Zeus lets the other Gods help out their respective sides in the war\n",
      "- Book 24: Zeus demands that Achilles release the corpse of Hector to be buried honourably\n",
      "\n",
      "List of other deeds.- Zeus granted Callirrhoe's prayer that her sons by Alcmaeon, Acarnan and Amphoterus, grow quickly so that they might be able to avenger the death of their father by the hands of Phegeus and his two sons. - He unsuccessfully wooed Thetis, daughter of Nereus. Zeus and Hera. Zeus was brother and consort of Hera. By Hera, Zeus sired Ares, Hebe and Hephaestus, though some accounts say that Hera produced these offspring alone.\n",
      "He was equated with many foreign weather gods, permitting Pausanias to observe \"That Zeus is king in heaven is a saying common to all men\". Zeus' symbols are the thunderbolt, eagle, bull, and oak. In addition to his Indo-European inheritance, the classical \"cloud-gatherer\" (Greek: , Nephelēgereta) also derives certain iconographic traits from the cultures of the ancient Near East, such as the scepter. Zeus is frequently depicted by Greek artists in one of two poses: standing, striding forward with a thunderbolt leveled in his raised right hand, or seated in majesty. Name.\n",
      "Greek mythology is known today primarily from Greek literature and representations on visual media dating from the Geometric period from to onward. In fact, literary and archaeological sources integrate, sometimes mutually supportive and sometimes in conflict; however, in many cases, the existence of this corpus of data is a strong indication that many elements of Greek mythology have strong factual and historical roots. Literary sources. Mythical narration plays an important role in nearly every genre of Greek literature. Nevertheless, the only general mythographical handbook to survive from Greek antiquity was the Library of Pseudo-Apollodorus.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(search_result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compor o novo contexto e selecionar a próxima ferramenta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thought': 'Now that I have searched and found information about Zeus in Greek mythology, I can reflect on the key points to understand the essence of his character and significance.',\n",
       " 'tool_name': 'think',\n",
       " 'query': ''}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_context2 = f'''\n",
    "Question: {test_question}\n",
    "\n",
    "Thought: I need to search for information about Zeus in Greek mythology to find the answer.\n",
    "Search result: {search_result[\"result\"]}\n",
    "'''\n",
    "\n",
    "routing_tool(context=test_context2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executamos a ferramenta de pensamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reflection': \"Zeus, in Greek mythology, is the king of the gods, known for being the sky and thunder god, ruling from Mount Olympus. He wields significant power, controlling the weather and fate of humans, often using his lightning bolts to intervene in mortal affairs. Throughout literature, such as in Homer's Iliad, Zeus plays a major role, influencing the war and its outcome. His character is multifaceted, displaying emotions, making decisions, and interacting with other gods and mortals. His power and influence are undeniable, making him a central figure in Greek mythology.\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_context3 = f'''\n",
    "Question: {test_question}\n",
    "\n",
    "Thought: I need to search for information about Zeus in Greek mythology to find the answer.\n",
    "Search result: {search_result[\"result\"]}\n",
    "\n",
    "Thought: I have gathered information about Zeus in Greek mythology, now I need to think about the context to understand the main points and reflect on the answer.\n",
    "'''\n",
    "\n",
    "think_tool(context=test_context3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Próximo roteamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thought': 'I have thought about the context and I think it is time to answer the question.',\n",
       " 'tool_name': 'answer',\n",
       " 'query': ''}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_context4 = f'''\n",
    "Question: {test_question}\n",
    "\n",
    "Thought: I need to search for information about Zeus in Greek mythology to find the answer.\n",
    "Search result: {search_result[\"result\"]}\n",
    "\n",
    "Thought: I have gathered information about Zeus in Greek mythology, now I need to think about the context to understand the main points and reflect on the answer.\n",
    "Think result: Zeus is known as the sky and thunder god in ancient Greek religion and is often depicted holding a thunderbolt. He is the king of the gods and is married to Hera, with whom he has fathered several children. His powers and mythologies are similar to those of other Indo-European deities, such as Jupiter in Roman mythology. He is often depicted in art standing or seated in majesty, holding a scepter, and is associated with the eagle, bull, and oak.\"\n",
    "'''\n",
    "\n",
    "routing_tool(context=test_context4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E chamamos por fim a ferramenta de resposta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Zeus is known as the sky and thunder god in ancient Greek religion, and is the king of the gods of Mount Olympus.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_context5 = f'''\n",
    "Question: {test_question}\n",
    "\n",
    "Thought: I need to search for information about Zeus in Greek mythology to find the answer.\n",
    "Search result: {search_result[\"result\"]}\n",
    "\n",
    "Thought: I have gathered information about Zeus in Greek mythology, now I need to think about the context to understand the main points and reflect on the answer.\n",
    "Think result: Zeus is known as the sky and thunder god in ancient Greek religion, and is the king of the gods of Mount Olympus.\n",
    "\n",
    "Thought: \"I\\'ve reflected on the information and main points about Zeus, now I need to provide a concise answer to the original question.\"\n",
    "'''\n",
    "\n",
    "answer_tool(context=test_context5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código principal\n",
    "\n",
    "O código principal tem como função utilizar as ferramentas para responder questões, compondo o contexto com os resultados delas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswerer:\n",
    "    '''\n",
    "    Answers a question using a LLM agent.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, search_tool:SearchTool, routing_tool:Optional[RoutingTool]=None, \n",
    "                 think_tool:Optional[ThinkTool]=None, answer_tool:Optional[AnswerTool]=None ) -> None:\n",
    "        '''\n",
    "        QuestionAnswerer constructor.\n",
    "\n",
    "        Args:\n",
    "            search_tool (SearchTool): search tool for the agent.\n",
    "            routing_tool (Optional[RoutingTool], optional): routing tool for the agent. If None creates a new with default arguments. Defaults to None.\n",
    "            think_tool (Optional[ThinkTool], optional): think tool for the agent. If None creates a new with default arguments. Defaults to None.\n",
    "            answer_tool (Optional[AnswerTool], optional): answer tool for the agent. If None creates a new with default arguments. Defaults to None.\n",
    "        '''\n",
    "        \n",
    "        self._search_tool = search_tool\n",
    "\n",
    "        if routing_tool is None:\n",
    "            routing_tool = RoutingTool()\n",
    "\n",
    "        if think_tool is None:\n",
    "            think_tool = ThinkTool()\n",
    "\n",
    "        if answer_tool is None:\n",
    "            answer_tool = AnswerTool()\n",
    "\n",
    "        self._routing_tool = routing_tool\n",
    "        self._think_tool = think_tool\n",
    "        self._answer_tool = answer_tool\n",
    "\n",
    "        \n",
    "    def __call__(self, question:str, max_steps:int = 5, verbose=False) -> Tuple[str, str, str]:\n",
    "        '''\n",
    "        Answers a question using the agent.\n",
    "\n",
    "        Args:\n",
    "            question (str): question to answer.\n",
    "            max_steps (int, optional): maximum number of tools use, the last one is always \"AnswerTool\". Defaults to 5.\n",
    "            verbose (bool, optional): if should print the tool sequence while executing. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            str: answer for the question.\n",
    "            str: resulting context used to answer.\n",
    "            str: sequence of used tools.\n",
    "        '''\n",
    "\n",
    "        context = f\"Question: {question}\"\n",
    "        tool_sequence = \"\"\n",
    "\n",
    "        step = 0\n",
    "\n",
    "        while True:\n",
    "            \n",
    "            if step >= max_steps-1: #Max steps -> force answer\n",
    "                next_tool = \"answer\"\n",
    "                query = \"\"\n",
    "                thought = \"Now I need to provide a concise answer to the original question.\"\n",
    "            else: #Select next tool with the routing tool\n",
    "                if verbose:\n",
    "                    print(\"R\", end=\"\")\n",
    "                tool_sequence += \"R\"\n",
    "\n",
    "                rounting_result = self._routing_tool(context=context)\n",
    "                next_tool = rounting_result[\"tool_name\"].lower()\n",
    "                query = rounting_result[\"query\"]\n",
    "                thought = rounting_result[\"thought\"]\n",
    "\n",
    "            #Compose context with the reasoning about the tool usage\n",
    "            context += f\"\\n\\nThought: {thought}\\n\"\n",
    "\n",
    "            if verbose:\n",
    "                print(next_tool[0].upper(), end=\"\")\n",
    "            tool_sequence += next_tool[0].upper()\n",
    "\n",
    "            try:\n",
    "                \n",
    "                #Use the selected tool\n",
    "                if next_tool == \"search\":\n",
    "                    search_result = self._search_tool(query=query, context=context)\n",
    "                    context += f\"Search result: {search_result['result']}\"\n",
    "                elif next_tool == \"think\":\n",
    "                    think_result = self._think_tool(query=query, context=context)\n",
    "                    context += f\"Think result: {think_result['reflection']}\"\n",
    "                elif next_tool == \"answer\":\n",
    "                    answer_result = self._answer_tool(query=query, context=context)\n",
    "\n",
    "                    if verbose:\n",
    "                        print(\"\")\n",
    "                    \n",
    "                    #Answer tool ends the execution\n",
    "                    return answer_result[\"answer\"], context, tool_sequence\n",
    "                \n",
    "            except KeyboardInterrupt as e:\n",
    "                raise e\n",
    "            \n",
    "            except:\n",
    "                if verbose:\n",
    "                    print(\"F\", end=\"\\n\")\n",
    "                \n",
    "                tool_sequence += \"F\"\n",
    "                context += \"The tool failed. I can try using it again, or try using another tool.\"\n",
    "                \n",
    "            \n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testamos o agente com a mesma questão utilizada anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answerer = QuestionAnswerer(search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    }
   ],
   "source": [
    "answer, context, tool_sequence = question_answerer(test_question, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Zeus, in Greek mythology, is the king of the gods and the god of the sky and thunder. He is known for wielding powerful lightning bolts and is depicted in various poses in art, often with his symbols, the thunderbolt, eagle, bull, or oak. He is married to Hera and has fathered several children, including Ares, Hebe, and Hephaestus. Zeus plays a significant role in Homer's Iliad, influencing the outcome of the Trojan War.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Zeus know for in Greek mythology?\n",
      "\n",
      "Thought: I want to find relevant information about Zeus in Greek mythology, so I choose a tool that can search for related content.\n",
      "Search result: Zeus (British English , North American English ; , Zeús ) is the sky and thunder god in ancient Greek religion, who rules as king of the gods of Mount Olympus. His name is cognate with the first element of his Roman equivalent Jupiter. His mythologies and powers are similar, though not identical, to those of Indo-European deities such as Jupiter, Perkūnas, Perun, Indra and Thor. Zeus is the child of Cronus and Rhea, the youngest of his siblings to be born, though sometimes reckoned the eldest as the others required disgorging from Cronus's stomach. In most traditions, he is married to Hera, by whom he is usually said to have fathered Ares, Hebe, and Hephaestus.\n",
      "Since lightning is quite powerful and sometimes deadly, it is a bold sign when lightning strikes because it is known that Zeus most likely threw the bolt. In the Iliad. The Iliad is a poem by Homer about the Trojan war and the battle over the City of Troy, in which Zeus plays a major part. Scenes in which Zeus appears include:\n",
      "\n",
      "- Book 2: Zeus sends Agamemnon a dream and is able to partially control his decisions because of the effects of the dream\n",
      "- Book 4: Zeus promises Hera to ultimately destroy the City of Troy at the end of the war\n",
      "- Book 7: Zeus and Poseidon ruin the Achaeans fortress\n",
      "- Book 8: Zeus prohibits the other Gods from fighting each other and has to return to Mount Ida where he can think over his decision that the Greeks will lose the war\n",
      "- Book 14: Zeus is seduced by Hera and becomes distracted while she helps out the Greeks\n",
      "- Book 15: Zeus wakes up and realizes that Poseidon his own brother has been helping out the Greeks, while also sending Hector and Apollo to help fight the Trojans ensuring that the City of Troy will fall\n",
      "- Book 16: Zeus is upset that he couldn't help save Sarpedon's life because it would then contradict his previous decisions\n",
      "- Book 17: Zeus is emotionally hurt by the fate of Hector\n",
      "- Book 20: Zeus lets the other Gods help out their respective sides in the war\n",
      "- Book 24: Zeus demands that Achilles release the corpse of Hector to be buried honourably\n",
      "\n",
      "List of other deeds.- Zeus granted Callirrhoe's prayer that her sons by Alcmaeon, Acarnan and Amphoterus, grow quickly so that they might be able to avenger the death of their father by the hands of Phegeus and his two sons. - He unsuccessfully wooed Thetis, daughter of Nereus.\n",
      "Scenes in which Zeus appears include:\n",
      "\n",
      "- Book 2: Zeus sends Agamemnon a dream and is able to partially control his decisions because of the effects of the dream\n",
      "- Book 4: Zeus promises Hera to ultimately destroy the City of Troy at the end of the war\n",
      "- Book 7: Zeus and Poseidon ruin the Achaeans fortress\n",
      "- Book 8: Zeus prohibits the other Gods from fighting each other and has to return to Mount Ida where he can think over his decision that the Greeks will lose the war\n",
      "- Book 14: Zeus is seduced by Hera and becomes distracted while she helps out the Greeks\n",
      "- Book 15: Zeus wakes up and realizes that Poseidon his own brother has been helping out the Greeks, while also sending Hector and Apollo to help fight the Trojans ensuring that the City of Troy will fall\n",
      "- Book 16: Zeus is upset that he couldn't help save Sarpedon's life because it would then contradict his previous decisions\n",
      "- Book 17: Zeus is emotionally hurt by the fate of Hector\n",
      "- Book 20: Zeus lets the other Gods help out their respective sides in the war\n",
      "- Book 24: Zeus demands that Achilles release the corpse of Hector to be buried honourably\n",
      "\n",
      "List of other deeds.- Zeus granted Callirrhoe's prayer that her sons by Alcmaeon, Acarnan and Amphoterus, grow quickly so that they might be able to avenger the death of their father by the hands of Phegeus and his two sons. - He unsuccessfully wooed Thetis, daughter of Nereus. Zeus and Hera. Zeus was brother and consort of Hera. By Hera, Zeus sired Ares, Hebe and Hephaestus, though some accounts say that Hera produced these offspring alone.\n",
      "He was equated with many foreign weather gods, permitting Pausanias to observe \"That Zeus is king in heaven is a saying common to all men\". Zeus' symbols are the thunderbolt, eagle, bull, and oak. In addition to his Indo-European inheritance, the classical \"cloud-gatherer\" (Greek: , Nephelēgereta) also derives certain iconographic traits from the cultures of the ancient Near East, such as the scepter. Zeus is frequently depicted by Greek artists in one of two poses: standing, striding forward with a thunderbolt leveled in his raised right hand, or seated in majesty. Name.\n",
      "Greek mythology is known today primarily from Greek literature and representations on visual media dating from the Geometric period from to onward. In fact, literary and archaeological sources integrate, sometimes mutually supportive and sometimes in conflict; however, in many cases, the existence of this corpus of data is a strong indication that many elements of Greek mythology have strong factual and historical roots. Literary sources. Mythical narration plays an important role in nearly every genre of Greek literature. Nevertheless, the only general mythographical handbook to survive from Greek antiquity was the Library of Pseudo-Apollodorus.\n",
      "\n",
      "\n",
      "Thought: I have a lot of information about Zeus in Greek mythology, but I want to reflect on the most important aspects of his character and deeds to provide a concise answer to the question.\n",
      "Think result: Zeus, in Greek mythology, is the king of the gods and the god of the sky and thunder. He is known for wielding powerful lightning bolts and is depicted in various poses in art, often with his symbols, the thunderbolt, eagle, bull, or oak. He is married to Hera and has fathered several children, including Ares, Hebe, and Hephaestus. Zeus plays a significant role in Homer's Iliad, influencing the outcome of the Trojan War. His deeds include granting wishes, helping or hindering mortals, and intervening in human conflicts, making him a central figure in Greek mythology.\n",
      "\n",
      "Thought: I've reflected on the key aspects of Zeus' character in Greek mythology and now I'm ready to provide a concise answer to the question.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.1142857142857143, 0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_corrector(a_gold, answer), compute_f1(a_gold, answer), compute_exact(a_gold, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RSRTRA'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração das respostas\n",
    "\n",
    "Aqui serão geradas as respostas de todas as perguntas de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:35<28:57, 35.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [01:21<33:15, 41.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [01:44<25:50, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [02:28<28:53, 37.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [03:23<32:43, 43.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [04:08<32:25, 44.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [04:22<24:39, 34.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [05:25<30:24, 43.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [06:06<29:14, 42.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [06:24<23:21, 35.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [06:56<22:09, 34.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [07:14<18:34, 29.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [07:50<19:16, 31.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [08:34<21:01, 35.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [08:49<16:56, 29.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [10:08<25:00, 44.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [11:37<31:39, 57.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRSR"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [15:04<54:43, 102.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [15:34<41:36, 80.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [17:26<45:01, 90.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [18:38<40:54, 84.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [20:07<40:06, 85.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [21:15<36:17, 80.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [22:00<30:21, 70.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [24:07<36:13, 86.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [26:38<42:27, 106.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRSRTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [29:37<49:06, 128.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRSRSA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [31:56<48:11, 131.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [32:13<33:58, 97.05s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [32:59<27:16, 81.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [33:25<20:31, 64.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [34:10<17:44, 59.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [35:01<16:04, 56.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [35:43<13:52, 52.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [35:55<10:04, 40.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [37:41<13:59, 59.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [38:05<10:39, 49.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [39:01<10:13, 51.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [39:42<08:49, 48.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [40:04<06:41, 40.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [40:28<05:17, 35.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [40:51<04:14, 31.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [41:22<03:41, 31.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [41:43<02:50, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRSRTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [43:32<04:22, 52.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [43:54<02:52, 43.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [44:15<01:50, 36.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [44:51<01:13, 36.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [45:30<00:37, 37.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSRTRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [46:07<00:00, 55.35s/it]\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "file = open (\"results.jsonl\", \"w\")\n",
    "\n",
    "for i in tqdm.tqdm(range(n_question)):\n",
    "    question = questions[i][\"question\"]\n",
    "    gold_answer = questions[i][\"answer\"]\n",
    "\n",
    "    try:\n",
    "        answer, context, tool_sequence = question_answerer(question, verbose=True)\n",
    "\n",
    "        is_correct = groq_corrector(gold_answer, answer)\n",
    "        f1_score = compute_f1(gold_answer, answer)\n",
    "        exact_score = compute_exact(gold_answer, answer)\n",
    "\n",
    "    except KeyboardInterrupt as e:\n",
    "        file.close()\n",
    "        raise e\n",
    "        \n",
    "    except:\n",
    "        answer = \"\"\n",
    "        context = \"\"\n",
    "        tool_sequence = \"F\"\n",
    "        is_correct = False\n",
    "        f1_score = 0\n",
    "        exact_score = 0\n",
    "\n",
    "    entry = {\"question_number\": i,\n",
    "            \"question\":question,\n",
    "             \"gold_answer\":gold_answer,\n",
    "             \"answer\":answer,\n",
    "             \"tool_sequence\":tool_sequence,\n",
    "             \"is_correct\":is_correct,\n",
    "             \"f1_score\":f1_score,\n",
    "             \"exact_score\":exact_score,\n",
    "             \"context\":context}\n",
    "    \n",
    "    all_results.append(entry)\n",
    "\n",
    "    file.write(json.dumps(entry)+\"\\n\")\n",
    "    file.flush()\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "46 min 7,5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"results.json\", \"w\")\n",
    "json.dump(all_results, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação\n",
    "\n",
    "Com as respostas geradas, podemos avaliar a performance do agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"results.json\", \"r\")\n",
    "all_results = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos pelo cálculo das métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "F1 score: 0.47502661713188027 ± 0.45167093813665027\n",
      "Exact score: 0.36 ± 0.48\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0.0\n",
    "correctness = np.empty(n_question)\n",
    "f1_scores = np.empty(n_question)\n",
    "exact_scores = np.empty(n_question)\n",
    "tool_sequences = []\n",
    "\n",
    "for i in range(n_question):\n",
    "    accuracy += all_results[i][\"is_correct\"]\n",
    "    correctness[i] = all_results[i][\"is_correct\"]\n",
    "    f1_scores[i] = all_results[i][\"f1_score\"]\n",
    "    exact_scores[i] = all_results[i][\"exact_score\"]\n",
    "    tool_sequences.append(all_results[i][\"tool_sequence\"])\n",
    "\n",
    "accuracy /= n_question\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 score:\", f1_scores.mean(), \"±\", f1_scores.std())\n",
    "print(\"Exact score:\", exact_scores.mean(), \"±\", exact_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos verificar que o agente raramente tem uma resposta \"meio correta\" segundo o F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(f1_scores)\n",
    "\n",
    "plt.title(\"F1 score histogram\")\n",
    "plt.xlabel(\"F1 score\")\n",
    "plt.ylabel(\"Occurrences\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E que este score está de certa forma relacionado com a corretude da resposta, embora scores em aproximadamente (0.2, 0.6) sejam ambíguos sobre a corretude da resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'F1 score correctness')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f1_scores, correctness, \"o\")\n",
    "\n",
    "plt.xlabel(\"F1 score\")\n",
    "\n",
    "plt.yticks([0.0, 1.0], [\"Wrong\", \"Correct\"])\n",
    "plt.ylabel(\"Correctness\")\n",
    "\n",
    "plt.title(\"F1 score correctness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já o score de resposta idêntica incorreta não indica necessariamente que a resposta está errada, enquanto que não possui nenhum falso positivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative = np.bitwise_and(correctness == True, exact_scores == 0).sum()\n",
    "false_positive = np.bitwise_and(correctness == False, exact_scores == 1).sum()\n",
    "true_positive = np.bitwise_and(correctness == True, exact_scores == 1).sum()\n",
    "true_negative = np.bitwise_and(correctness == False, exact_scores == 0).sum()\n",
    "\n",
    "confusion_matrix = np.array([[true_positive, false_negative], [false_positive, true_negative]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Correctness vs Exact')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "im = ax.imshow(confusion_matrix, cmap=\"Greys_r\")\n",
    "\n",
    "markers = [\"Correct\", \"Wrong\"]\n",
    "\n",
    "ax.set_xticks(np.arange(len(markers)))\n",
    "ax.set_yticks(np.arange(len(markers)))\n",
    "ax.set_xticklabels(markers)\n",
    "ax.set_yticklabels(markers)\n",
    "\n",
    "plt.xlabel(\"Exact score\")\n",
    "plt.ylabel(\"Correctness score\")\n",
    "\n",
    "for i in range(len(markers)):\n",
    "        for j in range(len(markers)):\n",
    "            text = ax.text(j, i, np.around(confusion_matrix[i, j], decimals=2),\n",
    "                        ha=\"center\", va=\"center\", color=\"red\")\n",
    "            \n",
    "plt.suptitle(\"Confusion matrix\")\n",
    "plt.title(\"Correctness vs Exact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos agora para a análise das sequências de ferramentas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_sequences_unique, tool_sequences_count = np.unique(tool_sequences, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos inicialmente que a sequência mais utilizada é realizar uma busca, pensamento e responder a questão, que era a sequência esperada pensando o funcionamento de cada ferramente: primeiro o agente procura informações sobre a pergunta, seguido por uma reflexão sobre essas informações e a resposta final.\n",
    "\n",
    "A próxima sequência mais comum é pesquisar e responder, sem a etapa de pensamento, o que pode indicar que o agente considere desnecessário esta etapa, talvez pela resposta já estar clara nas informações encontradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(tool_sequences_unique, tool_sequences_count)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.title(\"Ocorrências das sequências de ferramentas\")\n",
    "plt.xlabel(\"Sequência de ferramentas\")\n",
    "plt.ylabel(\"Ocorrências\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy by tool\n",
    "\n",
    "tool_sequences_accuracy = {}\n",
    "for tool_sequence in tool_sequences_unique:\n",
    "    tool_sequences_accuracy[tool_sequence] = 0\n",
    "\n",
    "for result in all_results:\n",
    "    tool_sequence = result[\"tool_sequence\"]\n",
    "    tool_sequences_accuracy[tool_sequence] += result[\"is_correct\"]\n",
    "\n",
    "tool_sequences_accuracy_list = []\n",
    "\n",
    "for i in range(len(tool_sequences_unique)):\n",
    "    tool_sequence = tool_sequences_unique[i]\n",
    "    tool_sequences_accuracy[tool_sequence] /= tool_sequences_count[i]\n",
    "\n",
    "    tool_sequences_accuracy_list.append(tool_sequences_accuracy[tool_sequence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já ao analisar a acurácia das ferramentas, podemos observar que a sequência \"RSRSRA\" é a mais acurada, onde o agente realiza duas buscas antes de gerar uma repostas. Comparando junto da sequência \"RSRA\", é perceptível que sequências que realizam pensamentos são menos acuradas, enquanto que ambas as duas sequências que estouraram o limite de ferramentas não geraram nenhuma resposta válida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(tool_sequences_unique, tool_sequences_accuracy_list)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.title(\"Acurácia estimada das sequências de ferramentas\")\n",
    "plt.xlabel(\"Sequência de ferramentas\")\n",
    "plt.ylabel(\"Acurácia estimada\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geramos um grafo das ferramentas utilizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tool graph generation\n",
    "\n",
    "node_queue = collections.deque()\n",
    "node_queue.append(\"\")\n",
    "\n",
    "next_tool_occurrences = {}\n",
    "for t in [\"R\", \"A\", \"T\", \"S\", \"F\"]:\n",
    "    next_tool_occurrences[t] = 0\n",
    "\n",
    "adj_list = {}\n",
    "\n",
    "while len(node_queue) != 0:\n",
    "    current_node = node_queue.pop()\n",
    "\n",
    "    if current_node in adj_list:\n",
    "        continue\n",
    "\n",
    "\n",
    "    total_occurrences = 0\n",
    "    n_sequence = 0\n",
    "    sequences = {}\n",
    "    for i in range(len(tool_sequences_unique)):\n",
    "        sequence = tool_sequences_unique[i]\n",
    "        occurrences = tool_sequences_count[i]\n",
    "        \n",
    "        if len(sequence) > len(current_node):\n",
    "            if sequence[:len(current_node)] != current_node:\n",
    "                continue\n",
    "            \n",
    "            next_char = sequence[len(current_node)]\n",
    "\n",
    "            total_occurrences += occurrences\n",
    "            next_tool_occurrences[next_char] += occurrences\n",
    "\n",
    "            if next_char in sequences:\n",
    "                sequences[next_char] += occurrences\n",
    "                \n",
    "            else:\n",
    "                sequences[next_char] = occurrences\n",
    "\n",
    "                if current_node+next_char not in node_queue:\n",
    "                    node_queue.append(current_node+next_char)\n",
    "\n",
    "    \n",
    "\n",
    "    for sequence in sequences:\n",
    "        sequences[sequence] /= total_occurrences\n",
    "    adj_list[current_node] = sequences\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flowchart LR\n",
      "'' -->|F 2%| F\n",
      "'' -->|R 98%| R\n",
      "R -->|S 100%| RS\n",
      "RS -->|R 100%| RSR\n",
      "RSR -->|A 32.65%| RSRA\n",
      "RSR -->|S 4.08%| RSRS\n",
      "RSR -->|T 63.27%| RSRT\n",
      "RSRT -->|R 100%| RSRTR\n",
      "RSRTR -->|A 80.65%| RSRTRA\n",
      "RSRTR -->|S 19.35%| RSRTRS\n",
      "RSRTRS -->|R 100%| RSRTRSR\n",
      "RSRTRSR -->|A 50%| RSRTRSRA\n",
      "RSRTRSR -->|S 16.67%| RSRTRSRS\n",
      "RSRTRSR -->|T 33.33%| RSRTRSRT\n",
      "RSRTRSRT -->|A 100%| RSRTRSRTA\n",
      "RSRTRSRS -->|A 100%| RSRTRSRSA\n",
      "RSRS -->|R 100%| RSRSR\n",
      "RSRSR -->|A 100%| RSRSRA\n"
     ]
    }
   ],
   "source": [
    "#Print of the graph\n",
    "\n",
    "print(\"flowchart LR\")\n",
    "\n",
    "for node in adj_list:\n",
    "    for next_char in adj_list[node]:\n",
    "        node_to_print = node\n",
    "\n",
    "        if node_to_print == \"\":\n",
    "            node_to_print = \"''\"\n",
    "\n",
    "        probability = adj_list[node][next_char]\n",
    "        probability *= 100\n",
    "        probability = round(probability, 2)\n",
    "\n",
    "        if int(probability) == probability:\n",
    "            probability = int(probability)\n",
    "\n",
    "        next_node = node+next_char\n",
    "        print(f\"{node_to_print} -->|{next_char} {probability}%| {next_node}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renderizando o diagrama em [Mermaid Live Editor](https://mermaid.live/):\n",
    "\n",
    "[Disponível online](https://mermaid.ink/img/pako:eNptkkFrgzAYhv_KR2D00gZnVms9DITR03bxyzGXoOkqqzqyyBht__tSo0ldd0ue5-P9XkhOpOwqRTKyP3bf5UFqA6-FaBcLWK2ezzuIH86w8_cCtqkFdqAY7giPUXQFaAmOIxO6TqGby4HFNFk7nAeO8ESj1GEMmEPCaLxxnA-c_w3nLp5PC9LIL-DjCu5LbinzDkeH94k4Zfra6xuXz6WNTWiyCR7nngNjlLHgufd8TJ-t5iEf__Po_F3tsbSvfCNysiSN0o2sK_vCJ9ECCGIOqlGCZPZYSf0hiGgvdk72psOftiSZ0b1akv6zkka91PJdy4Zke3n8slRVten0m_syw8-5_AJB36Zj?type=png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://mermaid.ink/img/pako:eNptkkFrgzAYhv_KR2D00gZnVms9DITR03bxyzGXoOkqqzqyyBht__tSo0ldd0ue5-P9XkhOpOwqRTKyP3bf5UFqA6-FaBcLWK2ezzuIH86w8_cCtqkFdqAY7giPUXQFaAmOIxO6TqGby4HFNFk7nAeO8ESj1GEMmEPCaLxxnA-c_w3nLp5PC9LIL-DjCu5LbinzDkeH94k4Zfra6xuXz6WNTWiyCR7nngNjlLHgufd8TJ-t5iEf__Po_F3tsbSvfCNysiSN0o2sK_vCJ9ECCGIOqlGCZPZYSf0hiGgvdk72psOftiSZ0b1akv6zkka91PJdy4Zke3n8slRVten0m_syw8-5_AJB36Zj?type=png)](https://mermaid.live/edit#pako:eNptkkFrgzAYhv_KR2D00gZnVms9DITR03bxyzGXoOkqqzqyyBht__tSo0ldd0ue5-P9XkhOpOwqRTKyP3bf5UFqA6-FaBcLWK2ezzuIH86w8_cCtqkFdqAY7giPUXQFaAmOIxO6TqGby4HFNFk7nAeO8ESj1GEMmEPCaLxxnA-c_w3nLp5PC9LIL-DjCu5LbinzDkeH94k4Zfra6xuXz6WNTWiyCR7nngNjlLHgufd8TJ-t5iEf__Po_F3tsbSvfCNysiSN0o2sK_vCJ9ECCGIOqlGCZPZYSf0hiGgvdk72psOftiSZ0b1akv6zkka91PJdy4Zke3n8slRVten0m_syw8-5_AJB36Zj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E limpamos o grafo removendo as etapas de roteamento que sempre ocorrem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list_no_R = {}\n",
    "\n",
    "for node in adj_list:\n",
    "    if len(node) >= 1 and node[-1] == \"R\":\n",
    "        continue\n",
    "\n",
    "    next_nodes = {}\n",
    "\n",
    "    for next_char in adj_list[node]:\n",
    "        next_node = node+next_char\n",
    "\n",
    "        if next_char == \"R\":\n",
    "            next_node_prob = adj_list[node][next_char]\n",
    "\n",
    "            for next_next_char in adj_list[next_node]:\n",
    "                next_next_node = next_node+next_next_char\n",
    "                next_nodes[next_next_node] = next_node_prob*adj_list[next_node][next_next_char]\n",
    "\n",
    "        else:\n",
    "            next_nodes[next_node] = adj_list[node][next_char]\n",
    "\n",
    "    adj_list_no_R[node] = next_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flowchart LR\n",
      "'' -->|F 2%| F\n",
      "'' -->|S 98%| RS\n",
      "RS -->|A 32.65%| RSRA\n",
      "RS -->|S 4.08%| RSRS\n",
      "RS -->|T 63.27%| RSRT\n",
      "RSRT -->|A 80.65%| RSRTRA\n",
      "RSRT -->|S 19.35%| RSRTRS\n",
      "RSRTRS -->|A 50%| RSRTRSRA\n",
      "RSRTRS -->|S 16.67%| RSRTRSRS\n",
      "RSRTRS -->|T 33.33%| RSRTRSRT\n",
      "RSRTRSRT -->|A 100%| RSRTRSRTA\n",
      "RSRTRSRS -->|A 100%| RSRTRSRSA\n",
      "RSRS -->|A 100%| RSRSRA\n"
     ]
    }
   ],
   "source": [
    "print(\"flowchart LR\")\n",
    "\n",
    "for node in adj_list_no_R:\n",
    "    for next_node in adj_list_no_R[node]:\n",
    "        node_to_print = node\n",
    "\n",
    "        if node_to_print == \"\":\n",
    "            node_to_print = \"''\"\n",
    "\n",
    "        probability = adj_list_no_R[node][next_node]\n",
    "        probability *= 100\n",
    "        probability = round(probability, 2)\n",
    "\n",
    "        if int(probability) == probability:\n",
    "            probability = int(probability)\n",
    "        \n",
    "        next_char = next_node[-1]\n",
    "\n",
    "        print(f\"{node_to_print} -->|{next_char} {probability}%| {next_node}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renderizando o diagrama em [Mermaid Live Editor](https://mermaid.live/):\n",
    "\n",
    "[Disponível online](https://mermaid.ink/img/pako:eNplkTFvwjAQhf-KdVLFEiwnl8Sxh0pIFVO7xJ4qLxYxBZUkKA1qKfDf6yZgQGy-9717d_IdYNFWDiQsN-33YmW7nryWpplMyHT6fJyT5OlI5qFWRBReKJVpSjUoM4IJzbNBLGdBViSlbLTemDXJkSZ8lPW_XOpzSsFCih5zzkiRWFAMSI0oTM9YIJe2sEKc05xf8X2rJogU8Yr1BYedYnYTrkN6mH3H1cgfmF8LIqhdV9t15f_5YBpCDPQrVzsD0j8r230aMM3J--yub9W-WYDsu52LYLetbO9e1vajszXIpd18edVV677t3sbDDfeLYGub97a9enwN8gA_IOOkoDzmhWCcYyYYphHsQSYZp1mGmPIkzQVLkZ8i-B0iGOUiRYGc88LjQojTH4QenJc?type=png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://mermaid.ink/img/pako:eNplkTFvwjAQhf-KdVLFEiwnl8Sxh0pIFVO7xJ4qLxYxBZUkKA1qKfDf6yZgQGy-9717d_IdYNFWDiQsN-33YmW7nryWpplMyHT6fJyT5OlI5qFWRBReKJVpSjUoM4IJzbNBLGdBViSlbLTemDXJkSZ8lPW_XOpzSsFCih5zzkiRWFAMSI0oTM9YIJe2sEKc05xf8X2rJogU8Yr1BYedYnYTrkN6mH3H1cgfmF8LIqhdV9t15f_5YBpCDPQrVzsD0j8r230aMM3J--yub9W-WYDsu52LYLetbO9e1vajszXIpd18edVV677t3sbDDfeLYGub97a9enwN8gA_IOOkoDzmhWCcYyYYphHsQSYZp1mGmPIkzQVLkZ8i-B0iGOUiRYGc88LjQojTH4QenJc?type=png)](https://mermaid.live/edit#pako:eNplkTFvwjAQhf-KdVLFEiwnl8Sxh0pIFVO7xJ4qLxYxBZUkKA1qKfDf6yZgQGy-9717d_IdYNFWDiQsN-33YmW7nryWpplMyHT6fJyT5OlI5qFWRBReKJVpSjUoM4IJzbNBLGdBViSlbLTemDXJkSZ8lPW_XOpzSsFCih5zzkiRWFAMSI0oTM9YIJe2sEKc05xf8X2rJogU8Yr1BYedYnYTrkN6mH3H1cgfmF8LIqhdV9t15f_5YBpCDPQrVzsD0j8r230aMM3J--yub9W-WYDsu52LYLetbO9e1vajszXIpd18edVV677t3sbDDfeLYGub97a9enwN8gA_IOOkoDzmhWCcYyYYphHsQSYZp1mGmPIkzQVLkZ8i-B0iGOUiRYGc88LjQojTH4QenJc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos uma cadeia de Markov das ferramentas utilizadas. Possivelmente seria possível utilizar esta cadeia para replicar o funcionamento do agente, evitando as etapas de roteamento e diminuindo o custo de execução; embora a acurácia possa ser reduzida. Executar várias vezes o agente para uma mesma pergunta poderia também ser realizado com custo reduzido, gerando diferentes respostas que poderiam ser consolidadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora observando a probabilidade absoluta de selecionar uma ferramenta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R': 137, 'A': 49, 'T': 33, 'S': 58, 'F': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_tool_occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A | 34.75%\n",
      "T | 23.4%\n",
      "S | 41.13%\n",
      "F | 0.71%\n"
     ]
    }
   ],
   "source": [
    "total_tool_occurrences = 0\n",
    "for tool in next_tool_occurrences:\n",
    "    if tool == \"R\":\n",
    "        continue\n",
    "\n",
    "    total_tool_occurrences += next_tool_occurrences[tool]\n",
    "\n",
    "\n",
    "next_tool_probs = {}\n",
    "for tool in next_tool_occurrences:\n",
    "    if tool == \"R\":\n",
    "        continue\n",
    "\n",
    "    next_tool_probs[tool] = next_tool_occurrences[tool]/total_tool_occurrences\n",
    "\n",
    "for tool in next_tool_probs:\n",
    "    print(tool, \"|\", f\"{round(next_tool_probs[tool]*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Próxima ferramenta| Probabilidade\n",
    "-|-\n",
    "A | 34.75%\n",
    "T | 23.4%\n",
    "S | 41.13%\n",
    "F | 0.71%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que a ferramenta de busca é a mais utilizada, o que indica que o agente entendeu a necessidade de buscar informações sobre a pergunta; seguinda pela de resposta, que obrigatoriamente aparece uma vez em todas as sequências; e por fim pela ferramenta de pensamento, que tem utilidade questionável pelos dados de acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplos de contextos\n",
    "\n",
    "Nesta seçãoa analisaremos casos específicos de sequências de ferramentas, comparando com o contexto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_context(index:int):\n",
    "    '''\n",
    "    Prints the result context.\n",
    "\n",
    "    Args:\n",
    "        index (int): question context to print.\n",
    "    '''\n",
    "    for line in all_results[index][\"context\"].split(\"\\n\"):\n",
    "        first = line.split(\" \")[0]\n",
    "        if first in [\"Thought:\"]:\n",
    "            print(line)\n",
    "        elif first in [\"Question:\", \"Think\"]:\n",
    "            print(line+\"\\n\")\n",
    "        elif first in [\"Search\"]:\n",
    "            print(\"SEARCH RESULT\\n\")\n",
    "\n",
    "def print_answers(index:int):\n",
    "    '''\n",
    "    Prints the result answer.\n",
    "\n",
    "    Args:\n",
    "        index (int): question to print the answer.\n",
    "    '''\n",
    "    print(\"Answer:\", all_results[index][\"answer\"], \"| Correct:\", all_results[index][\"gold_answer\"])\n",
    "\n",
    "def print_separator():\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSRTRSRTA\n",
    "\n",
    "Existem dois casos com esta sequência, ambos incorretos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How long had the Perthshire Regiment been a going concern for when Harison joined it as a captain?\n",
      "\n",
      "Thought: I need to find information related to the Perthshire Regiment and its history to answer this question.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: I have some historical information about the 73rd (Perthshire) Regiment of Foot, but I need to think about how this information can be used to answer the question about how long the regiment had been a going concern when Harison joined it as a captain.\n",
      "Think result: After reviewing the historical context of the Perthshire Regiment, it is unclear when exactly Harison joined the regiment as a captain, which makes it difficult to determine how long the regiment had been a going concern at that time. Further information about Harison's timeline is needed to answer this question accurately.\n",
      "\n",
      "Thought: I need more context about Harison's timeline to accurately determine how long the Perthshire Regiment had been a going concern when he joined it as a captain.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: I have the historical context of the Perthshire Regiment and Harison's timeline, now I need to think about how this information can be used to answer the question about how long the regiment had been a going concern when Harison joined it as a captain.\n",
      "Think result: After reviewing the historical context of the Perthshire Regiment and Harison's timeline, it is clear that Harison joined the regiment as a captain in 1849. Since the regiment was formed in 1786, it had been in existence for approximately 63 years when Harison joined it.\n",
      "\n",
      "Thought: Now I need to provide a concise answer to the original question.\n"
     ]
    }
   ],
   "source": [
    "print_context(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How much behind did the was the bronze medalist from the gold medalist?\n",
      "\n",
      "Thought: I need to search for documents that contain information about Olympic medals and their corresponding times or positions.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: The search results didn't provide a clear answer to the question, but it provided some information about Olympic medals. I need to think about the context and reflect on what could be useful to find the answer.\n",
      "Think result: The provided information is about Olympic medals, specifically discussing ice hockey and the history of the Olympic games. While it does not provide a direct answer to the question of how much behind the bronze medalist was from the gold medalist, it highlights the importance of understanding the context of the Olympic games and medals. Perhaps, searching for more specific information about Olympic event timings or scores could provide a clearer answer. Additionally, considering the historical context and the lack of specific information, it might be necessary to rephrase the question or provide more details about the specific event or Olympic game being referred to.\n",
      "\n",
      "Thought: I need to use the search tool to find more specific information about Olympic event timings or scores, which could provide a clearer answer to the original question.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: I need to carefully consider the search results, think about the context, and try to find the answer to the original question.\n",
      "Think result: The search results provided a wealth of information about Olympic medals and events, but did not directly answer the question of how much behind the bronze medalist was from the gold medalist. However, they highlighted the importance of considering the context of the Olympic games and medals. To find a clearer answer, it might be necessary to rephrase the question or provide more details about the specific event or Olympic game being referred to. Additionally, searching for more specific information about Olympic event timings or scores could provide a clearer answer.\n",
      "\n",
      "Thought: Now I need to provide a concise answer to the original question.\n"
     ]
    }
   ],
   "source": [
    "print_context(44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com estas duas sequências, o primeiro caso indica uma falha em si do agente, enquanto que na segunda ele não obteve as informações necessárias para respoder a questão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSRTRSRSA\n",
    "\n",
    "Neste caso existe apenas uma sequência, também com resposta incorreta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When was the company for which Tookey called a protest for founded?\n",
      "\n",
      "Thought: I'm not sure what company is referred to, so I need to search for more information.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: After searching for more information, I have a lot of details about Tookey and his campaigns, but I still need to think about all this content to understand what company was referred to.\n",
      "Think result: I didn't find a specific company mentioned in the provided information. The text discusses Tookey's campaigns against certain films, like Crash and Life of Brian, but doesn't mention a company that he called a protest for. It seems that more context or information is needed to answer this question.\n",
      "\n",
      "Thought: After thinking about the previous content, I realized that I couldn't find a specific company mentioned in the text. Therefore, I need to search again with more context or information to answer the question.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: I need to search again with more context or information to answer the question.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: Now I need to provide a concise answer to the original question.\n"
     ]
    }
   ],
   "source": [
    "print_context(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, observamos que o agente não obteve informações úteis para responder a questão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSRSRA\n",
    "\n",
    "Duas sequências, ambas corretas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which stadium where Brunt played can hold more people, The Hawthorns or White Hart Lane?\n",
      "\n",
      "Thought: I need to find information about the capacity of The Hawthorns and White Hart Lane stadiums\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: I need to find the capacity of The Hawthorns stadium to compare with the one of White Hart Lane and decide which one can hold more people\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: I have found the capacities of both stadiums, I need to compare them to find the answer\n"
     ]
    }
   ],
   "source": [
    "print_context(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How much time had passed between Wilhelm's return to studies at Berlin and the birth of his son Friedrich?\n",
      "\n",
      "Thought: We need to find relevant information about Wilhelm's studies and his son Friedrich's birth, so we can calculate the time between them.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: We've found some useful information about Wilhelm's studies at Berlin University, but we still need to find the birth date of his son Friedrich to calculate the time between them.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: Now that we have found the birth date of Wilhelm's son Friedrich Max Müller, we can calculate the time between Wilhelm's return to studies at Berlin and the birth of his son.\n"
     ]
    }
   ],
   "source": [
    "print_context(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este é um caso particularmente interessante, onde o agente precisa realizar uma comparação entre dados, e consegue realizar corretamente a busca por eles antes de gerar uma resposta correta. Isso demonstra o potencial de dar agência ao modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSRA\n",
    "\n",
    "Nestes casos o agente considera que já possui informações suficientes logo após a primeira busca.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro caso, correto, o agente rapidamente obtém a informação e responde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How old was Messe when the First World War started?\n",
      "\n",
      "Thought: I need to find information related to Pablo Messe and the First World War, so I'll use a search tool to find relevant documents.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: I have retrieved relevant information about Giovanni Messe and the First World War, so I'll use an 'answer' tool to provide the final answer to the question.\n"
     ]
    }
   ],
   "source": [
    "print_context(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já os próximos dois casos são semelhantes, porém são corrigidas como incorretas. Elas são na verdade erros do corretor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: In which Italian region did Pesce studied medicine?\n",
      "\n",
      "Thought: I want to find documents that might have information about Pesce's life and education, so I'll use the search tool to look for relevant information.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: I have found the information I was looking for, which is the region where Pesce studied medicine, so I'll use the answer tool to provide the final answer to the question.\n",
      "----------\n",
      "Answer: Genoa | Correct: Liguria\n"
     ]
    }
   ],
   "source": [
    "print_context(10)\n",
    "print_separator()\n",
    "print_answers(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genoa é a capital da Liguria, sendo a resposta do modelo foi mais precisa do que a esperada pela questão, e o corretor não sabia dessa informação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which team won the first game in the 2004 National League Division Series?\n",
      "\n",
      "Thought: I don't have enough information to answer this question, I need to search for relevant documents.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: I have all the necessary information to answer the question, now I can generate the answer.\n",
      "----------\n",
      "Answer: The St. Louis Cardinals won the first game in the 2004 National League Division Series. | Correct: Cardinals \n"
     ]
    }
   ],
   "source": [
    "print_context(30)\n",
    "print_separator()\n",
    "print_answers(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O corretor não percebeu que \"St. Louis Cardinals\" é o nome completo do time \"Cardinals\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já o próximo caso incorreto mais uma vez mostra uma falha na busca por informações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many years did the player who  top-scored for Turks and Caicos Islands during  the 2008 Standford 20/20 play for the team?\n",
      "\n",
      "Thought: I don't have enough information to provide a direct answer, so I need to search for related information.\n",
      "SEARCH RESULT\n",
      "\n",
      "Thought: I have all the information I need, and I can answer the question directly\n",
      "----------\n",
      "Answer: Unknown, as there is no information about the time period Donovan Anthony Matthews played for the team. | Correct: 1 year\n"
     ]
    }
   ],
   "source": [
    "print_context(14)\n",
    "print_separator()\n",
    "print_answers(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corretor\n",
    "\n",
    "Analisando as respostas indicadas como corretas pelo corretor, apenas 1 questão não possui resposta inteiramente correta, que pede um levantamente de pessoas e universidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Frank McPhee, Princeton\n",
      "- Bernie Flowers, Purdue\n",
      "- Eddie Bell, Pennsylvania\n",
      "- Tom Stolhandske, Texas\n",
      "- Tom Scott, Virginia\n",
      "- Joe Collier, Northwestern\n",
      "- Don Branby, Colorado\n",
      "- Buck Martin, Georgia Tech\n",
      "- Steve Mellinger, Kentucky\n",
      "- Ed Luke, Michigan State\n",
      "- Harry Babcock, Georgia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_results[24][\"gold_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frank McPhee of Princeton, Bernie Flowers of Purdue, Eddie Bell of Pennsylvania, Tom Stolhandske of Texas, Tom Scott of Virginia, Joe Collier of Northwestern, Buck Martin of Georgia Tech, Steve Mellinger of Kentucky, and Ed Luke of Michigan State.\n"
     ]
    }
   ],
   "source": [
    "print(all_results[24][\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obsevar que o agente levanta corretamente 9 das 11 pessoas necessárias, sendo uma resposta não interamente correta, mas também não interamente incorreta:\n",
    "\n",
    "Correto|Agente\n",
    "-|-\n",
    "Frank McPhee, Princeton | Frank McPhee of Princeton\n",
    "Bernie Flowers, Purdue | Bernie Flowers of Purdue\n",
    "Eddie Bell, Pennsylvania | Eddie Bell of Pennsylvania\n",
    "Tom Stolhandske, Texas | Tom Stolhandske of Texas\n",
    "Tom Scott, Virginia | Tom Scott of Virginia\n",
    "Joe Collier, Northwestern | Joe Collier of Northwestern\n",
    "Don Branby, Colorado | \n",
    "Buck Martin, Georgia Tech | Buck Martin of Georgia Tech \n",
    "Steve Mellinger, Kentucky | Steve Mellinger of Kentucky\n",
    "Ed Luke, Michigan State | Ed Luke of Michigan State  \n",
    "Harry Babcock, Georgia | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "Analisando de perto os contextos e respostas do modelo, é possível perceber uma necessidade de se aprimorar o processo de busca, que não consegue trazer todas as informações necessárias para o agente. \n",
    "\n",
    "Em seguida, uma necessidade de melhorar o corretor, que pode gerar falsos negativos. Mais testes são necessários para avaliar a corretude do corretor, e explorar outras possibilidades como dar também a pergunta ao corretor; porém, ele se mostra uma boa alternativa à pontuação exata, e possivelmente também ao score F1, por considerar de fato o que se deseja avaliar e ser mais explicável. Existe também a possibilidade de pedir ao corretor gerar raciocícios sobre a correção.\n",
    "\n",
    "A ferramenta de \"pensamento\" não demonstrou boa performance, embora seja necessário um teste de ablação para verificar de fato sua utilidade. O processo de gerar um pensamento sobre o uso da próxima ferramenta já adiciona este aspecto do artigo base, sendo que possivelmente esta ferramenta possa ser retirada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
