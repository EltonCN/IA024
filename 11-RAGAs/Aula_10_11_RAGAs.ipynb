{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #Operações com o SO (arquivos)\n",
    "import json #Leitura/escrita de arquivos JSON\n",
    "import time #Sleep\n",
    "import threading #Multithreading\n",
    "import unicodedata #Normalização de string\n",
    "import collections #Estrutura de contador e fila\n",
    "import string #Operações com strings\n",
    "import re #Expressões regulares\n",
    "import abc #Classes abstratas\n",
    "import warnings #Lançamento de warnings\n",
    "from typing import Optional, Dict, Tuple, Any #Type hints\n",
    "\n",
    "#import torch #spacy não carrega sem importar antes (??)\n",
    "#import spacy #Separador em sentenças\n",
    "import tqdm #Barra de progresso\n",
    "import groq #API para o Llama 3 70B\n",
    "#from pyserini.search import SimpleSearcher #Busca nos documentos\n",
    "import sentence_transformers #Rerankeamento\n",
    "#import bs4 #Remoção de tags HTML\n",
    "import numpy as np #Operações com arrays\n",
    "import matplotlib.pyplot as plt #Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "if not os.path.isfile(\"data\\\\context_articles.json\"):\n",
    "    !curl -LO https://iirc-dataset.s3.us-west-2.amazonaws.com/context_articles.tar.gz\n",
    "    !move context_articles.tar.gz data\n",
    "    !tar -xf data/context_articles.tar.gz\n",
    "    !move context_articles.json data\n",
    "\n",
    "if not os.path.isfile(\"data\\\\iirc_test.json\"):\n",
    "    !curl -LO https://iirc-dataset.s3.us-west-2.amazonaws.com/iirc_test.json\n",
    "    !move iirc_test.json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data\\\\context_articles.json\", \"r\")\n",
    "articles = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data\\\\iirc_test.json\", \"r\")\n",
    "test_data = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_question = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': {'type': 'span',\n",
       "  'answer_spans': [{'text': 'sky and thunder god',\n",
       "    'passage': 'zeus',\n",
       "    'type': 'answer',\n",
       "    'start': 83,\n",
       "    'end': 102}]},\n",
       " 'question': 'What is Zeus know for in Greek mythology?',\n",
       " 'context': [{'text': 'he Palici the sons of Zeus',\n",
       "   'passage': 'main',\n",
       "   'indices': [684, 710]},\n",
       "  {'text': 'in Greek mythology', 'passage': 'main', 'indices': [137, 155]},\n",
       "  {'text': 'Zeus (British English , North American English ; , Zeús ) is the sky and thunder god in ancient Greek religion',\n",
       "   'passage': 'Zeus',\n",
       "   'indices': [0, 110]}],\n",
       " 'question_links': ['Greek mythology', 'Zeus']}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][\"questions\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    item = test_data[i]\n",
    "\n",
    "    main_passage_name = item[\"title\"]\n",
    "\n",
    "    #Get the questions\n",
    "    for q in item[\"questions\"]:\n",
    "        data = {}\n",
    "        \n",
    "        #Get and format the answer\n",
    "        if q[\"answer\"][\"type\"] == \"span\":\n",
    "            data[\"answer\"] = q[\"answer\"][\"answer_spans\"][0][\"text\"]\n",
    "        elif q[\"answer\"][\"type\"] == \"value\":\n",
    "            data[\"answer\"] = q[\"answer\"][\"answer_value\"]+\" \"+q[\"answer\"][\"answer_unit\"]\n",
    "        elif  q[\"answer\"][\"type\"] == \"none\":\n",
    "            continue\n",
    "        elif q[\"answer\"][\"type\"] == \"binary\":\n",
    "            data[\"answer\"] = q[\"answer\"][\"answer_value\"]\n",
    "        else:\n",
    "            raise ValueError\n",
    "        \n",
    "        data[\"question\"] = q[\"question\"]\n",
    "\n",
    "        context = \"\"\n",
    "        for context_item in q[\"context\"]:\n",
    "            passage = context_item[\"passage\"]\n",
    "            if passage == \"main\":\n",
    "                passage = main_passage_name\n",
    "\n",
    "            context += f\"{passage}: {context_item['text']}\"\n",
    "            context += \"\\n\"\n",
    "\n",
    "        data[\"context\"] = context\n",
    "        data[\"context_sentence_count\"] = str(len(q[\"context\"]))\n",
    "\n",
    "        dataset.append(data)\n",
    "\n",
    "        if len(dataset) == n_question:\n",
    "            break\n",
    "    if len(dataset) == n_question:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data, articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroqInterface:\n",
    "    '''\n",
    "    Interface for using the Groq API\n",
    "\n",
    "    Implements a rate limit control for multi-threading use. \n",
    "    '''\n",
    "\n",
    "    _client :groq.Groq = None \n",
    "\n",
    "    LLAMA3_70B = \"llama3-70b-8192\"\n",
    "\n",
    "    inference_lock = threading.Lock()\n",
    "    time_waiter_lock = threading.Lock()\n",
    "    SINGLE_THREAD = True\n",
    "\n",
    "    def __init__(self, model:Optional[str]=None, api_key:Optional[str]=None, json_mode:bool=False, system_message:Optional[str]=None, n_retry:int=5):\n",
    "        '''\n",
    "        GroqInterface constructor.\n",
    "\n",
    "        Args:\n",
    "            model (str, optional): model to use. Llama3 70B is used if None. Default is None\n",
    "            api_key (str, optional): Groq API key to use, if None will check the environment 'GROQ_API_KEY' variable. Default is None.\n",
    "            json_mode (bool): if the model need to output in JSON. Default is False.\n",
    "            system_message (str): the system message to send to the model, if needed. Default is None.\n",
    "            n_retyr (int): number of times to retry if the model fails (not considering RateLimitError). Default is 5.\n",
    "        '''\n",
    "        \n",
    "        if GroqInterface._client is None:\n",
    "\n",
    "            if api_key is None:\n",
    "                api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "            if api_key is None:\n",
    "                raise RuntimeError(\"API key is not in the environment variables ('GROQ_API_KEY' variable is not set).\")\n",
    "\n",
    "            GroqInterface._client = groq.Groq(api_key=api_key)\n",
    "\n",
    "        if model is None:\n",
    "            model = GroqInterface.LLAMA3_70B\n",
    "        self._model = model\n",
    "\n",
    "        self._system_message = system_message\n",
    "\n",
    "\n",
    "        if json_mode:\n",
    "            self._response_format = {\"type\": \"json_object\"}\n",
    "        else:\n",
    "            self._response_format = None\n",
    "        self._json_mode = json_mode\n",
    "\n",
    "        self._n_retry = n_retry\n",
    "\n",
    "    def __call__(self, prompt:str) -> str:\n",
    "        '''\n",
    "        Generates the model response\n",
    "\n",
    "        Args:\n",
    "            prompt (str): prompt to send to the model.\n",
    "\n",
    "        Returns:\n",
    "            str: model response. \n",
    "        '''\n",
    "        done = False\n",
    "        retry_count = 0\n",
    "        while not done:\n",
    "            try:\n",
    "                if not GroqInterface.SINGLE_THREAD:\n",
    "                    GroqInterface.inference_lock.acquire()\n",
    "                    GroqInterface.inference_lock.release()\n",
    "\n",
    "                messages = []\n",
    "                if self._system_message is not None:\n",
    "                    messages.append({\"role\":\"system\", \"content\":self._system_message})\n",
    "                \n",
    "                messages.append({\"role\":\"user\", \"content\":prompt})\n",
    "\n",
    "                chat_completion = GroqInterface._client.chat.completions.create(\n",
    "                        messages=messages,\n",
    "                        model=self._model,\n",
    "                        response_format=self._response_format\n",
    "                    )\n",
    "                \n",
    "                done = True\n",
    "            except groq.RateLimitError as exception: #Wait\n",
    "                print(\"ERROR\")\n",
    "                print(exception)\n",
    "                \n",
    "                GroqInterface.error = exception\n",
    "                if not GroqInterface.SINGLE_THREAD:\n",
    "                    if not GroqInterface.time_waiter_lock.locked():\n",
    "                        GroqInterface.time_waiter_lock.acquire()\n",
    "                        GroqInterface.inference_lock.acquire()\n",
    "                        time.sleep(2)\n",
    "                        GroqInterface.time_waiter_lock.release()\n",
    "                        GroqInterface.inference_lock.release()\n",
    "                else:\n",
    "                    time.sleep(2)\n",
    "\n",
    "            except KeyboardInterrupt as e: #Stop the code\n",
    "                raise e\n",
    "            except Exception as e: #Retry\n",
    "                print(\"ERROR\")\n",
    "                print(e)\n",
    "                retry_count += 1\n",
    "                if retry_count >= self._n_retry:\n",
    "                    raise e\n",
    "\n",
    "        return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(abc.ABC):\n",
    "    '''\n",
    "    Base class for creating LLM agent tools.\n",
    "    '''\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def __call__(self, query:Dict[str, str], context:str) -> Dict[str, str]:\n",
    "        '''\n",
    "        Execute the tool.\n",
    "\n",
    "        Args:\n",
    "            query (str): query for the tool execution.\n",
    "            context (str): agent context in the tool execution moment.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, str]: tool results.\n",
    "        '''\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionGenerator(Tool, GroqInterface):\n",
    "\n",
    "    _system_message = '''You are a question generator that outputs in JSON. \n",
    "The JSON object must use the schema: {'questions':['str', 'str', ...]}\n",
    "\n",
    "Please use a valid JSON format.'''\n",
    "\n",
    "    _base_prompt = '''Generate questions for the given answer:\n",
    "\n",
    "Answer: {answer}\n",
    "'''\n",
    "\n",
    "    def __init__(self, model: Optional[str] = None, api_key: Optional[str] = None):\n",
    "\n",
    "        super().__init__(model, api_key, True, QuestionGenerator._system_message)\n",
    "\n",
    "    def __call__(self, query:Dict[str, str], context:str=None) -> Dict[str, str]:\n",
    "        answer = query[\"answer\"]\n",
    "        \n",
    "        prompt = QuestionGenerator._base_prompt.format(answer=answer)\n",
    "\n",
    "\n",
    "        return json.loads(GroqInterface.__call__(self, prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionComparator(Tool):\n",
    "\n",
    "    def __init__(self, embedder_model:str=\"all-MiniLM-L6-v2\") -> None:\n",
    "        self._embedder = sentence_transformers.SentenceTransformer(embedder_model)\n",
    "\n",
    "    def __call__(self, query: Dict[str, str], context: Optional[str]=None) -> Dict[str, str]:\n",
    "        query_question = query[\"query_question\"]\n",
    "        questions = query[\"questions\"]\n",
    "\n",
    "        q_embedding = self._embedder.encode(query_question, convert_to_tensor=True)\n",
    "        qi_embeddings = self._embedder.encode(questions, convert_to_tensor=True)\n",
    "            \n",
    "        cosine_scores = sentence_transformers.util.cos_sim(q_embedding, qi_embeddings)\n",
    "\n",
    "        score = cosine_scores.sum().item()\n",
    "        score /= len(qi_embeddings)\n",
    "\n",
    "        result = {\"score\":str(score)}\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "class AnswerRelevanceEvaluator(Tool):\n",
    "    def __init__(self, question_generator=None, question_comparator=None) -> None:\n",
    "        if question_generator is None:\n",
    "            question_generator = QuestionGenerator()\n",
    "        if question_comparator is None:\n",
    "            question_comparator = QuestionComparator()\n",
    "\n",
    "        self._question_generator = question_generator\n",
    "        self._question_comparator = question_comparator\n",
    "    \n",
    "    def __call__(self, query: Dict[str, str], context: str=None) -> Dict[str, str]:\n",
    "        \n",
    "        if \"answer\" not in query:\n",
    "            raise ValueError(\"Query must have the answer to evaluate (query not have key 'answer').\")\n",
    "\n",
    "        generator_result = self._question_generator(query)\n",
    "\n",
    "        comparator_query = {\"query_question\":query[\"question\"], \"questions\":generator_result[\"questions\"]}\n",
    "        comparator_result = self._question_comparator(comparator_query)\n",
    "\n",
    "        return comparator_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_relevance_evaluator = AnswerRelevanceEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': '0.19284075498580933'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_relevance_evaluator(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = question_generator(dataset[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': ['Who is Zeus in Greek mythology?',\n",
       "  'What is the god of the sky and thunder in Greek mythology?',\n",
       "  'What Greek god is associated with the sky and thunder?',\n",
       "  'Who is the Greek god of the sky and thunder?']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatementGenerator(Tool, GroqInterface):\n",
    "\n",
    "    _system_message = '''You are a statement generator that outputs in JSON. \n",
    "The JSON object must use the schema: {'statements':['str', 'str', ...]}\n",
    "\n",
    "Please use a valid JSON format.'''\n",
    "\n",
    "    _base_prompt = '''Given a question and answer, create one or more statements from each sentence in the given answer:\n",
    "\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "'''\n",
    "\n",
    "    def __init__(self, model: Optional[str] = None, api_key: Optional[str] = None):\n",
    "\n",
    "        super().__init__(model, api_key, True, StatementGenerator._system_message)\n",
    "\n",
    "    def __call__(self, query:Dict[str, str], context:str=None) -> Dict[str, str]:\n",
    "        question = query[\"question\"]\n",
    "        answer = query[\"answer\"]\n",
    "        \n",
    "        prompt = StatementGenerator._base_prompt.format(question=question, answer=answer)\n",
    "\n",
    "\n",
    "        return json.loads(GroqInterface.__call__(self, prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_generator = StatementGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_result = statement_generator(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statements': ['Zeus is known as the sky god in Greek mythology.',\n",
       "  'Zeus is known as the thunder god in Greek mythology.']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatementContextVerificator(Tool, GroqInterface):\n",
    "\n",
    "    _system_message = '''You are a statement analist that outputs in JSON. \n",
    "The JSON object must use the schema: \n",
    "{'analysis':[{'explanation':'str', 'verdict':'bool'}, {'explanation':'str', 'verdict':'bool'}, ...  ]}.\n",
    "\n",
    "The analysis list must be of same size of the input.\n",
    "\n",
    "Please use a valid JSON format.'''\n",
    "\n",
    "    _base_prompt = '''Context: \n",
    "{context}\n",
    "\n",
    "Consider the given context and following statements, then determine whether they are supported by \n",
    "the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (true/false). \n",
    "Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format.\n",
    "\n",
    "{statements}\n",
    "'''\n",
    "\n",
    "    def __init__(self, model: Optional[str] = None, api_key: Optional[str] = None):\n",
    "\n",
    "        super().__init__(model, api_key, True, StatementContextVerificator._system_message)\n",
    "\n",
    "    def __call__(self, query:Dict[str, str], context:str=None) -> Dict[str, str]:\n",
    "        statements = \"\"\n",
    "        \n",
    "        for statement in query[\"statements\"]:\n",
    "            statements += \"Statement: \"+statement+\"\\n\"\n",
    "        \n",
    "        prompt = StatementContextVerificator._base_prompt.format(statements=statements, context=query[\"rag_context\"])\n",
    "\n",
    "\n",
    "        return json.loads(GroqInterface.__call__(self, prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_context_verificator = StatementContextVerificator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\"statements\": generator_result[\"statements\"], \"rag_context\":dataset[0][\"context\"]}\n",
    "verificator_result = statement_context_verificator(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis': [{'explanation': 'The context states that Zeus is the sky and thunder god in ancient Greek religion, which aligns with the statement that Zeus is known as the sky god in Greek mythology.',\n",
       "   'verdict': True},\n",
       "  {'explanation': 'The context states that Zeus is the sky and thunder god in ancient Greek religion, which aligns with the statement that Zeus is known as the thunder god in Greek mythology.',\n",
       "   'verdict': True}]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verificator_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported = 0\n",
    "total = len(generator_result[\"statements\"])\n",
    "\n",
    "for analisy in verificator_result[\"analysis\"]:\n",
    "    supported += analisy[\"verdict\"]\n",
    "\n",
    "score = supported/total\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaithfulnessEvaluator(Tool):\n",
    "    def __init__(self, statement_generator:StatementGenerator=None, statement_context_verificator:StatementContextVerificator=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if statement_generator is None:\n",
    "            statement_generator = StatementGenerator()\n",
    "        if statement_context_verificator is None:\n",
    "            statement_context_verificator = StatementContextVerificator()\n",
    "\n",
    "        self._statement_generator = statement_generator\n",
    "        self._statement_context_verificator = statement_context_verificator\n",
    "\n",
    "    def __call__(self, query: Dict[str, str], context: str=None) -> Dict[str, str]:   \n",
    "        generator_result = self._statement_generator(query)\n",
    "\n",
    "        verificator_query = {\"statements\": generator_result[\"statements\"], \"rag_context\":query[\"context\"]}\n",
    "        verificator_result = self._statement_context_verificator(verificator_query)\n",
    "\n",
    "        supported = 0\n",
    "        total = len(generator_result[\"statements\"])\n",
    "\n",
    "        for analisy in verificator_result[\"analysis\"]:\n",
    "            supported += analisy[\"verdict\"]\n",
    "\n",
    "        score = supported/total\n",
    "\n",
    "        return {\"score\":str(score)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faithfulness_evaluator = FaithfulnessEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': '1.0'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faithfulness_evaluator(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceExtractor(Tool, GroqInterface):\n",
    "    _system_message = '''You are a sentence extractor that outputs in JSON. \n",
    "The JSON object must use the schema: {'sentences':['str', 'str', ...]}\n",
    "\n",
    "Please use a valid JSON format.'''\n",
    "\n",
    "    _base_prompt = '''Context: \n",
    "{context}\n",
    "\n",
    "Please extract relevant sentences from the provided context that can potentially help answer the following question. \n",
    "If no relevant sentences are found, or if you believe the question cannot be answered from the given context, return a object with an empty 'sentences' list.\n",
    "While extract ing candidate sentences you’re not allowed to make any changes to sentences from given context.\n",
    "\n",
    "Question: {question}\n",
    "'''\n",
    "\n",
    "    def __init__(self, model: Optional[str] = None, api_key: Optional[str] = None):\n",
    "\n",
    "        super().__init__(model, api_key, True, SentenceExtractor._system_message)\n",
    "\n",
    "    def __call__(self, query:Dict[str, str], context:str=None) -> Dict[str, str]:\n",
    "        question = query[\"question\"]\n",
    "        rag_context = query[\"rag_context\"]\n",
    "        \n",
    "        prompt = SentenceExtractor._base_prompt.format(question=question, context=rag_context)\n",
    "\n",
    "        return json.loads(GroqInterface.__call__(self, prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_extractor = SentenceExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_query = {\"question\": dataset[0][\"question\"], \"rag_context\":dataset[0][\"context\"]}\n",
    "extractor_result = sentence_extractor(extractor_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentences': ['Zeus: Zeus (British English , North American English ; , Zeús ) is the sky and thunder god in ancient Greek religion']}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = len(extractor_result[\"sentences\"]) / dataset[0][\"context_sentence_count\"]\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextRelevanceEvaluator(Tool):\n",
    "    def __init__(self, sentence_extractor=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if sentence_extractor is None:\n",
    "            sentence_extractor = SentenceExtractor()\n",
    "\n",
    "        self._sentence_extractor = sentence_extractor\n",
    "\n",
    "    def __call__(self, query: Dict[str, str], context: str=None) -> Dict[str, str]:\n",
    "        extractor_query = {\"question\": query[\"question\"], \"rag_context\": query[\"context\"]}\n",
    "        extractor_result = sentence_extractor(extractor_query)\n",
    "\n",
    "        score = len(extractor_result[\"sentences\"]) / int(query[\"context_sentence_count\"])\n",
    "\n",
    "        result = {\"score\":str(score)}\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_relevance_evaluator = ContextRelevanceEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = context_relevance_evaluator(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': '0.3333333333333333'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "class RAGAsEvaluator(Tool):\n",
    "\n",
    "    def __init__(self, faithfulness_evaluator=None, answer_relevance_evaluator=None, context_relevance_evaluator=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if faithfulness_evaluator is None:\n",
    "            faithfulness_evaluator = FaithfulnessEvaluator()\n",
    "        if answer_relevance_evaluator is None:\n",
    "            answer_relevance_evaluator = AnswerRelevanceEvaluator()\n",
    "        if context_relevance_evaluator is None:\n",
    "            context_relevance_evaluator = ContextRelevanceEvaluator()\n",
    "\n",
    "        self._faithfulness_evaluator = faithfulness_evaluator\n",
    "        self._answer_relevance_evaluator = answer_relevance_evaluator\n",
    "        self._context_relevance_evaluator = context_relevance_evaluator\n",
    "    \n",
    "    def __call__(self, query: Dict[str, str], context: str=None) -> Dict[str, str]:\n",
    "        faithfulness_result = self._faithfulness_evaluator(query)\n",
    "        answer_relevance_result = self._answer_relevance_evaluator(query)\n",
    "        context_relevance_result = self._context_relevance_evaluator(query)\n",
    "\n",
    "        result = { \n",
    "            \"faithfulness\" : faithfulness_result[\"score\"],\n",
    "            \"answer_relevance\" : answer_relevance_result[\"score\"],\n",
    "            \"context_relevance\" : context_relevance_result[\"score\"],\n",
    "        }\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_evaluator = RAGAsEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_result = ragas_evaluator(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': '1.0',\n",
       " 'answer_relevance': '0.6503564516703287',\n",
       " 'context_relevance': '0.3333333333333333'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [04:14<04:55, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "Error code: 400 - {'error': {'message': \"Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': \"{'analysis':[{'explanation':'The statement claims that the Perthshire Regiment had been in operation for 69 years when Christopher Harison joined it as a captain in 1849. From the context, we know that the 73rd Regiment of Foot was raised in 1780, and Harison joined in 1849, which means the regiment had been operating for approximately 69 years, matching the statement.', 'verdict':True}]}\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [06:09<03:10, 12.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "Error code: 400 - {'error': {'message': \"Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\"analysis\":[{\"explanation\":\"The context lists four WHL Championship losses for the Saskatoon Blades, which is the team where Ashton played junior hockey.\",\"verdict\":False}]}'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [06:38<02:55, 13.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "Error code: 400 - {'error': {'message': \"Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\\n\"sentences\": [\"Ron Ashton: Ashton played junior hockey for his hometown Saskatoon Blades of the Western Canadian Hockey League (now WHL), playing his first full season in 1972-73 with future NHL and WHA players Bob Bourne, Dave Lewis and George Pesut,\", \"Bob Bourne: Robert Glen Bourne (born June 21, 1954)\", \"Dave Lewis (ice hockey): David Rodney Lewis (born July 3, 1953\", \"George Pesut: George Matthew Pesut \"(Zuti)\" (born June 17, 1953\"]\\n}'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [09:24<00:00, 11.29s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "file = open(\"evaluations.jsonl\", \"w\")\n",
    "\n",
    "for data in tqdm.tqdm(dataset):\n",
    "    try:\n",
    "        evaluation = ragas_evaluator(data)\n",
    "\n",
    "    except KeyboardInterrupt as e:\n",
    "        file.close()\n",
    "        raise e\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Evaluation error:\", e)\n",
    "\n",
    "        evaluation = { \n",
    "            \"faithfulness\" : \"0\",\n",
    "            \"answer_relevance\" : \"0\",\n",
    "            \"context_relevance\" : \"0\",\n",
    "        }\n",
    "\n",
    "    evaluations.append(evaluation)\n",
    "\n",
    "    file.write(json.dumps(evaluation)+\"\\n\")\n",
    "    file.flush()\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"evaluations.json\", \"w\")\n",
    "json.dump(evaluations, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "faithfulness = np.empty(n_question)\n",
    "answer_relevance = np.empty(n_question)\n",
    "context_relevance = np.empty(n_question)\n",
    "\n",
    "for i in range(n_question):\n",
    "    faithfulness[i] = evaluations[i][\"faithfulness\"]\n",
    "    answer_relevance[i] = evaluations[i][\"answer_relevance\"]\n",
    "    context_relevance[i] = evaluations[i][\"context_relevance\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithfullness  Min: 0.0 | Max: 1.0\n",
      "Answer Relevance  Min: 0.026833323140939076 | Max: 0.7692429224650065\n",
      "Context Relevance  Min: 0.0 | Max: 5.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Faithfullness \", \"Min:\", faithfulness.min(), \"| Max:\", faithfulness.max())\n",
    "print(\"Answer Relevance \", \"Min:\", answer_relevance.min(), \"| Max:\", answer_relevance.max())\n",
    "print(\"Context Relevance \", \"Min:\", context_relevance.min(), \"| Max:\", context_relevance.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 1.        , 1.        , 0.        , 0.66666667,\n",
       "       0.5       , 0.5       , 0.8       , 1.        , 1.        ,\n",
       "       1.        , 0.5       , 0.5       , 0.5       , 0.        ,\n",
       "       0.5       , 1.        , 0.66666667, 0.4       , 1.        ,\n",
       "       0.5       , 1.        , 0.5       , 1.        , 1.        ,\n",
       "       1.        , 0.5       , 0.5       , 1.        , 0.5       ,\n",
       "       0.        , 1.        , 0.        , 0.66666667, 1.        ,\n",
       "       1.        , 0.5       , 0.75      , 0.5       , 0.5       ,\n",
       "       0.5       , 1.        , 1.        , 0.5       , 0.66666667,\n",
       "       0.5       , 1.        , 0.66666667, 0.66666667, 0.66666667])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip(context_relevance, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_relevance = np.clip(context_relevance, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion|Score\n",
      "-|-\n",
      "Faithfullness| 0.73 ± 0.43829214001622246\n",
      "Answer Relevance| 0.24423735859899814 ± 0.14732980886784547\n",
      "Context Relevance| 0.6689999999999999 ± 0.2985522474282256\n"
     ]
    }
   ],
   "source": [
    "print(\"Criterion|Score\")\n",
    "print(\"-|-\")\n",
    "print(\"Faithfullness|\", faithfulness.mean(), \"±\", faithfulness.std())\n",
    "print(\"Answer Relevance|\", answer_relevance.mean(), \"±\", answer_relevance.std())\n",
    "print(\"Context Relevance|\", context_relevance.mean(), \"±\", context_relevance.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criterion|Score\n",
    "-|-\n",
    "Faithfullness| 0.73 ± 0.43829214001622246\n",
    "Answer Relevance| 0.24423735859899814 ± 0.14732980886784547\n",
    "Context Relevance| 0.6689999999999999 ± 0.2985522474282256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0., 36.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(faithfulness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6., 14.,  9.,  9.,  7.,  2.,  1.,  1.,  0.,  1.]),\n",
       " array([0.02683332, 0.10107428, 0.17531524, 0.2495562 , 0.32379716,\n",
       "        0.39803812, 0.47227908, 0.54652004, 0.620761  , 0.69500196,\n",
       "        0.76924292]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD4CAYAAAD4k815AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOAklEQVR4nO3df7BndV3H8edLNjMMheRqBmwXHcSIocFuZTljJeRsYGAj0ywzNFLUTmZKxQyt0aRTf7Rmozkjo7MpQUWgkU0UYRLCMDpAXWD5rQi44SLKRUoLp3Dz3R/3i94uu/v93nPO/X4vn56PmTt7zvd87ve8OPfua8/3/CJVhSSpHc+adQBJ0rAsdklqjMUuSY2x2CWpMRa7JDVm0zRXdvjhh9f8/Pw0VylJz3i33HLLY1U1N+n4qRb7/Pw8i4uL01ylJD3jJfnXtYz3UIwkNcZil6TGWOyS1BiLXZIaY7FLUmMsdklqzNhiT3JRkkeT3LWPZeclqSSHr088SdJaTbLHfjGwZfWLSY4CXgs8NHAmSVIPY4u9qm4AHt/HovcA5wM+0F2SNpBOd54mOR14uKpuTzJu7DZgG8DmzZu7rG7m5rdfNZP17t5x6kzWK+mZbc0nT5McDPw28LuTjK+qnVW1UFULc3MTP+pAktRRl6tiXgocDdyeZDdwJHBrku8eMpgkqZs1H4qpqjuBFz41Pyr3hap6bMBckqSOJrnc8TLgRuDYJHuSnLP+sSRJXY3dY6+qM8csnx8sjSSpN+88laTGWOyS1BiLXZIaY7FLUmMsdklqjMUuSY2x2CWpMRa7JDXGYpekxljsktQYi12SGmOxS1JjLHZJaozFLkmNsdglqTEWuyQ1xmKXpMZY7JLUGItdkhpjsUtSY8YWe5KLkjya5K4Vr70ryaeT3JHkb5Icuq4pJUkTm2SP/WJgy6rXrgGOr6oTgPuAtw2cS5LU0dhir6obgMdXvfbxqto7mr0JOHIdskmSOhjiGPsvAlfvb2GSbUkWkywuLS0NsDpJ0oH0KvYkFwB7gUv3N6aqdlbVQlUtzM3N9VmdJGkCm7p+Y5KzgdcBJ1VVDZZIktRLp2JPsgU4H/jxqvrasJEkSX1McrnjZcCNwLFJ9iQ5B3gfcAhwTZJdST6wzjklSRMau8deVWfu4+UPrUMWSdIAvPNUkhpjsUtSYyx2SWqMxS5JjbHYJakxFrskNcZil6TGWOyS1BiLXZIaY7FLUmMsdklqjMUuSY2x2CWpMRa7JDXGYpekxljsktQYi12SGmOxS1JjLHZJaozFLkmNsdglqTFjiz3JRUkeTXLXite+K8k1ST47+vOw9Y0pSZrUJHvsFwNbVr22Hbi2qo4Brh3NS5I2gLHFXlU3AI+vevl04JLR9CXA64eNJUnqqusx9hdV1SOj6S8CL9rfwCTbkiwmWVxaWuq4OknSpHqfPK2qAuoAy3dW1UJVLczNzfVdnSRpjK7F/qUkLwYY/fnocJEkSX10LfYrgTeOpt8I/O0wcSRJfU1yueNlwI3AsUn2JDkH2AH8VJLPAieP5iVJG8CmcQOq6sz9LDpp4CySpAF456kkNcZil6TGWOyS1BiLXZIaY7FLUmMsdklqjMUuSY2x2CWpMRa7JDVm7J2nmp357VfNOsLU7d5x6qwjSM947rFLUmMsdklqjMUuSY2x2CWpMRa7JDXGYpekxljsktQYi12SGmOxS1JjLHZJakyvYk/yG0nuTnJXksuSPGeoYJKkbjoXe5IjgLcCC1V1PHAQsHWoYJKkbvoeitkEfEeSTcDBwBf6R5Ik9dG52KvqYeCPgIeAR4CvVNXHV49Lsi3JYpLFpaWl7kklSRPpcyjmMOB04Gjge4DnJjlr9biq2llVC1W1MDc31z2pJGkifQ7FnAx8rqqWqurrwEeBHxsmliSpqz7F/hDwyiQHJwlwEnDvMLEkSV31OcZ+M3AFcCtw5+i9dg6US5LUUa//NV5VvR14+0BZJEkD8M5TSWqMxS5JjbHYJakxFrskNcZil6TGWOyS1BiLXZIaY7FLUmMsdklqTK87T6WhzW+/aibr3b3j1JmsV1oP7rFLUmMsdklqjMUuSY2x2CWpMRa7JDXGYpekxljsktQYi12SGmOxS1JjLHZJaozFLkmN6VXsSQ5NckWSTye5N8mPDhVMktRN34eAvRf4WFWdkeTZwMEDZJIk9dC52JM8H3g1cDZAVT0JPDlMLElSV3322I8GloA/TfIDwC3AuVX1xMpBSbYB2wA2b97ceWWzepyrJD3T9DnGvgl4BfD+qjoReALYvnpQVe2sqoWqWpibm+uxOknSJPoU+x5gT1XdPJq/guWilyTNUOdir6ovAp9PcuzopZOAewZJJUnqrO9VMW8BLh1dEfMg8Av9I0mS+uhV7FW1C1gYJookaQjeeSpJjbHYJakxFrskNcZil6TGWOyS1BiLXZIaY7FLUmMsdklqjMUuSY2x2CWpMRa7JDXGYpekxljsktQYi12SGmOxS1JjLHZJaozFLkmNsdglqTEWuyQ1xmKXpMb0LvYkByW5LcnfDxFIktTPEHvs5wL3DvA+kqQB9Cr2JEcCpwIfHCaOJKmvvnvsfwycD3yjfxRJ0hA6F3uS1wGPVtUtY8ZtS7KYZHFpaanr6iRJE+qzx/4q4LQku4HLgdck+YvVg6pqZ1UtVNXC3Nxcj9VJkibRudir6m1VdWRVzQNbgU9U1VmDJZMkdeJ17JLUmE1DvElVXQ9cP8R7SZL6cY9dkhpjsUtSYyx2SWqMxS5JjbHYJakxFrskNcZil6TGWOyS1BiLXZIaY7FLUmMsdklqjMUuSY2x2CWpMRa7JDXGYpekxljsktQYi12SGmOxS1JjLHZJaozFLkmNsdglqTGdiz3JUUmuS3JPkruTnDtkMElSN5t6fO9e4LyqujXJIcAtSa6pqnsGyiZJ6qDzHntVPVJVt46m/wO4FzhiqGCSpG767LF/U5J54ETg5n0s2wZsA9i8efMQq5MGN7/9qpmte/eOU2e2brWp98nTJN8J/DXw61X11dXLq2pnVS1U1cLc3Fzf1UmSxuhV7Em+jeVSv7SqPjpMJElSH32uignwIeDeqnr3cJEkSX302WN/FfDzwGuS7Bp9nTJQLklSR51PnlbVJ4EMmEWSNADvPJWkxljsktQYi12SGmOxS1JjLHZJaozFLkmNsdglqTEWuyQ1xmKXpMYM8theSd3N8pHBszKrRxX/f3k8s3vsktQYi12SGmOxS1JjLHZJaozFLkmNsdglqTEWuyQ1xmKXpMZY7JLUGItdkhpjsUtSY3oVe5ItST6T5P4k24cKJUnqrnOxJzkIuBD4aeA44Mwkxw0VTJLUTZ899h8G7q+qB6vqSeBy4PRhYkmSuurz2N4jgM+vmN8D/MjqQUm2AdtGs/+Z5DMrFh8OPNYjwzSYcRhmHEYTGfPOKSXZv6lvxw7/zSszfu9avnHdn8deVTuBnftalmSxqhbWO0MfZhyGGYdhxmG0nrHPoZiHgaNWzB85ek2SNEN9iv1fgGOSHJ3k2cBW4MphYkmSuup8KKaq9ib5NeAfgYOAi6rq7jW+zT4P0WwwZhyGGYdhxmE0nTFVNWQQSdKMeeepJDXGYpekxkyl2Mc9eiDJtyf58Gj5zUnmp5FrjRlfneTWJHuTnDHtfBNm/M0k9yS5I8m1SdZ07euUMv5KkjuT7EryyVncrTzpozCSvCFJJZn6ZXETbMezkyyNtuOuJL+00TKOxvzc6Hfy7iR/udEyJnnPim14X5J/34AZNye5Lslto7/bp4x906pa1y+WT6w+ALwEeDZwO3DcqjG/CnxgNL0V+PB65+qQcR44Afgz4Ixp5ltDxp8EDh5Nv2mDbsfnrZg+DfjYRss4GncIcANwE7Cw0TICZwPvm/bv4RozHgPcBhw2mn/hRsu4avxbWL4IZENlZPkk6ptG08cBu8e97zT22Cd59MDpwCWj6SuAk5JkCtkmzlhVu6vqDuAbU8y10iQZr6uqr41mb2L53oKNlvGrK2afC0z77P2kj8L4feCdwH9NM9zIM+FxHZNk/GXgwqr6N4CqenQDZlzpTOCyqST7lkkyFvC80fTzgS+Me9NpFPu+Hj1wxP7GVNVe4CvAC6aQ7WnrH9lXxllba8ZzgKvXNdHTTZQxyZuTPAD8IfDWKWV7ytiMSV4BHFVVV00z2AqT/qzfMPpofkWSo/axfD1NkvFlwMuSfCrJTUm2TC3dson/zowOWx4NfGIKuVaaJOM7gLOS7AH+geVPFgfkydMGJTkLWADeNess+1JVF1bVS4HfAn5n1nlWSvIs4N3AebPOMsbfAfNVdQJwDd/6xLuRbGL5cMxPsLw3/CdJDp1loAPYClxRVf8z6yD7cCZwcVUdCZwC/Pno93S/plHskzx64Jtjkmxi+ePGl6eQ7WnrH9mIj0eYKGOSk4ELgNOq6r+nlO0pa92OlwOvX89A+zAu4yHA8cD1SXYDrwSunPIJ1LHbsaq+vOLn+0HgB6eU7SmT/Kz3AFdW1der6nPAfSwX/bSs5fdxK9M/DAOTZTwH+AhAVd0IPIflB4Tt3xRODmwCHmT5Y85TJwe+f9WYN/N/T55+ZMonMMZmXDH2YmZz8nSS7Xgiyydijpl2vjVkPGbF9M8Aixst46rx1zP9k6eTbMcXr5j+WeCmDZhxC3DJaPpwlg85vGAjZRyNezmwm9ENmxtwO14NnD2a/j6Wj7EfMOu0wp/C8r/WDwAXjF77PZb3KmH5X6C/Au4H/hl4yQw28LiMP8TyHsgTLH+auHsDZvwn4EvArtHXlRsw43uBu0f5rjtQqc4q46qxUy/2CbfjH4y24+2j7fjyDZgxLB/Wuge4E9i60TKO5t8B7Jh2tjVsx+OAT41+1ruA1457Tx8pIEmN8eSpJDXGYpekxljsktQYi12SGmOxS1JjLHZJaozFLkmN+V+f9q5OEgJcMAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(answer_relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 1.        , 1.        , 0.        , 0.66666667,\n",
       "       0.5       , 0.5       , 0.8       , 1.        , 1.        ,\n",
       "       1.        , 0.5       , 0.5       , 0.5       , 0.        ,\n",
       "       0.5       , 1.        , 0.66666667, 0.4       , 1.        ,\n",
       "       0.5       , 1.        , 0.5       , 1.        , 1.        ,\n",
       "       1.        , 0.5       , 0.5       , 1.        , 0.5       ,\n",
       "       0.        , 1.        , 0.        , 0.66666667, 1.        ,\n",
       "       1.        , 0.5       , 0.75      , 0.5       , 0.5       ,\n",
       "       0.5       , 1.        , 1.        , 0.5       , 0.66666667,\n",
       "       0.5       , 1.        , 0.66666667, 0.66666667, 0.66666667])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  0.,  0.,  1.,  1., 17.,  7.,  1.,  1., 18.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(context_relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
