{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #Operações com o SO (arquivos)\n",
    "import json #Leitura/escrita de arquivos JSON\n",
    "import time #Sleep\n",
    "import threading #Multithreading\n",
    "import abc #Classes abstratas\n",
    "from typing import Optional, Dict, List, Tuple, Any #Type hints\n",
    "\n",
    "import tqdm #Barra de progresso\n",
    "import groq #API para o Llama 3 70B\n",
    "import numpy as np #Operações com arrays\n",
    "import matplotlib.pyplot as plt #Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroqInterface:\n",
    "    '''\n",
    "    Interface for using the Groq API\n",
    "\n",
    "    Implements a rate limit control for multi-threading use. \n",
    "    '''\n",
    "\n",
    "    _client :groq.Groq = None \n",
    "\n",
    "    LLAMA3_70B = \"llama3-70b-8192\"\n",
    "\n",
    "    inference_lock = threading.Lock()\n",
    "    time_waiter_lock = threading.Lock()\n",
    "    SINGLE_THREAD = True\n",
    "\n",
    "    def __init__(self, model:Optional[str]=None, api_key:Optional[str]=None, json_mode:bool=False, system_message:Optional[str]=None, n_retry:int=5):\n",
    "        '''\n",
    "        GroqInterface constructor.\n",
    "\n",
    "        Args:\n",
    "            model (str, optional): model to use. Llama3 70B is used if None. Default is None\n",
    "            api_key (str, optional): Groq API key to use, if None will check the environment 'GROQ_API_KEY' variable. Default is None.\n",
    "            json_mode (bool): if the model need to output in JSON. Default is False.\n",
    "            system_message (str): the system message to send to the model, if needed. Default is None.\n",
    "            n_retyr (int): number of times to retry if the model fails (not considering RateLimitError). Default is 5.\n",
    "        '''\n",
    "        \n",
    "        if GroqInterface._client is None:\n",
    "\n",
    "            if api_key is None:\n",
    "                api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "            if api_key is None:\n",
    "                raise RuntimeError(\"API key is not in the environment variables ('GROQ_API_KEY' variable is not set).\")\n",
    "\n",
    "            GroqInterface._client = groq.Groq(api_key=api_key)\n",
    "\n",
    "        if model is None:\n",
    "            model = GroqInterface.LLAMA3_70B\n",
    "        self._model = model\n",
    "\n",
    "        self._system_message = system_message\n",
    "\n",
    "\n",
    "        if json_mode:\n",
    "            self._response_format = {\"type\": \"json_object\"}\n",
    "        else:\n",
    "            self._response_format = None\n",
    "        self._json_mode = json_mode\n",
    "\n",
    "        self._n_retry = n_retry\n",
    "\n",
    "    def __call__(self, prompt:str) -> str:\n",
    "        '''\n",
    "        Generates the model response\n",
    "\n",
    "        Args:\n",
    "            prompt (str): prompt to send to the model.\n",
    "\n",
    "        Returns:\n",
    "            str: model response. \n",
    "        '''\n",
    "        done = False\n",
    "        retry_count = 0\n",
    "        while not done:\n",
    "            try:\n",
    "                if not GroqInterface.SINGLE_THREAD:\n",
    "                    GroqInterface.inference_lock.acquire()\n",
    "                    GroqInterface.inference_lock.release()\n",
    "\n",
    "                messages = []\n",
    "                if self._system_message is not None:\n",
    "                    messages.append({\"role\":\"system\", \"content\":self._system_message})\n",
    "                \n",
    "                messages.append({\"role\":\"user\", \"content\":prompt})\n",
    "\n",
    "                chat_completion = GroqInterface._client.chat.completions.create(\n",
    "                        messages=messages,\n",
    "                        model=self._model,\n",
    "                        response_format=self._response_format\n",
    "                    )\n",
    "                \n",
    "                done = True\n",
    "            except groq.RateLimitError as exception: #Wait\n",
    "                print(\"ERROR\")\n",
    "                print(exception)\n",
    "                \n",
    "                GroqInterface.error = exception\n",
    "                if not GroqInterface.SINGLE_THREAD:\n",
    "                    if not GroqInterface.time_waiter_lock.locked():\n",
    "                        GroqInterface.time_waiter_lock.acquire()\n",
    "                        GroqInterface.inference_lock.acquire()\n",
    "                        time.sleep(2)\n",
    "                        GroqInterface.time_waiter_lock.release()\n",
    "                        GroqInterface.inference_lock.release()\n",
    "                else:\n",
    "                    time.sleep(2)\n",
    "\n",
    "            except KeyboardInterrupt as e: #Stop the code\n",
    "                raise e\n",
    "            except Exception as e: #Retry\n",
    "                print(\"ERROR\")\n",
    "                print(e)\n",
    "                retry_count += 1\n",
    "                if retry_count >= self._n_retry:\n",
    "                    raise e\n",
    "\n",
    "        return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(abc.ABC):\n",
    "    '''\n",
    "    Base class for creating LLM agent tools.\n",
    "    '''\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def __call__(self, query:Dict[str, str], context:str) -> Dict[str, str]:\n",
    "        '''\n",
    "        Execute the tool.\n",
    "\n",
    "        Args:\n",
    "            query (str): query for the tool execution.\n",
    "            context (str): agent context in the tool execution moment.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, str]: tool results.\n",
    "        '''\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTool(Tool, GroqInterface):\n",
    "\n",
    "\n",
    "    _system_message = '''You are a semantic temperature sensor carried by a subject, that outputs in JSON. \n",
    "The JSON object must use the schema: {'temperatures':[{'time':'str', 'temperature':'str'}, {'time':'str', 'temperature':'str'}]}, where temperature must be in celsius.\n",
    "\n",
    "Please use a valid JSON format.'''\n",
    "\n",
    "    _base_prompt = '''Generate a estimated temperature for each time, considering the perceptual information from our subject:\n",
    "\n",
    "Subject: {subject}\n",
    "\n",
    "Moments: \n",
    "{moments}\n",
    "'''\n",
    "\n",
    "    def __init__(self, model: Optional[str] = None, api_key: Optional[str] = None):\n",
    "      \n",
    "        super().__init__(model, api_key, True, self._system_message)\n",
    "\n",
    "    def __call__(self, query:Dict[str, str], context:str=None) -> Dict[str, List[str]]:\n",
    "\n",
    "        prompt = self._base_prompt.format(**query)\n",
    "\n",
    "\n",
    "        return json.loads(GroqInterface.__call__(self, prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tool = TestTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_interface = GroqInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_description = groq_interface(\"Generate a random description for a person, including its gender, age and body composition\")\n",
    "\n",
    "subject_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a random description for a person:\n",
    "\n",
    "**Name:** Ava Moreno\n",
    "\n",
    "**Gender:** Female\n",
    "\n",
    "**Age:** 29 years old\n",
    "\n",
    "**Height:** 5'7\" (170 cm)\n",
    "\n",
    "**Weight:** 125 lbs (56.7 kg)\n",
    "\n",
    "**Body Composition:**\n",
    "\n",
    "* **Body Type:** Mesomorph (athletic, toned build)\n",
    "* **Body Fat Percentage:** 22%\n",
    "* **Muscle Mass:** 38%\n",
    "* **Bone Density:** Average\n",
    "\n",
    "**Physical Characteristics:**\n",
    "\n",
    "* Hair: Dark brown, shoulder-length, wavy\n",
    "* Eyes: Bright green\n",
    "* Skin Tone: Light olive complexion\n",
    "* Facial Structure: Heart-shaped face, prominent cheekbones, small nose\n",
    "* Build: Toned and athletic, with a small waist and curved hips\n",
    "* Posture: Good, with a slight forward lean\n",
    "\n",
    "**Style:**\n",
    "\n",
    "* Fashion sense: Trendy, eclectic, and expressive\n",
    "* Clothing preferences: Dresses, skirts, and jeans with bold patterns and bright colors\n",
    "* Accessories: Statement jewelry, chunky boots, and colorful scarves\n",
    "\n",
    "Feel free to modify or discard any aspect of this description to suit your needs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"A female person, with 29 years old, 56.7 Kg, mesomorph (athletic, toned build) body type, 22% fat percentage, 38% muscle mass, average bone density\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\"subject\":subject,\n",
    "         \"moments\":[\n",
    "            {\"time\":\"0 min\", \"description\":\"the subject is outside, it is using a thick blouse\"},\n",
    "            {\"time\":\"1 min\", \"description\":\"the subject enters a house, it is using a thick blouse\"},\n",
    "            {\"time\":\"2 min\", \"description\":\"the subject turns on a heater at 22 ºC\"},\n",
    "            {\"time\":\"5 min\", \"description\":\"no action\"},\n",
    "            {\"time\":\"10 min\", \"description\":\"the subject removes it's blouse\"}\n",
    "         ]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_tool(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'temperatures': [{'time': '0 min', 'temperature': '15.5°C'},\n",
    "  {'time': '1 min', 'temperature': '18.2°C'},\n",
    "  {'time': '2 min', 'temperature': '20.1°C'},\n",
    "  {'time': '5 min', 'temperature': '21.5°C'},\n",
    "  {'time': '10 min', 'temperature': '23.8°C'}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTool2(Tool, GroqInterface):\n",
    "\n",
    "\n",
    "    _system_message = '''You are a smarthphone light sensor, carried by a subject, that outputs in JSON. \n",
    "The JSON object must use the schema: {'light intensities':[{'time':'str', 'reasoning':'str', 'ligth':'str'}, {'time':'str', 'reasoning':'str', 'ligth':'str'}]}, \n",
    "where light must be in lux, and reasoning is a explanation about why this value this moment.\n",
    "\n",
    "Please use a valid JSON format.'''\n",
    "\n",
    "    _base_prompt = '''Generate a estimated light intensity for each time, considering the perceptual information from our subject:\n",
    "\n",
    "Subject: {subject}\n",
    "\n",
    "Moments: \n",
    "{moments}\n",
    "'''\n",
    "\n",
    "    def __init__(self, model: Optional[str] = None, api_key: Optional[str] = None):\n",
    "      \n",
    "        super().__init__(model, api_key, True, self._system_message)\n",
    "\n",
    "    def __call__(self, query:Dict[str, str], context:str=None) -> Dict[str, List[str]]:\n",
    "\n",
    "        prompt = self._base_prompt.format(**query)\n",
    "\n",
    "\n",
    "        return json.loads(GroqInterface.__call__(self, prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tool2 = TestTool2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = test_tool2(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'light intensities': [{'time': '0 min',\n",
    "   'reasoning': 'subject is outside on a normal day',\n",
    "   'light': '10000 lux'},\n",
    "  {'time': '1 min',\n",
    "   'reasoning': 'subject enters a house, but still has daylight through windows',\n",
    "   'light': '500 lux'},\n",
    "  {'time': '2 min',\n",
    "   'reasoning': 'subject turns on a heater, but no significant change in light',\n",
    "   'light': '500 lux'},\n",
    "  {'time': '5 min',\n",
    "   'reasoning': 'no action, light remains the same',\n",
    "   'light': '500 lux'},\n",
    "  {'time': '10 min',\n",
    "   'reasoning': 'subject removes blouse, but light does not change',\n",
    "   'light': '500 lux'}]}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
