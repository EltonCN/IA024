{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FullLoRA\n",
    "\n",
    "Elton Cardoso do Nascimento, 233840."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(OBS: as primeiras seções contem códigos retirados dos exercícios anteriores. As novas implementações começam a partir da seção \"Implementação do LoRA\").\n",
    "\n",
    "Iremos começar importando os módulos que serão utilizados na atividade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string # Manipular strings\n",
    "from collections import Counter # Fazer contagem de elementos\n",
    "import random # Operações randômicas\n",
    "import os # Manipular arquivos\n",
    "import time # Medição de tempo\n",
    "import abc # Classes abstratas\n",
    "import itertools # Iterators\n",
    "from typing import List, Dict, Union, Tuple, Optional # Type hints\n",
    "\n",
    "import numpy as np # Operações vetoriais\n",
    "from numpy.testing import assert_raises, assert_array_equal, assert_array_almost_equal # Testes\n",
    "from numpy.typing import ArrayLike # Type hints\n",
    "import tqdm # Print do progresso\n",
    "import torch # ML\n",
    "from torch.utils.data import Dataset, DataLoader # Preparação de dados\n",
    "import matplotlib.pyplot as plt # Plots\n",
    "import wandb # Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E algumas funções auxiliares que serão utilizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_array_not_equal(array1:ArrayLike, array2:ArrayLike) -> None:\n",
    "    \"\"\"\n",
    "    Raises an AssertionError if two array_like objects are equal.\n",
    "\n",
    "    Args:\n",
    "        array1 (ArrayLike): First array to check.\n",
    "        array2 (ArrayLike): Second array to check.\n",
    "    \"\"\"\n",
    "    assert_raises(AssertionError, assert_array_equal, array1, array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seeds(seed:int=18) -> None:\n",
    "    \"\"\"\n",
    "    Resets the random generators from random and torch to a fixed seed.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos dados.\n",
    "\n",
    "Nesta seção serão definidas funções para preparar os dados para treino do modelo. Devido a necessidade de alterar os parâmetros constantemente durante os experimentos de treino, são definidas em funções as operações que são necessárias. Exemplos são executados para mostrar o funcionamento correto das operações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faz download e carrega o dataset\n",
    "\n",
    "Nesta seção os dados serão transferidos, lidos e limpos.\n",
    "\n",
    "O primeiro passo é realizar o download dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"data\\\\67724.txt.utf-8\"):\n",
    "    !curl -LO https://www.gutenberg.org/ebooks/67724.txt.utf-8\n",
    "    !move 67724.txt.utf-8 data\n",
    "\n",
    "if not os.path.isfile(\"data\\\\67725.txt.utf-8\"):\n",
    "    !curl -LO https://www.gutenberg.org/ebooks/67725.txt.utf-8\n",
    "    !move 67725.txt.utf-8 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguido pela leitura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4971"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(\"data\\\\67724.txt.utf-8\",\"r\", encoding=\"utf8\").read()\n",
    "text += open(\"data\\\\67725.txt.utf-8\",\"r\", encoding=\"utf8\").read()\n",
    "\n",
    "paragraphs = text.split(\"\\n\\n\")\n",
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E limpeza dos dados.\n",
    "\n",
    "São realizadas as seguintes operações seguindo o paper \"A Neural Probabilistic Language Model\" (Bengio, 2003).\n",
    "\n",
    "\n",
    "- Pontuação: é mantida, porém separada do texto para permitir criação de símbolos próprios no vocabulário, e evitar a criação de várias símbolos representando as palavras com pontuação (\"pontuação\" -> \"pontuação\" + \",\" )\n",
    "- Número: convertidos para símbolo especial. No caso todos os números são convertidos para \"999\", para que convirjam para o mesmo símbolo no vocabulário\n",
    "- Letras maiúsculas: convertidas para minúsculas.\n",
    "- Nomes próprios: não são alterados devido a necessidade de serem identificados, diferente do paper.\n",
    "- Palavras raras: são removidas ao criar o vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text:str) -> str:\n",
    "    '''\n",
    "    Clean the text, changing upper case and setting numbers to 999.\n",
    "    '''\n",
    "    \n",
    "    text = text.lower() # Upper Case -> lower case\n",
    "    \n",
    "    old_text = text.split()\n",
    "    new_text = []\n",
    "\n",
    "    for j in range(len(old_text)):\n",
    "        word = old_text[j] \n",
    "\n",
    "        if word.isdigit(): #Number -> 999\n",
    "            word = \"999\"\n",
    "        elif len(word) > 1 and word[0] in string.punctuation: # Ponctuation -> separate\n",
    "            old_text.insert(j+1, word[1:])\n",
    "            word = word[0]\n",
    "        elif word[-1] in string.punctuation and len(word) > 1: # Ponctuation -> separate\n",
    "            old_text.insert(j+1, word[:-1])\n",
    "            old_text.insert(j+2, word[-1])\n",
    "            \n",
    "            word = \"\"\n",
    "        \n",
    "        if len(word) > 0: # No empty words\n",
    "            new_text.append(word)\n",
    "    \n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_paragraphs = [paragraph.replace(\"\\n\", \" \") for paragraph in paragraphs if paragraph.strip()] # Removes \\n\n",
    "\n",
    "for i in range(len(cleaned_paragraphs)):\n",
    "    cleaned_paragraphs[i] = clean_text(cleaned_paragraphs[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver um exemplo de parágrafo limpo do dataset, junto com a quantidade total de parágrafos obtidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE ----------------\n",
      "﻿the project gutenberg ebook of o guarany : romance brazileiro , vol . 999 ( of 999 ) this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with almost no restrictions whatsoever . you may copy it , give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org . if you are not located in the united states , you\n",
      "---------------------\n",
      "4892\n"
     ]
    }
   ],
   "source": [
    "print(\"SAMPLE ----------------\")\n",
    "print(cleaned_paragraphs[0])\n",
    "print(\"---------------------\")\n",
    "\n",
    "print(len(cleaned_paragraphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11470"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_words(texts:List[str]) -> Counter:\n",
    "    \"\"\"\n",
    "    Counts the words in the texts.\n",
    "\n",
    "    Args:\n",
    "        texts (List[str]): List of strings with the texts.\n",
    "\n",
    "    Returns:\n",
    "        Counter: counter with the word count across all texts.\n",
    "    \"\"\"\n",
    "    \n",
    "    word_counts = Counter()\n",
    "    for text in texts:\n",
    "        word_counts.update(text.split(\" \"))\n",
    "    return word_counts\n",
    "\n",
    "word_counts = count_words(cleaned_paragraphs)\n",
    "\n",
    "len(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um vocabulário\n",
    "\n",
    "Com a contagem de palavras podemos definir uma função para criar um novo vocabulário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(word_counts:Counter, vocab_size:int) -> Tuple[Dict[str, int], List[str]]:\n",
    "    \"\"\"\n",
    "    Generates the vocabulary with the most frequent words.\n",
    "\n",
    "    Args:\n",
    "        word_counts (Counter): word count to generate vocabulary.\n",
    "        vocab_size (int): maximum size for the vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, int]: vocabulary mapping words to codes.\n",
    "        List[str]: inverse vocabulary mapping codes to words.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    most_frequent_words = [word for word, count in word_counts.most_common(vocab_size)]\n",
    "    vocab = {word: i for i, word in enumerate(most_frequent_words, 1)}\n",
    "\n",
    "    inverse_vocab = list(vocab.keys())\n",
    "\n",
    "    return vocab, inverse_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E podemos executar um teste mostrando a geração de um vocabulário e suas primeiras 0 entradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vocab_size = 1000\n",
    "test_vocab, test_inverse_vocab = create_vocab(word_counts, test_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 1),\n",
       " ('a', 2),\n",
       " ('que', 3),\n",
       " ('-', 4),\n",
       " ('o', 5),\n",
       " ('de', 6),\n",
       " ('e', 7),\n",
       " (';', 8),\n",
       " ('.', 9),\n",
       " ('um', 10)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.islice(test_vocab.items(), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É interessante observar que as palavras mais frequentes são acentuações, o que pode dificultar o aprendizado de sentenças significativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificando e Decodificando sentenças\n",
    "\n",
    "Podemos utilizar as seguintes funções para codificar um texto e decodificá-lo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sentence:Union[str,List[str]], vocab:Dict) -> List[int]:\n",
    "    \"\"\"\n",
    "    Encodes a sentence using a vocabulary.\n",
    "\n",
    "    Args:\n",
    "        sentence (Union[str,List[str]]): sentence to encode. Or a string,\n",
    "            or the string already separated into words\n",
    "        vocab (Dict): vocabulary to encode. Maps words to codes.\n",
    "\n",
    "    Returns:\n",
    "        List[int]: the encoded sentence\n",
    "    \"\"\"\n",
    "    if isinstance(sentence, list):\n",
    "        words = sentence\n",
    "    else:\n",
    "        words = sentence.split(\" \")\n",
    "    \n",
    "    return [vocab.get(word, 0) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentence(encoding:List[int], inverse_vocab:List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Decodes a sentence back to words.\n",
    "\n",
    "    Args:\n",
    "        encoding (List[int]): encoded sentence to decode.\n",
    "        inverse_vocab (List[str]): inverse vocabulary. Maps codes to words\n",
    "\n",
    "    Returns:\n",
    "        List[str]: decoded sentence. Unknown codes are decoded to '???' \n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for encoding_i in encoding:\n",
    "        if encoding_i == 0:\n",
    "            result.append(\"???\")\n",
    "        else:\n",
    "            result.append(inverse_vocab[encoding_i-1])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação e Classe do dataset\n",
    "\n",
    "Aqui iremos definir as sentenças a partir dos textos; divídi-las em treino, teste e valiadação; e criar a classe para carregar os dados durante os experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(texts:List[str], context_size:int, \n",
    "                     vocab:Dict) -> Tuple[List[List[int]], List[int]]:\n",
    "    \"\"\"\n",
    "    Creates sequences from the texts, with the target (word to predict), \n",
    "    using a fixed size and vocabulary.\n",
    "\n",
    "    Args:\n",
    "        texts (List[str]): texts to create sequences.\n",
    "        context_size (int): size of the sequences.\n",
    "        vocab (Dict): maps words to codes.\n",
    "\n",
    "    Returns:\n",
    "        List[List[int]]: created sequences. \n",
    "        List[int]]: created targets.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    x_all = []\n",
    "    y_all = []\n",
    "\n",
    "    for paragraph in texts:\n",
    "        start = 0\n",
    "        end = context_size\n",
    "\n",
    "        paragraph = encode_sentence(paragraph, vocab)\n",
    "\n",
    "        while end < len(paragraph):\n",
    "            x = paragraph[start:end]\n",
    "            y = paragraph[end]\n",
    "\n",
    "            if not ( 0 in x or 0 == y):\n",
    "                x_all.append(x)\n",
    "                y_all.append(y)\n",
    "\n",
    "            start += 1\n",
    "            end += 1\n",
    "            \n",
    "    x_all = np.array(x_all)\n",
    "    y_all = np.array(y_all)\n",
    "\n",
    "    return x_all, y_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um dataset de teste e validamos que as entradas e targets possuem o mesmo tamanho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_context_size = 10\n",
    "\n",
    "test_x_all, test_y_all = create_sequences(cleaned_paragraphs, test_context_size, test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_x_all) == len(test_y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar viéses, definimos uma função para embaralhar o dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataset(x:List, y:List) -> Tuple[List, List]:\n",
    "    \"\"\"\n",
    "    Shuffle the dataset.\n",
    "\n",
    "    Args:\n",
    "        x (List): dataset inputs.\n",
    "        y (List): dataset targets.\n",
    "\n",
    "    Returns:\n",
    "        List: shuffled inputs. \n",
    "        List: shuffled outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    indexes = list(range(len(x)))\n",
    "    random.shuffle(indexes)\n",
    "\n",
    "    x = x[indexes]\n",
    "    y = y[indexes]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E separamos os dados em treino (60%), validação (20%) e teste (20%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_dataset(x_all:List, y_all:List) -> Tuple[Tuple[List, List], Tuple[List, List], Tuple[List, List]]:\n",
    "    \"\"\"\n",
    "    Separate the data in train, validation and test.\n",
    "\n",
    "    Args:\n",
    "        x_all (List): all dataset inputs.\n",
    "        y_all (List): all dataset targets.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List, List]: train inputs and targets. \n",
    "        Tuple[List, List]: validation inputs and targets.\n",
    "        Tuple[List, List]: test inputs and targets.\n",
    "    \"\"\"\n",
    "    size_all = len(x_all)\n",
    "\n",
    "    cut1 = int(0.6*size_all)\n",
    "    cut2 = int(0.8*size_all)\n",
    "\n",
    "    x_train = x_all[0:cut1]\n",
    "    y_train = y_all[0:cut1]\n",
    "\n",
    "    x_val = x_all[cut1:cut2]\n",
    "    y_val = y_all[cut1:cut2]\n",
    "\n",
    "    x_test = x_all[cut2:]\n",
    "    y_test = y_all[cut2:]\n",
    "\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos os conjuntos e demonstramos que a separação separa corretamente os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_x_train, test_y_train), (test_x_val, test_y_val), (test_x_test, test_y_test) = separate_dataset(test_x_all, test_y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_x_train)+len(test_x_val)+len(test_x_test) == len(test_x_all)\n",
    "\n",
    "assert len(test_x_train) == int(0.6*len(test_x_all))\n",
    "assert len(test_x_val) == np.floor(0.2*len(test_x_all))\n",
    "assert len(test_x_test) == np.ceil(0.2*len(test_x_all))\n",
    "\n",
    "assert len(test_x_train) == len(test_y_train)\n",
    "assert len(test_x_val) == len(test_y_val)\n",
    "assert len(test_x_test) == len(test_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos a classe para manipular o dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPredictDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Text prediction dataset.\n",
    "\n",
    "    Input: sequence of encoded words.\n",
    "    Target: next word for the sequence.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x_data:List[List[int]], y_data:List[int]) -> None:\n",
    "        \"\"\"\n",
    "        Creates a new dataset.\n",
    "\n",
    "        Args:\n",
    "            x_data (List[List[int]]): dataset inputs.\n",
    "            y_data (List[int]): dataset targets.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if input and target have different sizes.\n",
    "        \"\"\"\n",
    "\n",
    "        self._x_data = torch.tensor(x_data)-1\n",
    "        self._y_data = torch.tensor(y_data, dtype=torch.int64)-1\n",
    "        \n",
    "        if len(x_data) != len(y_data):\n",
    "            raise ValueError(f\"x_data and y_data must have same size. ({len(x_data)} ≠ {len(y_data)})\")\n",
    "        \n",
    "        self._size = len(x_data)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Gets the size of the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: dataset size.\n",
    "        \"\"\"\n",
    "\n",
    "        return self._size\n",
    "\n",
    "    def __getitem__(self, idx:int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Gets a item of the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): data index.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: dataset input. \n",
    "            torch.Tensor: dataset target.\n",
    "        \"\"\"\n",
    "        return self._x_data[idx], self._y_data[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geramos um dataset de exemplo e mostramos que os tamanhos das entradas e saídas está correto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_dataset = TextPredictDataset(test_x_train, test_y_train)\n",
    "\n",
    "assert_array_equal(test_train_dataset[0][0].shape, [test_context_size])\n",
    "assert_array_equal(test_train_dataset[0][1].shape, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, mostramos o uso de um DataLoader e mostramos que os dados possuem tamanhos corretos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 5\n",
    "test_train_loader = DataLoader(test_train_dataset, batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "test_data = next(iter(test_train_loader))\n",
    "\n",
    "assert_array_equal(test_data[0].shape, [test_batch_size, test_context_size])\n",
    "assert_array_equal(test_data[1].shape, [test_batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando tudo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o uso posterior, podemos juntar todas as funções criadas realizando o processo completo de geração do dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(texts:List[str], vocab_size:int, context_size:int, batch_size:int) -> Tuple[Dict, List, Dict[str, DataLoader]]:\n",
    "    \"\"\"\n",
    "    Generates a text prediction dataset.\n",
    "\n",
    "    Args:\n",
    "        texts (List[str]): texts to generate the dataset.\n",
    "        vocab_size (int): size of the vocabulary (know words).\n",
    "        context_size (int): size of the sequences.\n",
    "        batch_size (int): size of the batchs.\n",
    "\n",
    "    Returns:\n",
    "        Dict: vocabulary. Maps words to codes.\n",
    "        List: inverse vocabulary. Maps codes to words.\n",
    "        Dict[str, DataLoader]: dataloaders.\n",
    "    \"\"\"\n",
    "\n",
    "    word_counts = count_words(texts)\n",
    "    vocab, inverse_vocab = create_vocab(word_counts, vocab_size)\n",
    "\n",
    "    x_all, y_all = create_sequences(texts, context_size, vocab)\n",
    "    \n",
    "    x_all, y_all = shuffle_dataset(x_all, y_all)\n",
    "\n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = separate_dataset(x_all, y_all)\n",
    "\n",
    "    train_dataset = TextPredictDataset(x_train, y_train)\n",
    "    val_dataset = TextPredictDataset(x_val, y_val)\n",
    "    test_dataset = TextPredictDataset(x_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    dataloaders = {\"train\": train_loader, \"val\":val_loader, \"test\":test_loader}\n",
    "\n",
    "    return vocab, inverse_vocab, dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "Esta seção irá implementar o base modelo que será treinado, baseado em \"A Neural Probabilistic Language Model\" (Bengio, 2003)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "Para o embedding utilizamos uma matriz de look-up aprendível:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Converts codes to embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim:int, vocab_size:int) -> None:\n",
    "        \"\"\"\n",
    "        Creates a new Embedding layer.\n",
    "\n",
    "        Args:\n",
    "            embed_dim (int): size of the embedding in the output.\n",
    "            vocab_size (int): size of the vocabulary the words were coded.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self._embed_dim = embed_dim\n",
    "        self._vocab_size = vocab_size\n",
    "\n",
    "        C = torch.Tensor(vocab_size, embed_dim)\n",
    "        torch.nn.init.xavier_uniform_(C)\n",
    "        self.C = torch.nn.Parameter(C)\n",
    "\n",
    "    def forward(self, input_tensor:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Embeds the input sequences.\n",
    "\n",
    "        Args:\n",
    "            input_tensor (torch.Tensor): sequences to be embeded.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: result embeddings.\n",
    "        \"\"\"\n",
    "        \n",
    "        result = torch.index_select(self.C, 0, input_tensor.flatten())\n",
    "        result = result.reshape(-1, input_tensor.shape[-1], self._embed_dim)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LanguageModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, context_size:int, vocab_size:int, embed_dim:int, hidden_units:int):\n",
    "        super().__init__()\n",
    "        \n",
    "        #V = |Vocab|, m = |Embed|\n",
    "        #n-1 = c = |Context|\n",
    "        #h = |Hidden|\n",
    "        \n",
    "        #C[V, m](input) -> x[c*m]\n",
    "        #Linear1(x) -> x2[h]\n",
    "        #ReLU(x2) -> x3[h]  | alterado do paper (tanh)\n",
    "        #Linear2(x) -> x4[V]\n",
    "        #Linear3(x3) -> x5[V] | sem bias (Linear2 já tem bias)\n",
    "        #Add(x4, x5) -> output\n",
    "        #Sem softmax -> melhor estabilidade\n",
    "\n",
    "        m = int(context_size*embed_dim)\n",
    "\n",
    "        self.embedding = Embedding(embed_dim, vocab_size)\n",
    "        self.linear1 = torch.nn.Linear(m, hidden_units)\n",
    "        self.relu = torch.nn.ReLU() \n",
    "        self.linear2 = torch.nn.Linear(m, vocab_size)\n",
    "        self.linear3 = torch.nn.Linear(hidden_units, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        \n",
    "        x2 = self.linear1(x)\n",
    "        x3 = self.relu(x2)\n",
    "        x4 = self.linear2(x)\n",
    "        x5 = self.linear3(x3)\n",
    "\n",
    "        output = x4+x5\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRA_Module(torch.nn.Module, abc.ABC):\n",
    "    '''\n",
    "    Abstract LoRA module.\n",
    "\n",
    "    A LoRA module realizes the same kind of operation as the reference module,\n",
    "    but with low-rank matrices decomposition.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, original_module:torch.nn.Module, rank:int, alpha:float, use_bias:bool=False) -> None:\n",
    "        '''\n",
    "        LoRA_Module constructor.\n",
    "\n",
    "        Args:\n",
    "            original_module (torch.nn.Module): original module to be LoRAed\n",
    "            rank (int): matrices rank. Must be positive and integer.\n",
    "            alpha (float): scaling parameter for the weight update.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if rank is not positive or integer.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        if rank < 0 or not isinstance(rank, int):\n",
    "            raise ValueError(f\"'rank' must be positive and integer. Received rank={rank}, type={type(rank)}\")\n",
    "\n",
    "        for param in original_module.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self._original_module = original_module\n",
    "        self._rank = rank\n",
    "        self._alpha = alpha\n",
    "        self._scaling = alpha/rank\n",
    "        self._use_bias = use_bias\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def add_weights(self) -> None:\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def reduce_module(self) -> torch.nn.Module:\n",
    "        '''\n",
    "        Generates a reduced version of the original module,\n",
    "        incorporating the new calculated weights.\n",
    "\n",
    "        Returns:\n",
    "            torch.nn.Module: reduced module.\n",
    "        '''\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRA_Linear(LoRA_Module):\n",
    "    '''\n",
    "    LoRA version of a Linear module.\n",
    "\n",
    "    Realizes the operation with low-rank A and B matrices:\n",
    "\n",
    "    y = x @ Aᵀ @ Bᵀ\n",
    "    '''\n",
    "    def __init__(self, linear:torch.nn.Linear, rank:int, alpha:float=1.0, use_bias:bool=False) -> None:\n",
    "        '''\n",
    "        LoRA_Linear constructor.\n",
    "\n",
    "        Args:\n",
    "            linear (torch.nn.Linear): original linear module to be LoRAed.\n",
    "            rank (int): matrices rank. Must be positive and integer.\n",
    "            alpha (float): scaling parameter for the weight update. Defaults to 1.0.\n",
    "        '''\n",
    "\n",
    "        if linear.bias is None:\n",
    "            use_bias = False\n",
    "\n",
    "        super().__init__(linear, rank, alpha, use_bias)\n",
    "        self._original_module : torch.nn.Linear\n",
    "\n",
    "        self._in_features = linear.in_features\n",
    "        self._out_features = linear.out_features\n",
    "\n",
    "        device = self._original_module.weight.device\n",
    "        dtype = self._original_module.weight.dtype\n",
    "\n",
    "\n",
    "        B = torch.empty(self._out_features, rank, device=device, dtype=dtype)\n",
    "        A = torch.empty(rank, self._in_features, device=device, dtype=dtype)\n",
    "\n",
    "        self.B = torch.nn.Parameter(B)\n",
    "        self.A = torch.nn.Parameter(A)\n",
    "\n",
    "        if self._use_bias:\n",
    "            bias = torch.empty_like(self._original_module.bias)\n",
    "            self.bias = torch.nn.Parameter(bias)\n",
    "\n",
    "        self._initalize()\n",
    "\n",
    "    def _initalize(self) -> None:\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=5) # LoRA code initializes this way (??)\n",
    "        torch.nn.init.zeros_(self.B)\n",
    "\n",
    "        if self._use_bias:\n",
    "            torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        y1 = self._original_module(x)\n",
    "        y2 = (x @ self.A.T)@self.B.T * self._scaling\n",
    "\n",
    "        if self._use_bias:\n",
    "            y2 += self.bias\n",
    "\n",
    "        y = y1+y2\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def add_weights(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            W = self._original_module.weight + (self.B@self.A*self._scaling)\n",
    "            W = torch.nn.Parameter(W)\n",
    "\n",
    "            self._original_module.weight = W\n",
    "\n",
    "            if self._use_bias:\n",
    "                self._original_module.bias += self.bias\n",
    "\n",
    "        self._initalize()\n",
    "\n",
    "    def reduce_module(self) -> torch.nn.Linear:\n",
    "        '''\n",
    "        Reduces to a Linear module,\n",
    "        incorporating the new calculated weights.\n",
    "\n",
    "        Returns:\n",
    "            torch.nn.Linear: reduced linear module.\n",
    "        '''\n",
    "        use_bias = self._original_module.bias is not None\n",
    "        device = self._original_module.weight.device\n",
    "        dtype = self._original_module.weight.dtype\n",
    "\n",
    "        linear = torch.nn.Linear(self._in_features, self._out_features, \n",
    "                                 use_bias, device, dtype)\n",
    "        \n",
    "        W = self._original_module.weight + (self.B@self.A*self._scaling)\n",
    "        W = torch.nn.Parameter(W)\n",
    "        linear.weight = W\n",
    "        linear.bias = self._original_module.bias \n",
    "\n",
    "        with torch.no_grad():\n",
    "            if self._use_bias:\n",
    "                linear.bias += self.bias\n",
    "                    \n",
    "        return linear\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRA_Embedding(LoRA_Module):\n",
    "    '''\n",
    "    LoRA version of a Embedding module.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, embedding:Embedding, rank:int, alpha:float=1.0, use_bias:bool=False) -> None:\n",
    "        '''\n",
    "        LoRA_Linear constructor.\n",
    "\n",
    "        Args:\n",
    "            embedding (torch.nn.Linear): original embedding module to be LoRAed.\n",
    "            rank (int): matrices rank. Must be positive and integer.\n",
    "            alpha (float): scaling parameter for the weight update. Defaults to 1.0.\n",
    "        '''\n",
    "\n",
    "        super().__init__(embedding, rank, alpha)\n",
    "        self._original_module : Embedding\n",
    "\n",
    "        self._embed_dim = self._original_module._embed_dim\n",
    "        self._vocab_size = self._original_module._vocab_size\n",
    "\n",
    "        device = self._original_module.C.device\n",
    "        dtype = self._original_module.C.dtype\n",
    "\n",
    "\n",
    "        A = torch.empty(self._vocab_size, rank, device=device, dtype=dtype)\n",
    "        B = torch.empty(rank, self._embed_dim, device=device, dtype=dtype)\n",
    "        \n",
    "        self.A = torch.nn.Parameter(A)\n",
    "        self.B = torch.nn.Parameter(B)\n",
    "\n",
    "        self._initalize()\n",
    "\n",
    "    \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        y1 = self._original_module(x)\n",
    "\n",
    "        y2 = torch.index_select(self.A, 0, x.flatten())\n",
    "        y2 = y2.reshape(-1, x.shape[-1], self._rank) # [batch, sequence, rank]\n",
    "\n",
    "        y2 = y2 @ self.B # [batch, sequence, embed]\n",
    "\n",
    "        y2 *= self._scaling\n",
    "\n",
    "        result = y1+y2\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _initalize(self) -> None:\n",
    "        torch.nn.init.normal_(self.A)\n",
    "        torch.nn.init.zeros_(self.B)\n",
    "\n",
    "    def add_weights(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            delta_C = self.A@self.B*self._scaling\n",
    "            self._original_module.C += delta_C\n",
    "\n",
    "        self._initalize()\n",
    "\n",
    "    def reduce_module(self) -> Embedding:\n",
    "        '''\n",
    "        Reduces to a Embedding module,\n",
    "        incorporating the new calculated weights.\n",
    "\n",
    "        Returns:\n",
    "            Embedding: reduced embedding module.\n",
    "        '''\n",
    "\n",
    "        embedding = Embedding(self._embed_dim, self._vocab_size)\n",
    "\n",
    "        C = self._original_module.C\n",
    "        delta_C = self.A@self.B*self._scaling\n",
    "        C  = C+delta_C\n",
    "\n",
    "        embedding.C = torch.nn.Parameter(C)\n",
    "\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map from original module to LoRA version\n",
    "LoRA_MAP : Dict[torch.nn.Module, LoRA_Module] = {torch.nn.Linear:LoRA_Linear, Embedding:LoRA_Embedding}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRA_Model(LoRA_Module):\n",
    "    '''\n",
    "    Converts a torch module to a LoRA version, with LoRA modules.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, original_module: torch.nn.Module, rank: int, alpha: float=1.0, use_bias:bool=False) -> None:\n",
    "        '''\n",
    "        LoRA_Model constructor.\n",
    "\n",
    "        Args:\n",
    "            original_module (torch.nn.Module): module to be LoRAed.\n",
    "            rank (int): matrices rank. Must be positive and integer.\n",
    "            alpha (float): scaling parameter for the weight update. Defaults to 1.0.\n",
    "        '''\n",
    "        super().__init__(original_module, rank, alpha, use_bias)\n",
    "\n",
    "\n",
    "        for name in original_module._modules:\n",
    "            module = original_module._modules[name]\n",
    "\n",
    "            for original_class in LoRA_MAP:\n",
    "                if isinstance(module, original_class):\n",
    "                    lora_class = LoRA_MAP[original_class]\n",
    "                    lora_module = lora_class(module, rank, alpha, use_bias)\n",
    "                    original_module._modules[name] = lora_module\n",
    "    \n",
    "    def add_weights(self) -> None:\n",
    "        for name in self._original_module._modules:\n",
    "            module = self._original_module._modules[name]\n",
    "\n",
    "            if isinstance(module, LoRA_Module):\n",
    "                module.add_weights()\n",
    "\n",
    "    def reduce_module(self) -> torch.nn.Module:\n",
    "        '''\n",
    "        Generates a reduced version of the original module,\n",
    "        incorporating the new calculated weights.\n",
    "\n",
    "        Returns:\n",
    "            torch.nn.Module: reduced module.\n",
    "        '''\n",
    "        for name in self._original_module._modules:\n",
    "            module = self._original_module._modules[name]\n",
    "\n",
    "            if isinstance(module, LoRA_Module):\n",
    "                self._original_module._modules[name] = module.reduce_module()\n",
    "\n",
    "        return self._original_module\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self._original_module(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(3,4)\n",
    "lora_linear = LoRA_Linear(linear, rank=2, alpha=0.5, use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3)\n",
    "\n",
    "y_linear = linear(x).detach()\n",
    "y_lora = lora_linear(x).detach()\n",
    "\n",
    "assert_array_equal(y_linear, y_lora) #Initialized LoRA have zero weight update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_linear.A = torch.nn.Parameter(torch.rand_like(lora_linear.A))\n",
    "lora_linear.B = torch.nn.Parameter(torch.rand_like(lora_linear.B))\n",
    "lora_linear.bias = torch.nn.Parameter(torch.rand_like(lora_linear.bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lora = lora_linear(x).detach()\n",
    "\n",
    "assert_array_not_equal(y_linear, y_lora) #LoRA layer changes the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_linear.add_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lora2 = lora_linear(x).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_array_not_equal(y_linear, y_lora) #LoRA layer changes the output\n",
    "assert_array_almost_equal(y_lora, y_lora2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_linear = lora_linear.reduce_module()\n",
    "\n",
    "y_reduced = reduced_linear(x).detach()\n",
    "\n",
    "assert_array_almost_equal(y_reduced, y_lora) #Reduced result is the same as the non-reduced\n",
    "assert isinstance(reduced_linear, torch.nn.Linear) #Reduced module is of same type as the original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção iremos realizar o treino inicial, iniciando pela definição de algumas funções auxiliares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares\n",
    "\n",
    "Iremos definir quatro funções auxiliares para: calcular a perplexidade a partir da loss, printar informações, calcular a loss e realizar o treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppl(loss:torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the perplexity from the loss.\n",
    "\n",
    "    Args:\n",
    "        loss (torch.Tensor): loss to compute the perplexity.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: corresponding perplexity.\n",
    "    \"\"\"\n",
    "    return torch.exp(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(loss_value:torch.Tensor, epoch:int, total_epochs:int, \n",
    "               time:float=0.0, accuracy:Optional[float]=None):\n",
    "    \"\"\"\n",
    "    Prints the information of a epoch.\n",
    "\n",
    "    Args:\n",
    "        loss_value (torch.Tensor): epoch loss.\n",
    "        epoch (int): epoch number.\n",
    "        total_epochs (int): total number of epochs. \n",
    "        time (float, optional): time to run the epoch. Don't print if is 0.0. Defaults to 0.0.\n",
    "        accuracy (float, optional): epoch accuracy.\n",
    "    \"\"\"\n",
    "    ppl_value = ppl(loss_value)\n",
    "\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{total_epochs}], \\\n",
    "            Loss: {loss_value.item():.4f}, \\\n",
    "            Perplexity: {ppl_value.item():.4f}', end=\"\")\n",
    "    \n",
    "    if accuracy is not None:\n",
    "        print(f', Accuracy: {100*accuracy:.4f}%')\n",
    "\n",
    "    if time != 0:\n",
    "        print(f\", Elapsed Time: {time:.2f} sec\")    \n",
    "    else:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_norm(lora_model:LoRA_Model):\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        delta_norm = []\n",
    "        for name in lora_model._original_module._modules:\n",
    "                module = lora_model._original_module._modules[name]\n",
    "\n",
    "                if isinstance(module, LoRA_Module):\n",
    "                    if isinstance(module, LoRA_Linear):\n",
    "                        deltaW = module.B@module.A*module._scaling\n",
    "                    else:\n",
    "                        deltaW = module.A@module.B*module._scaling\n",
    "                    \n",
    "                    deltaW = deltaW.detach().cpu()\n",
    "\n",
    "                    delta_norm.append(np.linalg.norm(deltaW, \"fro\"))\n",
    "\n",
    "    delta_norm = np.array(delta_norm)\n",
    "    \n",
    "    return delta_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE_TRAIN = 0\n",
    "MODE_EVALUATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model:torch.nn.Module, loader:DataLoader, \n",
    "                 criterion:torch.nn.Module, mode:int = MODE_EVALUATE, \n",
    "                 optimizer:Optional[torch.optim.Optimizer]=None, \n",
    "                 accumulation_steps:Optional[int] = 1) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Computes the loss from a model across a dataset.\n",
    "\n",
    "    If in train mode also runs optimizer steps.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): model to evaluate.\n",
    "        loader (DataLoader): dataset.\n",
    "        criterion (torch.nn.Module): loss function to compute.\n",
    "        mode (int): mode of the computation. \n",
    "                    If MODE_EVALUATE, computes without gradient, in eval mode and detachs loss.\n",
    "                    If MODE_TRAIN, computes with gradient and in train mode.\n",
    "                    Default is MODE_EVALUATE.\n",
    "        optimizer (torch.optim.Optimizer, optional): optimizer to use in the train mode.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: resulting loss.\n",
    "    \"\"\"\n",
    "    device = next(iter(model.parameters())).device\n",
    "\n",
    "    if mode == MODE_EVALUATE:\n",
    "        model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "    elif mode == MODE_TRAIN:\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        optimizer.zero_grad()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}.\")\n",
    "\n",
    "    batch_index = 0\n",
    "    total_loss = torch.tensor(0, dtype=torch.float32, device=device)\n",
    "    n = 0\n",
    "    for inputs, targets in tqdm.tqdm(loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        logits = model(inputs)\n",
    "        logits = logits.view(-1, logits.shape[-1])\n",
    "\n",
    "        loss : torch.Tensor = criterion(logits.squeeze(), targets)\n",
    "        total_loss += loss*targets.size(0)\n",
    "\n",
    "        #print(\"step loss\", loss.detach().item())\n",
    "        \n",
    "        \n",
    "        n += targets.size(0)\n",
    "\n",
    "        if mode == MODE_TRAIN:\n",
    "            loss /= accumulation_steps\n",
    "            loss.backward()\n",
    "\n",
    "            if ((batch_index+1) % accumulation_steps == 0) or (batch_index+1 == len(loader)):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        batch_index += 1\n",
    "\n",
    "    total_loss /= n \n",
    "    \n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "    total_loss = total_loss.detach()\n",
    "\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:torch.nn.Module, criterion:torch.nn.Module, optimizer:torch.optim.Optimizer, \n",
    "          dataloaders:DataLoader, n_epoch:int, accumulation_steps:int=1, \n",
    "          use_wandb:bool=False) -> Dict[str, ArrayLike]:\n",
    "    hist = {}\n",
    "    hist[\"loss_train\"] = []\n",
    "    hist[\"loss_val\"] = []\n",
    "    hist[\"ppl_train\"] = []\n",
    "    hist[\"ppl_val\"] = []\n",
    "    hist[\"time\"] = []\n",
    "    hist[\"delta_norm\"] = []\n",
    "\n",
    "    loss_val = compute_loss(model, dataloaders[\"val\"], criterion, MODE_EVALUATE)\n",
    "        \n",
    "    print(\"VAL \", end=\"\")\n",
    "    print_info(loss_val, -1, n_epoch)\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        start_time = time.time() \n",
    "\n",
    "        loss_train = compute_loss(model, dataloaders[\"train\"], criterion, MODE_TRAIN, optimizer, accumulation_steps)\n",
    "\n",
    "        end_time = time.time() \n",
    "        \n",
    "        epoch_duration = end_time - start_time \n",
    "\n",
    "        ppl_train = ppl(loss_train)\n",
    "\n",
    "        print_info(loss_train, epoch, n_epoch, epoch_duration)\n",
    "\n",
    "        delta_norm = get_delta_norm(model)\n",
    "        model.add_weights()\n",
    "        \n",
    "        #Validation stats\n",
    "        loss_val = compute_loss(model, dataloaders[\"val\"], criterion, MODE_EVALUATE)\n",
    "        ppl_val = ppl(loss_val)\n",
    "        \n",
    "        print(\"VAL \", end=\"\")\n",
    "        print_info(loss_val, epoch, n_epoch)\n",
    "\n",
    "        #Save history\n",
    "        hist[\"loss_train\"].append(loss_train.item())\n",
    "        hist[\"loss_val\"].append(loss_val.item())\n",
    "        hist[\"ppl_train\"].append(ppl_train.item())\n",
    "        hist[\"ppl_val\"].append(ppl_val.item())\n",
    "        hist[\"time\"].append(epoch_duration)\n",
    "        hist[\"delta_norm\"].append(delta_norm)\n",
    "\n",
    "\n",
    "        log = {\n",
    "            \"loss_train\": loss_train.item(),\n",
    "            \"loss_val\": loss_val.item(),\n",
    "            \"ppl_train\": ppl_train.item(),\n",
    "            \"ppl_val\": ppl_val.item(),\n",
    "            \"delta_norm\": delta_norm\n",
    "        }\n",
    "\n",
    "        if use_wandb:\n",
    "            wandb.log(log)\n",
    "\n",
    "    for key in hist:\n",
    "        hist[key] = np.array(hist[key])\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.finish()\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialização\n",
    "\n",
    "Começamos o processo de treino inicializando as variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos se será realizado o logging utilizando o wandb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wandb = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checamos se existe uma GPU disponível:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos os parâmetros de treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Github\\IA024\\Experiments\\wandb\\run-20240530_172814-i3yu7ye0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eltoncn/FullLoRA/runs/i3yu7ye0' target=\"_blank\">golden-bush-12</a></strong> to <a href='https://wandb.ai/eltoncn/FullLoRA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eltoncn/FullLoRA' target=\"_blank\">https://wandb.ai/eltoncn/FullLoRA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eltoncn/FullLoRA/runs/i3yu7ye0' target=\"_blank\">https://wandb.ai/eltoncn/FullLoRA/runs/i3yu7ye0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accumulation_steps = 1 # Passos de acumulação de gradiente\n",
    "batch_size = 32 # Tamanho de um batch\n",
    "context_size = 5 # Tamanho de uma sequência\n",
    "embed_dim = 64 # Tamanho do feature vector de cada palavra\n",
    "hidden_units = 300 # Quantidade de unidades na camada escondida\n",
    "\n",
    "\n",
    "lora_rank = 10\n",
    "\n",
    "scaling = 1\n",
    "\n",
    "lora_alpha = scaling*lora_rank#1\n",
    "\n",
    "lr = 5e-3 # Taxa de treinamento\n",
    "n_epoch = 10 # Quantidade de epochs\n",
    "optimizer_class = torch.optim.Adam # Otimizador\n",
    "vocab_size = 3000 # Quantidade de palavras no vocabulário\n",
    "weight_decay = 1e-3 # Regularização L2\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"accumulation_steps\": accumulation_steps,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"embed_dim\":embed_dim,\n",
    "    \"hidden_units\":hidden_units,\n",
    "    \"lora_alpha\" : lora_alpha,\n",
    "    \"lora_rank\" : lora_rank,\n",
    "    \"lr\": lr,\n",
    "    \"n_epoch\": n_epoch,\n",
    "    \"optimizer_class\": optimizer_class.__name__,\n",
    "    \"context_size\" : context_size,\n",
    "    \"weight_decay\": weight_decay,\n",
    "}\n",
    "\n",
    "if use_wandb:\n",
    "    run = wandb.init(project=\"FullLoRA\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reiniciamos as sementes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos o vocabulário, dataset, modelo, loss, otimizador e dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, inverse_vocab, dataloaders = create_data_loaders(cleaned_paragraphs, vocab_size, context_size, batch_size)\n",
    "\n",
    "\n",
    "base_model = LanguageModel(context_size, vocab_size, embed_dim, hidden_units)\n",
    "model = LoRA_Model(base_model, rank=lora_rank, alpha=lora_alpha, use_bias=True)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optimizer_class(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 656.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Epoch [0/10],             Loss: 8.0003,             Perplexity: 2981.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 715/715 [00:02<00:00, 262.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10],             Loss: 5.9388,             Perplexity: 379.4841, Elapsed Time: 2.74 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 739.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Epoch [1/10],             Loss: 5.4909,             Perplexity: 242.4718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 715/715 [00:02<00:00, 300.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10],             Loss: 5.2082,             Perplexity: 182.7643, Elapsed Time: 2.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 737.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Epoch [2/10],             Loss: 5.3564,             Perplexity: 211.9541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 715/715 [00:02<00:00, 262.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10],             Loss: 5.0537,             Perplexity: 156.5972, Elapsed Time: 2.75 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 652.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Epoch [3/10],             Loss: 5.2799,             Perplexity: 196.3594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 715/715 [00:03<00:00, 235.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10],             Loss: 4.9409,             Perplexity: 139.8944, Elapsed Time: 3.06 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 706.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Epoch [4/10],             Loss: 5.2641,             Perplexity: 193.2715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 715/715 [00:02<00:00, 297.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10],             Loss: 4.8634,             Perplexity: 129.4677, Elapsed Time: 2.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 728.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Epoch [5/10],             Loss: 5.2362,             Perplexity: 187.9610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 715/715 [00:02<00:00, 309.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10],             Loss: 4.8030,             Perplexity: 121.8803, Elapsed Time: 2.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 770.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Epoch [6/10],             Loss: 5.2503,             Perplexity: 190.6174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 715/715 [00:02<00:00, 282.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10],             Loss: 4.7531,             Perplexity: 115.9431, Elapsed Time: 2.55 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 643.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Epoch [7/10],             Loss: 5.2349,             Perplexity: 187.7016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 715/715 [00:02<00:00, 252.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10],             Loss: 4.7017,             Perplexity: 110.1357, Elapsed Time: 2.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 628.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Epoch [8/10],             Loss: 5.2335,             Perplexity: 187.4546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 715/715 [00:02<00:00, 269.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10],             Loss: 4.6542,             Perplexity: 105.0291, Elapsed Time: 2.68 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 647.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Epoch [9/10],             Loss: 5.2319,             Perplexity: 187.1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 715/715 [00:02<00:00, 269.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10],             Loss: 4.6053,             Perplexity: 100.0167, Elapsed Time: 2.68 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 663.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL Epoch [10/10],             Loss: 5.2150,             Perplexity: 184.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss_train</td><td>█▄▃▃▂▂▂▂▁▁</td></tr><tr><td>loss_val</td><td>█▅▃▂▂▂▂▁▁▁</td></tr><tr><td>ppl_train</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>ppl_val</td><td>█▄▂▂▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss_train</td><td>4.60534</td></tr><tr><td>loss_val</td><td>5.21503</td></tr><tr><td>ppl_train</td><td>100.01674</td></tr><tr><td>ppl_val</td><td>184.01765</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">golden-bush-12</strong> at: <a href='https://wandb.ai/eltoncn/FullLoRA/runs/i3yu7ye0' target=\"_blank\">https://wandb.ai/eltoncn/FullLoRA/runs/i3yu7ye0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240530_172814-i3yu7ye0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basetrain_history = train(model, criterion, optimizer, dataloaders, n_epoch, accumulation_steps, use_wandb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que o modelo treina corretamente, porém com considerável overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(basetrain_history[\"loss_train\"], \"o-\")\n",
    "plt.plot(basetrain_history[\"loss_val\"], \"o-\")\n",
    "\n",
    "plt.legend([\"Train\", \"Val\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss history\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(basetrain_history[\"ppl_train\"]/vocab_size, \"o-\")\n",
    "plt.plot(basetrain_history[\"ppl_val\"]/vocab_size, \"o-\")\n",
    "\n",
    "plt.legend([\"Train\", \"Val\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Normalized PPL\")\n",
    "plt.title(\"Perplexity history\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ae3184fd60>,\n",
       " <matplotlib.lines.Line2D at 0x1ae3184fd90>,\n",
       " <matplotlib.lines.Line2D at 0x1ae3184feb0>,\n",
       " <matplotlib.lines.Line2D at 0x1ae3184ffd0>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(basetrain_history[\"delta_norm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ae318be970>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(basetrain_history[\"delta_norm\"].mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA_Embedding(\n",
      "  (_original_module): Embedding()\n",
      ")\n",
      "LoRA_Linear(\n",
      "  (_original_module): Linear(in_features=320, out_features=300, bias=True)\n",
      ")\n",
      "LoRA_Linear(\n",
      "  (_original_module): Linear(in_features=320, out_features=3000, bias=True)\n",
      ")\n",
      "LoRA_Linear(\n",
      "  (_original_module): Linear(in_features=300, out_features=3000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for name in model._original_module._modules:\n",
    "    module = model._original_module._modules[name]\n",
    "\n",
    "    if isinstance(module, LoRA_Module):\n",
    "        print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, vocab, inverse_vocab, text, max_length):\n",
    "    text = clean_text(text)\n",
    "\n",
    "    total_length = len(text.split(\" \"))\n",
    "\n",
    "    last_sequence = create_sequences([text], context_size, vocab)[0][-1]\n",
    "    last_sequence = torch.tensor(last_sequence)-1\n",
    "    last_sequence = last_sequence.to(device)\n",
    "\n",
    "    new_characters = []\n",
    "\n",
    "    while total_length < max_length:\n",
    "        \n",
    "        output = model(torch.unsqueeze(last_sequence, 0))\n",
    "        \n",
    "        next_encoded = output.argmax(dim=1).item()\n",
    "\n",
    "        last_sequence = torch.cat((last_sequence[1:], torch.tensor([next_encoded]).to(device)))\n",
    "        \n",
    "        new_characters.append(next_encoded)\n",
    "\n",
    "        total_length += 1\n",
    "\n",
    "    new_characters = np.array(new_characters)+1\n",
    "\n",
    "    new_text = \" \".join(decode_sentence(new_characters, inverse_vocab))\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLD\n",
      "- - tu não abandonarás tua senhora , não é ? disse ella passando a\n",
      "\n",
      "GENERATED CONTINUATION\n",
      "o seu arco e o que se passava , e o seu sorriso que se havia o seu espirito , e o seu sorriso que\n"
     ]
    }
   ],
   "source": [
    "text = cleaned_paragraphs[300]\n",
    "max_length = 40\n",
    "\n",
    "new_text = generate_text(model, vocab, inverse_vocab, text, max_length)\n",
    "\n",
    "print(\"OLD\")\n",
    "print(text)\n",
    "print(\"\")\n",
    "print(\"GENERATED CONTINUATION\")\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
